
######## Layout of the data file
#
# A line is a keyword and a value separated by a tabulation
#
# Each instruction set (ARM32, Thumb, Java and ARM64) is introduced with the "isa" keyword
#
# The "code" keyword introduces a new opcode, with a bit pattern (or for Java, a hexadecimal byte pattern)
# Symbols 0 and 1 refer to bit values 0 and 1, . and @ and ! are ignored, but @ shows a preference to 0 and ! a preference to 1
# Any other symbol (expected to be a letter) becomes part of a bitfield with the name
# If the bits are non-contiguous, the field is a concatenation of those values
#
# The "exclude" keyword excludes certain bit combinations from matching the bit pattern
# If followed by a tab, "before" and another tab, it constrains when an exclusion holds, with the same syntax as removed
# Similarly, a tab, "since" and another tab works as an additional "added" keyword
# Special case are the "when"/"except" keywords which exclude specific features instead of processor generations
#
# For instructions that have very similar encoding in ARM and Thumb modes, the code.a/code.t pair of tags can be used
# When needed, the "for ARM" and "for Thumb" can be used with the "exclude" keyword to separte exclusions for one or the other
#
# The "it" keyword is used in Thumb mode to determine if an instruction may occur inside an IT block, with "no"/"yes" and "end" allowed
# A "when" keyword may provide an optional attribute (such as an "it"), provided the opcode matches the pattern
#
# The "asm" keyword introduces the assembly syntax for the instruction
# The { and } symbols can delimit a template parameter
# Simple arithmetic on template parameter is allowed: +/-/*
# A single letter references a bitfield in the code template
# The ' symbol concatenates bitfields, sequences of 0/1 bits can also appear
# The signextend prefix can extend the most significant bit of a bitfield parameter
# Special syntax is used for some values, the most basic being the conditional ? : operator pair
# A :X, :2X, :4X suffix specifies the formatting, a !offset adds the current PC value to it (and formats it as :X)
# Some macros include the operand() and adr_operand() for handling recurring encoding types, and cond(c) to print the current condition name
#
# When an instruction has a different syntax in classic and unified modes, the "asm.ual" introduces the unified version
#
# The "added" and "removed" keywords delimit which ARM versions support the instruction pattern
# The generator uses a very simple algorithm to determine which cores will support an instruction
# For example, use 5TExP for all 5TE instructions, and 5TE for those that are not absent from 5TExP
#
# For Jazelle instructions, "added" instead marks which instruction set contains that instruction, but the processor might still invoke the monitor
# Instead the keyword "usedby" marks which processors actually implement that instruction
#
# The "thumbee" keyword specifies whether the instruction is valid in Thumb/ThumbEE modes, with "no"/"yes" restricting it to one mode
#
# The "begin"/"end" block delimits the C code to be generated
# Similarly to the "asm" keyword, ${ and } symbols delimit template parameters, and certain other shorthands are possible using the $ prefix
# For example, $r[N] will select register number N in the current mode, and $r.lhs[N] will generate a special value for N=15 in ARM26 mode

######## AArch32, including ARM26 and ARM32

isa	A32

# registers are accessed as $r[n], for R0 to R15
# $r[15] evaluates to PC, and assigning to it clears the least significant bit for proper alignment
# $r.lhs[15] is special in ARM26 mode, the least significant 2 bits and the 6 most significant bits are copied over from CSPR
# it should be noted that assigning to R15 in ARM26 mode can also alter the CPSR bits according to the value, but this is handled by the arithmetic functions
# when assigning to $r.v7[15] on ARMv7 or later, it permits interworking between ARM and Thumb modes by checking the least significant bit
# same concept with $r.v5[15], but for ARMv5 or later
# storing R15 will result in an offset of 8 or 12 depending on the implementation, these can be written as $r.str[15]

#### ARMv1
#### Data processing

code	cccc00O0000SnnnnddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	and{cond(c)}{S?s:} r{d}, r{n}, {operand()}
asm.ual	and{S?s:}{cond(c)} r{d}, r{n}, {operand()}
added	1
begin
	// and
	if($c[${c}])
	{
		$r.v7[${d}] = a32_and32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand(S)}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O0001SnnnnddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	eor{cond(c)}{S?s:} r{d}, r{n}, {operand()}
asm.ual	eor{S?s:}{cond(c)} r{d}, r{n}, {operand()}
added	1
begin
	// eor
	if($c[${c}])
	{
		$r.v7[${d}] = a32_eor32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand(S)}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O0010SnnnnddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	sub{cond(c)}{S?s:} r{d}, r{n}, {operand()}
asm.ual	sub{S?s:}{cond(c)} r{d}, r{n}, {operand()}
added	1
begin
	// sub
	if($c[${c}])
	{
		$r.v7[${d}] = a32_sub32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand()}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O0011SnnnnddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	rsb{cond(c)}{S?s:} r{d}, r{n}, {operand()}
asm.ual	rsb{S?s:}{cond(c)} r{d}, r{n}, {operand()}
added	1
begin
	// rsb
	if($c[${c}])
	{
		$r.v7[${d}] = a32_rsb32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand()}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O0100SnnnnddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	add{cond(c)}{S?s:} r{d}, r{n}, {operand()}
asm.ual	add{S?s:}{cond(c)} r{d}, r{n}, {operand()}
added	1
begin
	// add
	if($c[${c}])
	{
		$r.v7[${d}] = a32_add32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand()}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O0101SnnnnddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	adc{cond(c)}{S?s:} r{d}, r{n}, {operand()}
asm.ual	adc{S?s:}{cond(c)} r{d}, r{n}, {operand()}
added	1
begin
	// adc
	if($c[${c}])
	{
		$r.v7[${d}] = a32_adc32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand()}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O0110SnnnnddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	sbc{cond(c)}{S?s:} r{d}, r{n}, {operand()}
asm.ual	sbc{S?s:}{cond(c)} r{d}, r{n}, {operand()}
added	1
begin
	// sbc
	if($c[${c}])
	{
		$r.v7[${d}] = a32_sbc32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand()}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O0111SnnnnddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	rsc{cond(c)}{S?s:} r{d}, r{n}, {operand()}
asm.ual	rsc{S?s:}{cond(c)} r{d}, r{n}, {operand()}
added	1
begin
	// rsc
	if($c[${c}])
	{
		$r.v7[${d}] = a32_rsc32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand()}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O10001nnnn@@@@OOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	tst{cond(c)} r{n}, {operand()}
added	1
begin
	// tst
	if($c[${c}])
	{
		a32_tst32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand(1)}, IGNORE_RESULT);
	}
end

code	cccc00O10001nnnn1111OOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	tst{cond(c)}p r{n}, {operand()}
a26	yes
added	1
#removed	3G
begin
	// tstp
	if($c[${c}])
	{
		a32_tst32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand(1)}, COPY_CPSR_BITS);
	}
end

code	cccc00O10011nnnn@@@@OOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	teq{cond(c)} r{n}, {operand()}
added	1
begin
	// teq
	if($c[${c}])
	{
		a32_teq32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand(1)}, IGNORE_RESULT);
	}
end

code	cccc00O10011nnnn1111OOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	teq{cond(c)}p r{n}, {operand()}
a26	yes
added	1
#removed	3G
begin
	// teqp
	if($c[${c}])
	{
		a32_teq32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand(1)}, COPY_CPSR_BITS);
	}
end

code	cccc00O10101nnnn@@@@OOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	cmp{cond(c)} r{n}, {operand()}
added	1
begin
	// cmp
	if($c[${c}])
	{
		a32_cmp32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand()}, IGNORE_RESULT);
	}
end

code	cccc00O10101nnnn1111OOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	cmp{cond(c)}p r{n}, {operand()}
a26	yes
added	1
#removed	3G
begin
	// cmpp
	if($c[${c}])
	{
		a32_cmp32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand()}, COPY_CPSR_BITS);
	}
end

code	cccc00O10111nnnn@@@@OOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	cmn{cond(c)} r{n}, {operand()}
added	1
begin
	// cmn
	if($c[${c}])
	{
		a32_cmn32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand()}, IGNORE_RESULT);
	}
end

code	cccc00O10111nnnn1111OOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	cmn{cond(c)}p r{n}, {operand()}
a26	yes
added	1
#removed	3G
begin
	// cmnp
	if($c[${c}])
	{
		a32_cmn32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand()}, COPY_CPSR_BITS);
	}
end

code	cccc00O1100SnnnnddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	orr{cond(c)}{S?s:} r{d}, r{n}, {operand()}
asm.ual	orr{S?s:}{cond(c)} r{d}, r{n}, {operand()}
added	1
begin
	// orr
	if($c[${c}])
	{
		$r.v7[${d}] = a32_orr32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand(S)}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O1101S@@@@ddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	mov{cond(c)}{S?s:} r{d}, {operand()}
asm.ual	mov{S?s:}{cond(c)} r{d}, {operand()}
added	1
begin
	// mov
	if($c[${c}])
	{
		$r.v7[${d}] = a32_mov32(cpu, ${operand(S)}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O1110SnnnnddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	bic{cond(c)}{S?s:} r{d}, r{n}, {operand()}
asm.ual	bic{S?s:}{cond(c)} r{d}, r{n}, {operand()}
added	1
begin
	// bic
	if($c[${c}])
	{
		$r.v7[${d}] = a32_bic32(cpu, $r.lhs[${n}] + ${pcoffset(n)}, ${operand(S)}, ${S!test}, ${d} == 15);
	}
end

code	cccc00O1111S@@@@ddddOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......0.................1..1....
asm	mvn{cond(c)}{S?s:} r{d}, {operand()}
asm.ual	mvn{S?s:}{cond(c)} r{d}, {operand()}
added	1
begin
	// mvn
	if($c[${c}])
	{
		$r.v7[${d}] = a32_mvn32(cpu, ${operand(S)}, ${S!test}, ${d} == 15);
	}
end

#### Load/store instructions

code	cccc01O1OBWLnnnnttttOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......1.................1..1....	before	2
exclude	......1....................1....	since	2
asm	{L?ldr:str}{cond(c)}{B?b:} r{t}, [r{n}, {adr_operand()}]{W?!:}
asm.ual	{L?ldr:str}{B?b:}{cond(c)} r{t}, [r{n}, {adr_operand()}]{W?!:}
added	1
begin
	// ldr/str
	if($c[${c}])
	{
		uint32_t offset = ${adr_operand()};

		if(${L!test})
		{
			if(${B!test})
			{
				$r.v5[${t}] = a32_ldrb(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
			else
			{
				$r.v5[${t}] = a32_ldr(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
		}
		else
		{
			if(${B!test})
			{
				a32_strb(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
			else
			{
				a32_str(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
		}
	}
end

code	cccc01O0UBTLnnnnttttOOOOOOOOOOOO
exclude	1111............................	since	5
exclude	......1.................1..1....	before	2
exclude	......1....................1....	since	2
asm	{L?ldr:str}{cond(c)}{B?b:}{T?t:} r{t}, [r{n}], {adr_operand()}
asm.ual	{L?ldr:str}{B?b:}{T?t:}{cond(c)} r{t}, [r{n}], {adr_operand()}
added	1
begin
	// ldr/str/ldrt/strt
	if($c[${c}])
	{
		uint32_t offset = ${adr_operand()};

		if(${L!test})
		{
			if(${B!test})
			{
				$r.v5[${t}] = a32_ldrb(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, ${T!test});
			}
			else
			{
				$r.v5[${t}] = a32_ldr(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, ${T!test});
			}
		}
		else
		{
			if(${B!test})
			{
				a32_strb(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, ${T!test});
			}
			else
			{
				a32_str(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, ${T!test});
			}
		}
	}
end

code	cccc100PUSWLnnnnllllllllllllllll
exclude	1111............................	since	5
asm	{L?ldm:stm}{cond(c)}{U?i:d}{P?b:a} r{n}{W?!:}, {reglist(l)}{S?^:}
asm.ual	{L?ldm:stm}{U?i:d}{P?b:a}{cond(c)} r{n}{W?!:}, {reglist(l)}{S?^:}
added	1
begin
	// ldm/stm
	if($c[${c}])
	{
		if(${L!test})
		{
			a32_ldm(cpu, ${l}, ${n}, ${U!test}, ${P!test}, ${W!test}, ${S!test});
		}
		else
		{
			a32_stm(cpu, ${l}, ${n}, ${U!test}, ${P!test}, ${W!test}, ${S!test});
		}
	}
end

#### Branch instruction

code	cccc101Ldddddddddddddddddddddddd
exclude	1111............................	since	5
asm	b{L?l:}{cond(c)} {signextend d'00!offset}
added	1
begin
	// b/bl
	if($c[${c}])
	{
		if(${L!test})
		{
			$lr = $pc.cpsr - 4;
		}
		$pc = ${signextend d'00!offset};
	}
end

code	cccc1111iiiiiiiiiiiiiiiiiiiiiiii
exclude	1111............................	since	5
asm	swi{cond(c)} #{i:X}
asm.ual	svc{cond(c)} #{i:X}
added	1
begin
	// swi
	if($c[${c}])
	{
		$pc = $pc_next;
		arm_svc(cpu);
	}
end

#### ARMv2
#### Multiplication

code	cccc0000000Sdddd????ssss1001mmmm
exclude	1111............................	since	5
asm	mul{cond(c)}{S?s:} r{d}, r{m}, r{s}
asm.ual	mul{S?s:}{cond(c)} r{d}, r{m}, r{s}
added	2
begin
	// mul
	if($c[${c}])
	{
		$r[${d}] = a32_mul32(cpu, $r[${m}], $r[${s}], ${S!test});
	}
end

code	cccc0000001Sddddnnnnssss1001mmmm
exclude	1111............................	since	5
asm	mla{cond(c)}{S?s:} r{d}, r{m}, r{s}, r{n}
asm.ual	mla{S?s:}{cond(c)} r{d}, r{m}, r{s}, r{n}
added	2
begin
	// mla
	if($c[${c}])
	{
		$r[${d}] = a32_mla32(cpu, $r[${m}], $r[${s}], $r[${n}], ${S!test});
	}
end

#### Coprocessor

code	cccc1110aaaannnnddddCCCCbbb0mmmm
exclude	1111............................	since	5
asm	cdp{cond(c)} {C}, {a}, cr{d}, cr{n}, cr{m}, {b}
coproc	cdp
added	2
begin
	// cdp
	if($c[${c}])
	{
		a32_perform_cdp(cpu, opcode);
	}
end

code	11111110aaaannnnddddCCCCbbb0mmmm
asm	cdp2 {C}, {a}, cr{d}, cr{n}, cr{m}, {b}
coproc	cdp
added	5T
begin
	// cdp2
	a32_perform_cdp(cpu, opcode);
end

code	cccc1101UNWLnnnnddddCCCCoooooooo
exclude	1111............................	since	5
asm	{L?ldc:stc}{cond(c)}{N?l:} {C}, cr{d}, [r{n}, #{U?:-}{o'00:X}]{W?!:}
asm.ual	{L?ldc:stc}{N?l:}{cond(c)} {C}, cr{d}, [r{n}, {U?:-}{o'00:X}]{W?!:}
coproc	ldc
added	2
begin
	// ldc/stc
	if($c[${c}])
	{
		uint32_t offset = ${o'00};

		a32_perform_ldc_stc(cpu, opcode, ${n}, offset, PREINDEXED, ${W!test});
	}
end

code	cccc1100UN1LnnnnddddCCCCoooooooo
exclude	1111............................	since	5
asm	{L?ldc:stc}{cond(c)}{N?l:} {C}, cr{d}, [r{n}], #{U?:-}{o'00:X}
asm.ual	{L?ldc:stc}{N?l:}{cond(c)} {C}, cr{d}, [r{n}], {U?:-}{o'00:X}
coproc	ldc
added	2
begin
	// ldc/stc
	if($c[${c}])
	{
		uint32_t offset = ${o'00};

		a32_perform_ldc_stc(cpu, opcode, ${n}, offset, POSTINDEXED, WRITEBACK);
	}
end

code	cccc11001N0LnnnnddddCCCCoooooooo
exclude	1111............................	since	5
asm	{L?ldc:stc}{cond(c)}{N?l:} {C}, cr{d}, [r{n}], {o}
asm.ual	{L?ldc:stc}{N?l:}{cond(c)} {C}, cr{d}, [r{n}], {o}
coproc	ldc
added	2
begin
	// ldc/stc
	if($c[${c}])
	{
		a32_perform_ldc_stc(cpu, opcode, ${n}, 0, NOINDEX, NOWRITEBACK);
	}
end

code	11111101UNWLnnnnddddCCCCoooooooo
asm	{L?ldc:stc}2{N?l:} {C}, cr{d}, [r{n}, #{U?:-}{o'00:X}]{W?!:}
coproc	ldc
added	5T
begin
	// ldc2/stc2

	uint32_t offset = ${o'00};

	a32_perform_ldc_stc(cpu, opcode, ${n}, offset, PREINDEXED, ${W!test});
end

code	11111100UN1LnnnnddddCCCCoooooooo
asm	{L?ldc:stc}2{N?l:} {C}, cr{d}, [r{n}], #{U?:-}{o'00:X}
coproc	ldc
added	5T
begin
	// ldc2/stc2

	uint32_t offset = ${o'00};

	a32_perform_ldc_stc(cpu, opcode, ${n}, offset, POSTINDEXED, WRITEBACK);
end

code	111111001N0LnnnnddddCCCCoooooooo
asm	{L?ldc:stc}2{N?l:} {C}, cr{d}, [r{n}], {o}
coproc	ldc
added	5T
begin
	// ldc2/stc2

	a32_perform_ldc_stc(cpu, opcode, ${n}, 0, NOINDEX, NOWRITEBACK);
end

code	cccc1110aaa0nnnnddddCCCCbbb1mmmm
exclude	1111............................	since	5
asm	mcr{cond(c)} {C}, {a}, r{d}, cr{n}, cr{m}, {b}
coproc	mcr
added	2
begin
	// mcr
	if($c[${c}])
	{
		a32_perform_mcr(cpu, opcode, ${d});
	}
end

code	11111110aaa0nnnnddddCCCCbbb1mmmm
asm	mcr2 {C}, {a}, r{d}, cr{n}, cr{m}, {b}
coproc	mcr
added	5T
begin
	// mcr2

	a32_perform_mcr(cpu, opcode, ${d});
end

code	cccc1110aaa1nnnnddddCCCCbbb1mmmm
exclude	1111............................	since	5
asm	mrc{cond(c)} {C}, {a}, r{d}, cr{n}, cr{m}, {b}
coproc	mrc
added	2
begin
	// mrc
	if($c[${c}])
	{
		a32_perform_mrc(cpu, opcode, ${d});
	}
end

code	11111110aaa1nnnnddddCCCCbbb1mmmm
asm	mrc2 {C}, {a}, r{d}, cr{n}, cr{m}, {b}
coproc	mrc
added	5T
begin
	// mrc2

	a32_perform_mrc(cpu, opcode, ${d});
end

#### ARMv2a

code	cccc00010B00nnnndddd!!!!1001mmmm
exclude	1111............................	since	5
asm	swp{cond(c)}{B?b:} r{d}, r{m}, r{n}
asm.ual	swp{B?b:}{cond(c)} r{d}, r{m}, r{n}
added	2a
begin
	// swp
	if($c[${c}])
	{
		if(${B!test})
		{
			uint8_t value = a32_read8(cpu, $r[${n}]);
			a32_write8(cpu, $r[${n}], $r[${m}]);
			$r[${d}] = value;
		}
		else
		{
			uint32_t address = $r[${n}];
			uint32_t value;

			if(cpu->config.version <= ARMV6 && !(cpu->sctlr_el1 & SCTLR_U))
			{
				value = rotate_right32(a32_read32(cpu, address & ~3), (address & 3) * 8);
			}
			else
			{
				if((address & 3) != 0)
					arm_unaligned(cpu);
				value = a32_read32(cpu, address);
			}

			a32_write32(cpu, $r[${n}] & ~3, $r[${m}]);
			$r[${d}] = value;
		}
	}
end

#### ARMv3
#### Status register access

code	cccc00010S00!!!!dddd@@@@0000@@@@
exclude	1111............................
asm	mrs{cond(c)} r{d}, {S?s:c}psr
added	3
begin
	// mrs
	if($c[${c}])
	{
		if(${S!test})
			$r[${d}] = $spsr;
		else
			$r[${d}] = $cpsr;
	}
end

code	cccc00010S10FXsC!!!!@@0@0000nnnn
exclude	1111............................
asm	msr{cond(c)} {S?s:c}psr_{F?f:}{X?x:}{s?s:}{C?c:}, r{n}
added	3
begin
	// msr
	if($c[${c}])
	{
		if(${S!test})
			a32_set_spsr(cpu, get_cpsr_spsr_mask(${F!test}, ${X!test}, ${s!test}, ${C!test}), $r[${n}]);
		else
			a32_set_cpsr(cpu, get_cpsr_spsr_mask(${F!test}, ${X!test}, ${s!test}, ${C!test}), $r[${n}]);
	}
end

code	cccc00110S10FXsC!!!!iiiiiiiiiiii
exclude	1111............................
asm	msr{cond(c)} {S?s:c}psr_{F?f:}{X?x:}{s?s:}{C?c:}, #{immed()}
added	3
begin
	// msr
	if($c[${c}])
	{
		if(${S!test})
			a32_set_spsr(cpu, get_cpsr_spsr_mask(${F!test}, ${X!test}, ${s!test}, ${C!test}), ${operand()});
		else
			a32_set_cpsr(cpu, get_cpsr_spsr_mask(${F!test}, ${X!test}, ${s!test}, ${C!test}), ${operand()});
	}
end

#### ARMv3M, ARMv4 (except ARMv4xM, ARMv5xM)
#### Long multiplication

code	cccc00001uaSnnnnddddssss1001mmmm
exclude	1111............................
asm	{u?s:u}{a?mla:mul}{cond(c)}{S?s:} r{d}, r{n}, r{m}, r{s}
asm.ual	{u?s:u}{a?mla:mul}{S?s:}{cond(c)} r{d}, r{n}, r{m}, r{s}
added	3M
begin
	// smull/umull/smlal/umlal
	if($c[${c}])
	{
		if(${u!test})
		{
			a32_smlal32(cpu, ${d}, ${n}, $r[${m}], $r[${s}], ${S!test}, ${a!test});
		}
		else
		{
			a32_umlal32(cpu, ${d}, ${n}, $r[${m}], $r[${s}], ${S!test}, ${a!test});
		}
	}
end

#### Explicitly undefined instructions in ARMv1/ARMv2/ARMv3

# shift by register addressing modes for memory instructions removed from v2
code	cccc011.................1..1....
asm	udf{cond(c)}
added	1
removed	2
begin
	// undefined
	if($c[${c}])
	{
		arm_undefined(cpu);
	}
end

# v4 explicitly renders all undefined bit sequences undefined, so they do not need to be listed separately
code	cccc011....................1....
asm	udf{cond(c)}
added	2
removed	4
begin
	// undefined
	if($c[${c}])
	{
		arm_undefined(cpu);
	}
end

# replaced with SWP/SWPB
code	cccc0001................1..1....
asm	udf{cond(c)}
added	1
removed	2a
begin
	// undefined
	if($c[${c}])
	{
		arm_undefined(cpu);
	}
end

#### ARMv4
#### Halfword and signed load/store

code	cccc0001U0WLnnnntttt@@@@1SH1mmmm
exclude	1111............................
exclude	...........0.............1......
exclude	...........0..............0.....
asm	{L?ldr:str}{cond(c)}{S?s:}{H?h:b} r{t}, [r{n}, {U?:-}r{m}]{W?!:}
asm.ual	{L?ldr:str}{S?s:}{H?h:b}{cond(c)} r{t}, [r{n}, {U?:-}r{m}]{W?!:}
added	4
begin
	// ldrh/strh/ldrsh/strsh/ldrsb/strsb
	if($c[${c}])
	{
		uint32_t offset = $r[${m}];
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${L!test})
		{
			if(!${H!test})
			{
				$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
			else if(!${S!test})
			{
				$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
			else
			{
				$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
		}
		else
		{
			a32_strh(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
		}
	}
end

code	cccc0000U00Lnnnntttt@@@@1SH1mmmm
exclude	1111............................
exclude	...........0.............1......
exclude	...........0..............0.....
asm	{L?ldr:str}{cond(c)}{S?s:}{H?h:b} r{t}, [r{n}], {U?:-}r{m}
asm.ual	{L?ldr:str}{S?s:}{H?h:b}{cond(c)} r{t}, [r{n}], {U?:-}r{m}
added	4
begin
	// ldrh/strh/ldrsh/strsh/ldrsb/strsb
	if($c[${c}])
	{
		uint32_t offset = $r[${m}];
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${L!test})
		{
			if(!${H!test})
			{
				$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
			}
			else if(!${S!test})
			{
				$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
			}
			else
			{
				$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
			}
		}
		else
		{
			a32_strh(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
		}
	}
end

code	cccc0001U1WLnnnnttttiiii1SH1iiii
exclude	1111............................
exclude	...........0.............1......
exclude	...........0..............0.....
asm	{L?ldr:str}{cond(c)}{S?s:}{H?h:b} r{t}, [r{n}, #{U?:-}{i:X}]{W?!:}
asm.ual	{L?ldr:str}{S?s:}{H?h:b}{cond(c)} r{t}, [r{n}, #{U?:-}{i:X}]{W?!:}
added	4
begin
	// ldrh/strh/ldrsh/strsh/ldrsb/strsb
	if($c[${c}])
	{
		uint32_t offset = ${i};
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${L!test})
		{
			if(!${H!test})
			{
				$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
			else if(!${S!test})
			{
				$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
			else
			{
				$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
		}
		else
		{
			a32_strh(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
		}
	}
end

code	cccc0000U1WLnnnnttttiiii1SH1iiii
exclude	1111............................
exclude	...........0.............1......
exclude	...........0..............0.....
asm	{L?ldr:str}{cond(c)}{S?s:}{H?h:b} r{t}, [r{n}], #{U?:-}{i:X}
asm.ual	{L?ldr:str}{S?s:}{H?h:b}{cond(c)} r{t}, [r{n}], #{U?:-}{i:X}
added	4
begin
	// ldrh/strh/ldrsh/strsh/ldrsb/strsb
	if($c[${c}])
	{
		uint32_t offset = ${i};
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${L!test})
		{
			if(!${H!test})
			{
				$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
			}
			else if(!${S!test})
			{
				$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
			}
			else
			{
				$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
			}
		}
		else
		{
			a32_strh(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
		}
	}
end

code	cccc001100100000!!!!@@@@00010100
exclude	1111............................
asm	csdb{cond(c)}
# TODO: unsure
added	4
begin
	// csdb
end

#### ARMv4T
#### Branch between instruction sets

# since this is also supported on ARMv5 with no Thumb support, it is easier to encode this as ARMv4T only, and separately as ARMv5
code	cccc00010010!!!!!!!!!!!!0001mmmm
exclude	1111............................
asm	bx{cond(c)} r{m}
added	4T
removed	5
begin
	// bx
	if($c[${c}])
	{
		$cpsr.thumb = $r[${m}] & 1; // must be set first for proper alignment
		$pc = $r[${m}];
	}
end

# the bx instruction is also part of ARMv4T
code	cccc00010010!!!!!!!!!!!!00L1mmmm
exclude	1111............................
asm	b{L?l:}x{cond(c)} r{m}
added	5
begin
	// bx/blx
	if($c[${c}])
	{
		if(${L!test})
		{
			$lr = $pc.cpsr - 4;
		}
		if((cpu->config.features & (1 << FEATURE_THUMB)))
			$cpsr.thumb = $r[${m}] & 1; // must be set first for proper alignment
		$pc = $r[${m}];
	}
end

#code	111001111111iiiiiiiiiiii1111iiii
#asm	udf #{i:X}
#added	4T
#begin
#	// udf
#	arm_undefined(cpu);
#end

#### ARMv5

code	cccc00010110!!!!dddd!!!!0001mmmm
exclude	1111............................
asm	clz{cond(c)} r{d}, r{m}
added	5
begin
	// clz
	if($c[${c}])
	{
		$r[${d}] = clz32($r[${m}]);
	}
end

code	cccc00010010iiiiiiiiiiii0111iiii
exclude	1111............................
asm	bkpt #{i:4X}
added	5
begin
	// bkpt
	if($c[${c}])
	{
		$pc = $pc_next;
		arm_breakpoint(cpu);
	}
end

#### ARMv5T

code	1111101Hiiiiiiiiiiiiiiiiiiiiiiii
asm	blx {signextend i'H'0!offset}
added	5T
begin
	// blx
	$lr = $pc_next;
	uint32_t target = ${signextend i'H'0!offset};
	$cpsr.thumb = true; // must be set first for proper alignment
	$pc = target;
end

#### ARMv5TE, ARMv5TExP

code	cccc00010000nnnndddd@@@@0101mmmm
exclude	1111............................
asm	qadd{cond(c)} r{d}, r{m}, r{n}
added	5TExP
begin
	// qadd
	if($c[${c}])
	{
		$r[${d}] = a32_qadd32(cpu, $r[${m}], $r[${n}]);
	}
end

code	cccc00010100nnnndddd@@@@0101mmmm
exclude	1111............................
asm	qdadd{cond(c)} r{d}, r{m}, r{n}
added	5TExP
begin
	// qdadd
	if($c[${c}])
	{
		$r[${d}] = a32_qdadd32(cpu, $r[${m}], $r[${n}]);
	}
end

code	cccc00010110nnnndddd@@@@0101mmmm
exclude	1111............................
asm	qdsub{cond(c)} r{d}, r{m}, r{n}
added	5TExP
begin
	// qdsub
	if($c[${c}])
	{
		$r[${d}] = a32_qdsub32(cpu, $r[${m}], $r[${n}]);
	}
end

code	cccc00010010nnnndddd@@@@0101mmmm
exclude	1111............................
asm	qsub{cond(c)} r{d}, r{m}, r{n}
added	5TExP
begin
	// qsub
	if($c[${c}])
	{
		$r[${d}] = a32_qsub32(cpu, $r[${m}], $r[${n}]);
	}
end

code	cccc00010000ddddnnnnssss1yx0mmmm
exclude	1111............................
asm	smla{x?t:b}{y?t:b}{cond(c)} r{d}, r{m}, r{s}, r{n}
added	5TExP
begin
	// smla
	if($c[${c}])
	{
		$r[${d}] = a32_smla32(cpu, ${x!test} ? $r[${m}] >> 16 : $r[${m}], ${y!test} ? $r[${s}] >> 16 : $r[${s}], $r[${n}]);
	}
end

code	cccc00010110dddd@@@@ssss1yx0mmmm
exclude	1111............................
asm	smul{x?t:b}{y?t:b}{cond(c)} r{d}, r{m}, r{s}
added	5TExP
begin
	// smul
	if($c[${c}])
	{
		$r[${d}] = a32_smul32(cpu, ${x!test} ? $r[${m}] >> 16 : $r[${m}], ${y!test} ? $r[${s}] >> 16 : $r[${s}]);
	}
end

code	cccc00010100hhhhllllssss1yx0mmmm
exclude	1111............................
asm	smlal{x?t:b}{y?t:b}{cond(c)} r{l}, r{h}, r{m}, r{s}
added	5TExP
begin
	// smlal
	if($c[${c}])
	{
		a32_smlal64(cpu, ${l}, ${h}, ${x!test} ? $r[${m}] >> 16 : $r[${m}], ${y!test} ? $r[${s}] >> 16 : $r[${s}]);
	}
end

code	cccc00010010ddddnnnnssss1y00mmmm
exclude	1111............................
asm	smlaw{y?t:b}{cond(c)} r{d}, r{m}, r{s}, r{n}
added	5TExP
begin
	// smlaw
	if($c[${c}])
	{
		$r[${d}] = a32_smlaw32(cpu, $r[${m}], ${y!test} ? $r[${s}] >> 16 : $r[${s}], $r[${n}]);
	}
end

code	cccc00010010dddd@@@@ssss1y10mmmm
exclude	1111............................
asm	smulw{y?t:b}{cond(c)} r{d}, r{m}, r{s}
added	5TExP
begin
	// smulw
	if($c[${c}])
	{
		$r[${d}] = a32_smulw32(cpu, $r[${m}], ${y!test} ? $r[${s}] >> 16 : $r[${s}]);
	}
end

#### ARMv5TE

code	cccc0001U0W0nnnntttt@@@@11H1mmmm
exclude	1111............................
exclude	...................1............
asm	{H?str:ldr}{cond(c)}d r{t}, [r{n}, {U?:-}r{m}]{W?!:}
asm.ual	{H?str:ldr}d{cond(c)} r{t}, [r{n}, {U?:-}r{m}]{W?!:}
added	5TE
begin
	// ldrd/strd
	if($c[${c}])
	{
		uint32_t offset = $r[${m}];
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${H!test})
		{
			a32_ldrd(cpu, ${t}, ${t} + 1, ${n}, offset, PREINDEXED, ${W!test});
		}
		else
		{
			a32_strd(cpu, ${t}, ${t} + 1, ${n}, offset, PREINDEXED, ${W!test});
		}
	}
end

code	cccc0000U000nnnntttt@@@@11H1mmmm
exclude	1111............................
exclude	...................1............
asm	{H?str:ldr}{cond(c)}d r{t}, [r{n}], {U?:-}r{m}
asm.ual	{H?str:ldr}d{cond(c)} r{t}, [r{n}], {U?:-}r{m}
added	5TE
begin
	// ldrd/strd
	if($c[${c}])
	{
		uint32_t offset = $r[${m}];
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${H!test})
		{
			a32_ldrd(cpu, ${t}, ${t} + 1, ${n}, offset, POSTINDEXED, WRITEBACK);
		}
		else
		{
			a32_strd(cpu, ${t}, ${t} + 1, ${n}, offset, POSTINDEXED, WRITEBACK);
		}
	}
end

code	cccc0001U1W0nnnnttttiiii11H1iiii
exclude	1111............................
exclude	...................1............
asm	{H?str:ldr}{cond(c)}d r{t}, [r{n}, #{U?:-}{i:X}]{W?!:}
asm.ual	{H?str:ldr}d{cond(c)} r{t}, [r{n}, #{U?:-}{i:X}]{W?!:}
added	5TE
begin
	// ldrd/strd
	if($c[${c}])
	{
		uint32_t offset = ${operand()};
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${H!test})
		{
			a32_ldrd(cpu, ${t}, ${t} + 1, ${n}, offset, PREINDEXED, ${W!test});
		}
		else
		{
			a32_strd(cpu, ${t}, ${t} + 1, ${n}, offset, PREINDEXED, ${W!test});
		}
	}
end

code	cccc0000U1W0nnnnttttiiii11H1iiii
exclude	1111............................
exclude	...................1............
asm	{H?str:ldr}{cond(c)}d r{t}, [r{n}], #{U?:-}{i:X}
asm.ual	{H?str:ldr}d{cond(c)} r{t}, [r{n}], #{U?:-}{i:X}
added	5TE
begin
	// ldrd/strd
	if($c[${c}])
	{
		uint32_t offset = ${operand()};
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${H!test})
		{
			a32_ldrd(cpu, ${t}, ${t} + 1, ${n}, offset, POSTINDEXED, WRITEBACK);
		}
		else
		{
			a32_strd(cpu, ${t}, ${t} + 1, ${n}, offset, POSTINDEXED, WRITEBACK);
		}
	}
end

code	cccc11000100TTTTttttCCCCaaaammmm
exclude	1111............................
asm	mcrr{cond(c)} {C}, {a}, r{t}, r{T}, cr{m}
coproc	mcrr
added	5TE
begin
	// mcrr
	if($c[${c}])
	{
		a32_perform_mcrr(cpu, opcode, ${t}, ${T});
	}
end

code	111111000100TTTTttttCCCCaaaammmm
asm	mcrr2 {C}, {a}, r{t}, r{T}, cr{m}
coproc	mcrr
added	6
begin
	// mcrr2

	a32_perform_mcrr(cpu, opcode, ${t}, ${T});
end

code	cccc11000101TTTTttttCCCCaaaammmm
exclude	1111............................
asm	mrrcc{cond(c)} {C}, {a}, r{t}, r{T}, cr{m}
coproc	mrrc
added	5TE
begin
	// mrrc
	if($c[${c}])
	{
		a32_perform_mrrc(cpu, opcode, ${t}, ${T});
	}
end

code	111111000101TTTTttttCCCCaaaammmm
asm	mrrc2 {C}, {a}, r{t}, r{T}, cr{m}
coproc	mrrc
added	6
begin
	// mrrc2

	a32_perform_mrrc(cpu, opcode, ${t}, ${T});
end

code	11110101U101nnnn1111!!!!iiiiiiii
asm	pld [r{n}, #{U?:-}{i:X}]
added	5TE
begin
	// pld
end

code	11110111U101nnnn!!!!HHHHHHH0mmmm
asm	pld [r{n}, {adr_operand()}]
added	5TE
begin
	// pld
end

code	11110101U001nnnn1111!!!!iiiiiiii
asm	pldw [r{n}, #{U?:-}{i:X}]
added	7+mp
begin
	// pldw
end

code	11110111U001nnnn!!!!HHHHHHH0mmmm
asm	pldw [r{n}, {adr_operand()}]
added	7+mp
begin
	// pldw
end

#### ARMv5TEJ
#### Jazelle transition

code	cccc00010010!!!!!!!!!!!!0010mmmm
exclude	1111............................
asm	bxj{cond(c)} r{m}
added	5TEJ
begin
	// bxj
	if($c[${c}])
	{
		a32_bxj(cpu, $r[${m}]);
	}
end

#### ARMv6

code	1111000100001D00@@@@@@@AIF0@@@@@
asm	cpsi{D?d:e} {A?a:}{I?i:}{F?f:}
added	6
begin
	// cps
	if(${A!test})
		$cpsr.a = ${D};
	if(${I!test})
		$cpsr.i = ${D};
	if(${F!test})
		$cpsr.f = ${D};
end

code	1111000100001D10@@@@@@@AIF0MMMMM
exclude	.......................000......
asm	cpsi{D?d:e} {A?a:}{I?i:}{F?f:}, #{M}
added	6
begin
	// cps
	if(${A!test})
		$cpsr.a = ${D};
	if(${I!test})
		$cpsr.i = ${D};
	if(${F!test})
		$cpsr.f = ${D};
	$cpsr.mode = ${M};
end

code	1111000100001@10@@@@@@@0000MMMMM
asm	cps #{M}
added	6
begin
	// cps
	$cpsr.mode = ${M};
end

code	cccc00011001nnnndddd!!!!1001!!!!
exclude	1111............................
asm	ldrex{cond(c)} r{d}, [r{n}]
added	6
begin
	// ldrex
	if($c[${c}])
	{
		$r.v5[${d}] = a32_ldrex(cpu, ${n}, 0);
	}
end

code	cccc00011000nnnndddd!!!!1001tttt
exclude	1111............................
asm	strex{cond(c)} r{d}, r{t}, [r{n}]
added	6
begin
	// strex
	if($c[${c}])
	{
		$r[${d}] = a32_strex(cpu, $r.str[${t}], ${n}, 0);
	}
end

code	cccc01101000nnnnddddiiiii001mmmm
exclude	1111............................
asm	pkhbt{cond(c)} r{d}, r{n}, r{m}, lsl #{i}
added	6
begin
	// pkhbt
	if($c[${c}])
	{
		$r[${d}] = ($r[${n}] & 0x0000FFFF) | (($r[${m}] << ${i}) & 0xFFFF0000);
	}
end

code	cccc01101000nnnnddddiiiii101mmmm
exclude	1111............................
asm	pkhtb{cond(c)} r{d}, r{n}, r{m}, asr #{positive(i)}
added	6
begin
	// pkhtb
	if($c[${c}])
	{
		if(${i} == 0)
			$r[${d}] = ($r[${n}] & 0xFFFF0000) | ($r[${m}] & 0x80000000 ? 0xFFFF0000 : 0);
		else
			$r[${d}] = ($r[${n}] & 0xFFFF0000) | (((int32_t)$r[${m}] >> ${i}) & 0xFFFF0000);
	}
end

code	cccc01100U10nnnndddd!!!!0001mmmm
exclude	1111............................
asm	{U?u:}qadd16{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// qadd16/uqadd16
	if($c[${c}])
	{
		if(${U!test})
			$r[${d}] = qadd16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)qadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		else
			$r[${d}] = uqadd16($r[${n}], $r[${m}]) | ((uint32_t)uqadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
	}
end

code	cccc01100U10nnnndddd!!!!1001mmmm
exclude	1111............................
asm	{U?u:}qadd8{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// qadd8/uqadd8
	if($c[${c}])
	{
		if(${U!test})
			$r[${d}] = qadd8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)qadd8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)qadd8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)qadd8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
		else
			$r[${d}] = uqadd8($r[${n}], $r[${m}]) | ((uint32_t)uqadd8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)uqadd8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)uqadd8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
	}
end

code	cccc01100U10nnnndddd!!!!0011mmmm
exclude	1111............................
asm	{U?u:s}qaddsubx{cond(c)} r{d}, r{n}, r{m}
asm.ual	{U?u:s}qasx{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// qaddsubx/uqaddsubx or qasx/uqasx
	if($c[${c}])
	{
		if(${U!test})
			$r[${d}] = uqsub16($r[${n}], $r[${m}] >> 16) | ((uint32_t)uqadd16($r[${n}] >> 16, $r[${m}]) << 16);
		else
			$r[${d}] = qsub16($r[${n}], $r[${m}] >> 16) | ((uint32_t)(uint16_t)qadd16($r[${n}] >> 16, $r[${m}]) << 16);
	}
end

code	cccc01100U10nnnndddd!!!!0111mmmm
exclude	1111............................
asm	{U?u:s}qsub16{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// qsub16/uqsub16
	if($c[${c}])
	{
		if(${U!test})
			$r[${d}] = qsub16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)qsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		else
			$r[${d}] = uqsub16($r[${n}], $r[${m}]) | ((uint32_t)uqsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
	}
end

code	cccc01100U10nnnndddd!!!!1111mmmm
exclude	1111............................
asm	{U?u:s}qsub8{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// qsub8/uqsub8
	if($c[${c}])
	{
		if(${U!test})
			$r[${d}] = qsub8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)qsub8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)qsub8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)qsub8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
		else
			$r[${d}] = uqsub8($r[${n}], $r[${m}]) | ((uint32_t)uqsub8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)uqsub8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)uqsub8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
	}
end

code	cccc01100U10nnnndddd!!!!0101mmmm
exclude	1111............................
asm	{U?u:s}qsubaddx{cond(c)} r{d}, r{n}, r{m}
asm.ual	{U?u:s}qsax{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// qsubaddx/uqsubaddx or qsax/uqsax
	if($c[${c}])
	{
		if(${U!test})
			$r[${d}] = uqadd16($r[${n}], $r[${m}] >> 16) | ((uint32_t)uqsub16($r[${n}] >> 16, $r[${m}]) << 16);
		else
			$r[${d}] = qadd16($r[${n}], $r[${m}] >> 16) | ((uint32_t)(uint16_t)qsub16($r[${n}] >> 16, $r[${m}]) << 16);
	}
end

code	cccc01101011!!!!dddd!!!!0011mmmm
exclude	1111............................
asm	rev{cond(c)} r{d}, r{m}
added	6
begin
	// rev
	if($c[${c}])
	{
		$r[${d}] = bswap_32($r[${m}]);
	}
end

code	cccc01101011!!!!dddd!!!!1011mmmm
exclude	1111............................
asm	rev16{cond(c)} r{d}, r{m}
added	6
begin
	// rev16
	if($c[${c}])
	{
		uint32_t value = $r[${m}];
		$r[${d}] = bswap_32_16(value);
	}
end

code	cccc01101111!!!!dddd!!!!1011mmmm
exclude	1111............................
asm	revsh{cond(c)} r{d}, r{m}
added	6
begin
	// revsh
	if($c[${c}])
	{
		$r[${d}] = sign_extend(16, bswap_16($r[${m}]));
	}
end

code	1111100PU0W1nnnn@@@@1010@@@@@@@@
asm	rfe{U?i:d}{P?b:a} r{n}{W?!:}
added	6
begin
	// rfe
	a32_rfe(cpu, ${n}, ${U!test}, ${P!test}, ${W!test});
end

code	cccc01100UH1nnnndddd!!!!0001mmmm
exclude	1111............................
asm	{U?u:s}{H?h:}add16{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// sadd16/uadd16/shadd16/uhadd16
	if($c[${c}])
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhadd16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_uhadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
			else
				$r[${d}] = a32_shadd16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_shadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_uadd16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_uadd16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
			else
				$r[${d}] = a32_sadd16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_sadd16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
		}
	}
end

code	cccc01100UH1nnnndddd!!!!1001mmmm
exclude	1111............................
asm	{U?u:s}{H?h:}add8{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// sadd8/uadd8/shadd8/uhadd8
	if($c[${c}])
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhadd8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)a32_uhadd8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)a32_uhadd8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)a32_uhadd8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
			else
				$r[${d}] = a32_shadd8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)a32_shadd8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)a32_shadd8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)a32_shadd8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_uadd8(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint8_t)a32_uadd8(cpu, $r[${n}] >> 8, $r[${m}] >> 8, 1) << 8) | ((uint32_t)(uint8_t)a32_uadd8(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16) | ((uint32_t)(uint8_t)a32_uadd8(cpu, $r[${n}] >> 24, $r[${m}] >> 24, 3) << 24);
			else
				$r[${d}] = a32_sadd8(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint8_t)a32_sadd8(cpu, $r[${n}] >> 8, $r[${m}] >> 8, 1) << 8) | ((uint32_t)(uint8_t)a32_sadd8(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16) | ((uint32_t)(uint8_t)a32_sadd8(cpu, $r[${n}] >> 24, $r[${m}] >> 24, 3) << 24);
		}
	}
end

code	cccc01100UH1nnnndddd!!!!0011mmmm
exclude	1111............................
asm	{U?u:s}{H?h:}addsubx{cond(c)} r{d}, r{n}, r{m}
asm.ual	{U?u:s}{H?h:}asx{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// saddsubx/uaddsubx/shaddsubx/uhaddsubx or sasx/uasx/shasx/uhasx
	if($c[${c}])
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhsub16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_uhadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
			else
				$r[${d}] = a32_shsub16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_shadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_usub16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_uadd16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
			else
				$r[${d}] = a32_ssub16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_sadd16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
		}
	}
end

code	cccc01100UH1nnnndddd!!!!0111mmmm
exclude	1111............................
asm	{U?u:s}{H?h:}sub16{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// ssub16/usub16/shsub16/uhsub16
	if($c[${c}])
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhsub16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_uhsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
			else
				$r[${d}] = a32_shsub16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_shsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_usub16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_usub16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
			else
				$r[${d}] = a32_ssub16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_ssub16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
		}
	}
end

code	cccc01100UH1nnnndddd!!!!1111mmmm
exclude	1111............................
asm	{U?u:s}{H?h:}sub8{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// ssub8/usub8/shsub8/uhsub8
	if($c[${c}])
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhsub8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)a32_uhsub8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)a32_uhsub8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)a32_uhsub8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
			else
				$r[${d}] = a32_shsub8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)a32_shsub8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)a32_shsub8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)a32_shsub8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_usub8(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint8_t)a32_usub8(cpu, $r[${n}] >> 8, $r[${m}] >> 8, 1) << 8) | ((uint32_t)(uint8_t)a32_usub8(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16) | ((uint32_t)(uint8_t)a32_usub8(cpu, $r[${n}] >> 24, $r[${m}] >> 24, 3) << 24);
			else
				$r[${d}] = a32_ssub8(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint8_t)a32_ssub8(cpu, $r[${n}] >> 8, $r[${m}] >> 8, 1) << 8) | ((uint32_t)(uint8_t)a32_ssub8(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16) | ((uint32_t)(uint8_t)a32_ssub8(cpu, $r[${n}] >> 24, $r[${m}] >> 24, 3) << 24);
		}
	}
end

code	cccc01100UH1nnnndddd!!!!0101mmmm
exclude	1111............................
asm	{U?u:s}{H?h:}subaddx{cond(c)} r{d}, r{n}, r{m}
asm.ual	{U?u:s}{H?h:}sax{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// ssubaddx/usubaddx/shsubaddx/uhsubaddx or ssax/usax/shsax/uhsax
	if($c[${c}])
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhadd16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_uhsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
			else
				$r[${d}] = a32_shadd16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_shsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_uadd16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_usub16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
			else
				$r[${d}] = a32_sadd16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_ssub16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
		}
	}
end

code	cccc01101000nnnndddd!!!!1011mmmm
exclude	1111............................
asm	sel{cond(c)} r{d}, r{n}, r{m}
added	6
begin
	// sel
	if($c[${c}])
	{
		uint32_t a = $r[${n}];
		uint32_t b = $r[${m}];
		uint32_t value = 0;
		value |= ($cpsr.ge0 ? a : b) & 0x000000FF;
		value |= ($cpsr.ge1 ? a : b) & 0x0000FF00;
		value |= ($cpsr.ge2 ? a : b) & 0x00FF0000;
		value |= ($cpsr.ge3 ? a : b) & 0xFF000000;
		$r[${d}] = value;
	}
end

code	1111000100000001@@@@E@@@0000@@@@
asm	setend {E?B:L}E
added	6
begin
	// setend
	$cpsr.e = ${E};
end

code	cccc01110L00ddddnnnnssss0SX1mmmm
exclude	1111............................
exclude	................1111............
asm	sml{S?s:a}{L?l:}d{X?x:}{cond(c)} r{d}, r{m}, r{s}, r{n}
added	6
begin
	// smlad/smlsd/smlald/smlsd
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01110101ddddnnnnssss00R1mmmm
exclude	1111............................
exclude	................1111............
asm	smmla{R?r:}{cond(c)} r{d}, r{m}, r{s}, r{n}
added	6
begin
	// smmla
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01110101ddddnnnnssss11R1mmmm
exclude	1111............................
asm	smmls{R?r:}{cond(c)} r{d}, r{m}, r{s}, r{n}
added	6
begin
	// smmls
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01110101dddd1111ssss00R1mmmm
exclude	1111............................
asm	smmul{R?r:}{cond(c)} r{d}, r{m}, r{s}
added	6
begin
	// smmul
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01110000dddd1111ssss00X1mmmm
exclude	1111............................
asm	smuad{X?x:}{cond(c)} r{d}, r{m}, r{s}
added	6
begin
	// smuad
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01110000dddd1111ssss01X1mmmm
exclude	1111............................
asm	smusd{X?x:}{cond(c)} r{d}, r{m}, r{s}
added	6
begin
	// smusd
	if($c[${c}])
	{
		// TODO
	}
end

code	1111100PU1W01101@@@@1010@@@MMMMM
asm	srs{U?i:d}{P?b:a} #{M}{W?!:}
asm.ual	srs{U?i:d}{P?b:a} r13{W?!:}, #{M}
added	6
begin
	// srs
	a32_srs(cpu, ${M}, ${U!test}, ${P!test}, ${W!test});
end

code	cccc01101U1iiiiiddddIIIIIh01mmmm
exclude	1111............................
exclude	....................00000.......
asm	{U?u:s}sat{cond(c)} r{d}, #{i+1}, r{m}, {h?asr:lsl} #{I}
added	6
begin
	// ssat/usat
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01101U1iiiiidddd00000h01mmmm
exclude	1111............................
asm	{U?u:s}sat{cond(c)} r{d}, #{i+1}, r{m}{h?, asr #32:}
added	6
begin
	// ssat/usat
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01101U10iiiidddd!!!!0011mmmm
exclude	1111............................
asm	{U?u:s}sat16{cond(c)} r{d}, #{i+1}, r{m}
added	6
begin
	// ssat16/usat16
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01101U10nnnnddddrr@@0111mmmm
exclude	1111............................
exclude	............1111................
asm	{U?u:s}xtab{cond(c)} r{d}, r{n}, r{m}, ror #{r*8}
added	6
begin
	// sxtab/uxtab
	if($c[${c}])
	{
		if(${U!test})
			$r[${d}] = $r[${n}] + uxtb32($r[${m}], ${r} * 8);
		else
			$r[${d}] = $r[${n}] + sxtb32($r[${m}], ${r} * 8);
	}
end

code	cccc01101U101111ddddrr@@0111mmmm
exclude	1111............................
asm	{U?u:s}xtb{cond(c)} r{d}, r{m}, ror #{r*8}
added	6
begin
	// sxtb/uxtb
	if($c[${c}])
	{
		if(${U!test})
			$r[${d}] = uxtb32($r[${m}], ${r} * 8);
		else
			$r[${d}] = sxtb32($r[${m}], ${r} * 8);
	}
end

code	cccc01101U00nnnnddddrr@@0111mmmm
exclude	1111............................
exclude	............1111................
asm	{U?u:s}xtab16{cond(c)} r{d}, r{n}, r{m}, ror #{r*8}
added	6
begin
	// sxtab16/uxtab16
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01101U001111ddddrr@@0111mmmm
exclude	1111............................
asm	{U?u:s}xtb16{cond(c)} r{d}, r{m}, ror #{r*8}
added	6
begin
	// sxtb16/uxtb16
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01101U11nnnnddddrr@@0111mmmm
exclude	1111............................
exclude	............1111................
asm	{U?u:s}xtah{cond(c)} r{d}, r{n}, r{m}, ror #{r*8}
added	6
begin
	// sxtah/uxtah
	if($c[${c}])
	{
		if(${U!test})
			$r[${d}] = $r[${n}] + uxth32($r[${m}], ${r} * 8);
		else
			$r[${d}] = $r[${n}] + sxth32($r[${m}], ${r} * 8);
	}
end

code	cccc01101U111111ddddrr@@0111mmmm
exclude	1111............................
asm	{U?u:s}xth{cond(c)} r{d}, r{m}, ror #{r*8}
added	6
begin
	// sxth/uxth
	if($c[${c}])
	{
		if(${U!test})
			$r[${d}] = uxth32($r[${m}], ${r} * 8);
		else
			$r[${d}] = sxth32($r[${m}], ${r} * 8);
	}
end

code	cccc00000100hhhhllllssss1001mmmm
exclude	1111............................
asm	umaal{cond(c)} r{l}, r{h}, r{m}, r{s}
added	6
begin
	// umaal
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01111000dddd1111ssss0001mmmm
exclude	1111............................
asm	usad8{cond(c)} r{d}, r{m}, r{s}
added	6
begin
	// usad8
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc01111000ddddnnnnssss0001mmmm
exclude	1111............................
exclude	................1111............
asm	usada8{cond(c)} r{d}, r{m}, r{s}, r{n}
added	6
begin
	// usada8
	if($c[${c}])
	{
		// TODO
	}
end

#### ARMv6K

code	111101010111!!!!!!!!@@@@0001!!!!
asm	clrex
added	6K
begin
	// clrex
	a32_clear_exclusive(cpu);
end

code	cccc00011101nnnndddd!!!!1001!!!!
exclude	1111............................
asm	ldrexb{cond(c)} r{d}, [r{n}]
added	6K
begin
	// ldrexb
	if($c[${c}])
	{
		$r.v5[${d}] = a32_ldrexb(cpu, ${n}, 0);
	}
end

code	cccc00011100nnnndddd!!!!1001tttt
exclude	1111............................
asm	strexb{cond(c)} r{d}, r{t}, [r{n}]
added	6K
begin
	// strexb
	if($c[${c}])
	{
		$r[${d}] = a32_strexb(cpu, $r.str[${t}], ${n}, 0);
	}
end

code	cccc00011011nnnndddd!!!!1001!!!!
exclude	1111............................
asm	ldrexd{cond(c)} r{d}, [r{n}]
added	6K
begin
	// ldrexd
	if($c[${c}])
	{
		a32_ldrexd(cpu, ${d}, ${d} + 1, ${n}, 0);
	}
end

code	cccc00011010nnnndddd!!!!1001tttt
exclude	1111............................
asm	strexd{cond(c)} r{d}, r{t}, [r{n}]
added	6K
begin
	// strexd
	if($c[${c}])
	{
		$r[${d}] = a32_strexd(cpu, ${t}, ${t} + 1, ${n}, 0);
	}
end

code	cccc00011111nnnndddd!!!!1001!!!!
exclude	1111............................
asm	ldrexh{cond(c)} r{d}, [r{n}]
added	6K
begin
	// ldrexh
	if($c[${c}])
	{
		$r.v5[${d}] = a32_ldrexh(cpu, ${n}, 0);
	}
end

code	cccc00011110nnnndddd!!!!1001tttt
exclude	1111............................
asm	strexh{cond(c)} r{d}, r{t}, [r{n}]
added	6K
begin
	// strexh
	if($c[${c}])
	{
		$r[${d}] = a32_strexh(cpu, $r.str[${t}], ${n}, 0);
	}
end

code	cccc001100100000!!!!@@@@00000000
exclude	1111............................
asm	nop{cond(c)}
added	6T2, 6K
begin
	// nop
end

code	cccc001100100000!!!!@@@@00000100
exclude	1111............................
asm	sev{cond(c)}
added	6K
begin
	// sev
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc00010110@@@@@@@@@@@@0111iiii
exclude	1111............................
asm	smi{cond(c)} #{i:X}
asm.ual	smc{cond(c)} #{i:X}
added	6K
begin
	// smc
	if($c[${c}])
	{
		arm_smc(cpu);
	}
end

code	cccc001100100000!!!!@@@@00000010
exclude	1111............................
asm	wfe{cond(c)}
added	6K
begin
	// wfe
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc001100100000!!!!@@@@00000011
exclude	1111............................
asm	wfi{cond(c)}
added	6K
begin
	// wfi
	if($c[${c}])
	{
		// TODO
	}
end

code	cccc001100100000!!!!@@@@00000001
exclude	1111............................
asm	yield{cond(c)}
added	6K
begin
	// yield
	if($c[${c}])
	{
		// TODO
	}
end

#### ARMv6T2

#### Unprivileged load/store

code	cccc0110U11Lnnnntttt@@@@1SH1mmmm
exclude	1111............................
exclude	...........0.............1......
exclude	...........0..............0.....
asm	{L?ldr:str}{S?s:}{H?h:b}t{cond(c)} r{t}, [r{n}], {U?:-}r{m}
added	6T2
begin
	// ldrht/strht/ldrbt/ldrst/ldrsbt/ldrsht
	if($c[${c}])
	{
		uint32_t offset = $r[${m}];
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${L!test})
		{
			if(!${H!test})
			{
				$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_USER_MODE);
			}
			else if(!${S!test})
			{
				$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_USER_MODE);
			}
			else
			{
				$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_USER_MODE);
			}
		}
		else
		{
			a32_strh(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, USE_USER_MODE);
		}
	}
end

code	cccc0000U11Lnnnnttttiiii1SH1iiii
exclude	1111............................
exclude	...........0.............1......
exclude	...........0..............0.....
asm	{L?ldr:str}{S?s:}{H?h:b}t{cond(c)} r{t}, [r{n}], #{U?:-}{i:X}
added	6T2
begin
	// ldrht/strht/ldrbt/ldrst/ldrsbt/ldrsht
	if($c[${c}])
	{
		uint32_t offset = ${i};
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${L!test})
		{
			if(!${H!test})
			{
				$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_USER_MODE);
			}
			else if(!${S!test})
			{
				$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_USER_MODE);
			}
			else
			{
				$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_USER_MODE);
			}
		}
		else
		{
			a32_strh(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, USE_USER_MODE);
		}
	}
end

#### Miscellaneous

code	cccc0111110mmmmmddddlllll0011111
exclude	1111............................
asm	bfc{cond(c)} r{d}, #{l}, #{m-l+1}
added	6T2
begin
	// bfc
	if($c[${c}])
	{
		$r[${d}] = a32_bfc32(cpu, $r[${d}], ${l}, ${m});
	}
end

code	cccc0111110mmmmmddddlllll001nnnn
exclude	1111............................
exclude	............................1111
asm	bfi{cond(c)} r{d}, r{n}, #{l}, #{m-l+1}
added	6T2
begin
	// bfi
	if($c[${c}])
	{
		$r[${d}] = a32_bfi32(cpu, $r[${d}], $r[${n}], ${l}, ${m});
	}
end

code	cccc001100100000!!!!@@@@1111oooo
exclude	1111............................
asm	dbg{cond(c)} #{o:X}
added	6T2
begin
	// dbg
end

code	cccc00000110ddddaaaammmm1001nnnn
exclude	1111............................
asm	mls{cond(c)} r{d}, r{n}, r{m}, r{a}
added	6T2
begin
	// mls
	if($c[${c}])
	{
		$r[${d}] = a32_mls32($r[${n}], $r[${m}], $r[${a}]);
	}
end

code	cccc00110000iiiiddddiiiiiiiiiiii
exclude	1111............................
asm	movw{cond(c)} r{d}, #{i:X}
added	6T2
begin
	// movw
	if($c[${c}])
	{
		$r[${d}] = ${i};
	}
end

code	cccc00110100iiiiddddiiiiiiiiiiii
exclude	1111............................
asm	movt{cond(c)} r{d}, #{i:X}
added	6T2
begin
	// movt
	if($c[${c}])
	{
		$r[${d}] = (${i} << 16) | ($r[${d}] & 0x0000FFFF);
	}
end

code	cccc01101111!!!!dddd!!!!0011mmmm
exclude	1111............................
asm	rbit{cond(c)} r{d}, r{m}
added	6T2
begin
	// rbit
	if($c[${c}])
	{
		$r[${d}] = rbit32($r[${m}]);
	}
end

code	cccc01111U1wwwwwddddlllll101nnnn
exclude	1111............................
asm	{U?u:s}bfx{cond(c)} r{d}, r{n}, #{l}, #{w+1}
added	6T2
begin
	// sbfx/ubfx
	if($c[${c}])
	{
		uint32_t value = $r[${n}] >> ${l};
		if(${U!test} || ((value >> ${w}) & 1) != 0)
			value &= (1 << ${w}) - 1;
		else
			value |= -1 << ${w};
		$r[${d}] = value;
	}
end

#### ARMv7

code	111101010111!!!!!!!!@@@@0101oooo
asm	dmb {o:X}
added	7
begin
	// dmb
end

code	111101010111!!!!!!!!@@@@0100oooo
# TODO
exclude	............................1100	since	8-R
asm	dsb {o:X}
added	7
begin
	// dsb
end

code	111101010111!!!!!!!!@@@@0110oooo
asm	isb {o:X}
added	7
begin
	// isb
end

code	11110100U101nnnn!!!!iiiiiiiiiiii
asm	pli [r${n}, #{U?:-}{i:X}]
added	7
begin
	// pli
end

code	11110110U101nnnn!!!!HHHHHHH0mmmm
asm	pli [r${n}, {adr_operand()}]
added	7
begin
	// pli
end

#### ARMv7VE
#### Virtualization Extensions

code	cccc00010110@@@@@@@@@@@@0110!!!@
exclude	1111............................
asm	eret{cond(c)}
added	7VE
begin
	// eret
	if($c[${c}])
	{
		a32_eret(cpu);
	}
end

code	cccc00010100iiiiiiiiiiii0111iiii
exclude	1111............................
asm	hvc{cond(c)} #{i:X}
added	7VE
begin
	// hvc
	if($c[${c}])
	{
		arm_hvc(cpu);
	}
end

code	cccc00010000MMMMdddd@@!m0000@@@@
exclude	1111............................
asm	mrs{cond(c)} r{d}, {banked_register(m'M)}
added	7VE
begin
	// mrs
	if($c[${c}])
	{
		// TODO
		$r[${d}] = cpu->r[a32_banked_register_numbers[${m'M}]];
	}
end

code	cccc00010100MMMMdddd@@!m0000@@@@
exclude	1111............................
asm	mrs{cond(c)} r{d}, {banked_spsr(m'M)}
added	7VE
begin
	// mrs
	if($c[${c}])
	{
		// TODO
		$r[${d}] = cpu->r[a32_banked_spsr_numbers[${m'M}]];
	}
end

code	cccc00010010MMMM!!!!@@!m0000nnnn
exclude	1111............................
asm	msr{cond(c)} {banked_register(m'M)}, r{n}
added	7VE
begin
	// msr
	if($c[${c}])
	{
		// TODO
		cpu->r[a32_banked_register_numbers[${m'M}]] = $r[${n}];
	}
end

code	cccc00010110MMMM!!!!@@!m0000nnnn
exclude	1111............................
asm	msr{cond(c)} {banked_spsr(m'M)}, r{n}
added	7VE
begin
	// msr
	if($c[${c}])
	{
		// TODO
		cpu->r[a32_banked_spsr_numbers[${m'M}]] = $r[${n}];
	}
end

code	cccc011110U1dddd!!!!mmmm0001nnnn
exclude	1111............................
asm	{U?u:s}div{cond(c)} r{d}, r{n}, r{m}
added	7VE
begin
	// sdiv/udiv
	if($c[${c}])
	{
		// TODO: if ARMv7-R and SCTLR.DZ=1, make undefined instruction exception
		if($r[${m}] == 0)
			$r[${d}] = 0; /* TODO: or GenerateIntegerZeroDivide */
		else if(${U!test})
			$r[${d}] = (uint32_t)$r[${n}] / (uint32_t)$r[${m}];
		else
			$r[${d}] = (int32_t)$r[${n}] / (int32_t)$r[${m}];
	}
end

#### ARMv8-R

code	111101010111!!!!!!!!@@@@01001100
asm	dfb
added	8-R
begin
	// dfb
end

#### ARMv8.1

code	cccc00010ss0nnnndddd@@C@0100mmmm
exclude	1111............................
exclude	.........11.....................
asm	crc32{C?c:}{s?b;h;w;}{cond(c)} r{d}, r{n}, r{m}
added	8.1
begin
	// crc32/crc32c
	if($c[${c}])
	{
		// TODO
	}
end

code	111100010001@@@@@@@@@@i@0000@@@@
asm	setpan #{i}
added	8.1
begin
	// setpan
	if(cpu->pstate.mode != 0)
	{
		cpu->pstate.pan = ${i};
	}
end

#### ARMv8.2

code	cccc001100100000!!!!@@@@00010000
exclude	1111............................
asm	esb{cond(c)}
added	8.2
begin
	// esb
	if($c[${c}])
	{
		// TODO
	}
end

######## Thumb, Thumb-2
isa	T32

#### 16-bit instructions (in width)
#### If-then block

code	10111111ccccmmmm
exclude	............0000
it	no
asm	it{condlist()} {cond(c)}
added	6T2
begin
	// it
	$itstate = ${c'm};
	return; // to avoid advancing the IT counter
end

#### ARMv4T

code	0100000101nnnddd
asm	adc{cond_or_s()} r{d}, r{n}
added	4T
begin
	// adc
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_adc32(cpu, $r[${d}], $r[${n}], !t32_in_it_block(cpu), false);
	}
end

code	0001110iiinnnddd
exclude	.......000......
asm	add{cond_or_s()} r{d}, r{n}, #{i:X}
added	4T
begin
	// add
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_add32(cpu, $r[${n}], ${i}, !t32_in_it_block(cpu), false);
	}
end

code	0001110000nnnddd
asm	mov{cond_or_s()} r{d}, r{n}
added	4T
begin
	// mov
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mov32(cpu, $r[${n}], !t32_in_it_block(cpu), false);
	}
end

code	00110dddiiiiiiii
asm	add{cond_or_s()} r{d}, #{i:X}
added	4T
begin
	// add
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_add32(cpu, $r[${d}], ${i}, !t32_in_it_block(cpu), false);
	}
end

code	0001100mmmnnnddd
asm	add{cond_or_s()} r{d}, r{n}, r{m}
added	4T
begin
	// add
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_add32(cpu, $r[${n}], $r[${m}], !t32_in_it_block(cpu), false);
	}
end

code	01000100dmmmmddd
exclude	........00......	before	6T2
exclude	........1....111
asm	add{cond()} r{d}, r{m}
added	4T
begin
	// add
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_add32(cpu, $r[${d}], $r[${m}], false, false);
	}
end

code	010001001mmmm111
it	end
asm	add{cond_or_s()} r15, r{m}
added	4T
begin
	// add
	if(t32_check_condition(cpu))
	{
		$r[15] = a32_add32(cpu, $r[15], $r[${m}], !t32_in_it_block(cpu), false);
	}
end

code	10100dddiiiiiiii
asm	add{cond()} r{d}, pc, #{i'00:X}
added	4T
begin
	// add
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_add32(cpu, $pc & ~4, (${i}) << 2, false, false);
	}
end

code	10101dddiiiiiiii
asm	add{cond()} r{d}, r13, #{i'00:X}
added	4T
begin
	// add
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_add32(cpu, $r[A32_SP], (${i}) << 2, false, false);
	}
end

code	101100000iiiiiii
asm	add r13, #{i'00:X}
asm.ual	add{cond()} r13, r13, #{i'00:X}
added	4T
begin
	// add
	if(t32_check_condition(cpu))
	{
		$r[A32_SP] = a32_add32(cpu, $r[A32_SP], (${i}) << 2, false, false);
	}
end

code	0100000000mmmddd
asm	and{cond_or_s()} r{d}, r{m}
added	4T
begin
	// and
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_and32(cpu, $r[${d}], $r[${m}], !t32_in_it_block(cpu), false);
	}
end

code	00010iiiiimmmddd
asm	asr{cond_or_s()} r{d}, r{m}, #{positive(i)}
added	4T
begin
	// asr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_asr32(cpu, $r[${m}], ${positive(i)}, !t32_in_it_block(cpu));
	}
end

code	0100000100sssddd
asm	asr{cond_or_s()} r{d}, r{s}
added	4T
begin
	// asr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_asr32(cpu, $r[${d}], $r[${s}] & 0xFF, !t32_in_it_block(cpu));
	}
end

code	1101cccciiiiiiii
exclude	....111.........
asm	b{cond(c)} {signextend i'0!offset}
added	4T
begin
	// b
	if($c[${c}])
	{
		$pc = ${signextend i'0!offset};
	}
end

code	11100iiiiiiiiiii
it	end
asm	b{cond()} {signextend i'0!offset}
added	4T
begin
	// b
	if(t32_check_condition(cpu))
	{
		$pc = ${signextend i'0!offset};
	}
end

code	0100001110mmmddd
asm	bic{cond_or_s()} r{d}, r{m}
added	4T
begin
	// bic
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_bic32(cpu, $r[${d}], $r[${m}], !t32_in_it_block(cpu), false);
	}
end

code	010001110mmmm@@@
it	end
asm	bx{cond()} r{m}
added	4T
begin
	// bx
	if(t32_check_condition(cpu))
	{
		$cpsr.thumb = $r[${m}] & 1; // must be set first for proper alignment
		$pc = $r[${m}];
	}
end

code	0100001011mmmnnn
asm	cmn{cond()} r{n}, r{m}
added	4T
begin
	// cmn
	if(t32_check_condition(cpu))
	{
		a32_cmn32(cpu, $r[${n}], $r[${m}], IGNORE_RESULT);
	}
end

code	00101nnniiiiiiii
asm	cmp{cond()} r{n}, #{i:X}
added	4T
begin
	// cmp
	if(t32_check_condition(cpu))
	{
		a32_cmp32(cpu, $r[${n}], ${i}, IGNORE_RESULT);
	}
end

code	0100001010mmmnnn
asm	cmp{cond()} r{n}, r{m}
added	4T
begin
	// cmp
	if(t32_check_condition(cpu))
	{
		a32_cmp32(cpu, $r[${n}], $r[${m}], IGNORE_RESULT);
	}
end

code	01000101nmmmmnnn
exclude	........00......
asm	cmp{cond()} r{n}, r{m}
added	4T
begin
	// cmp
	if(t32_check_condition(cpu))
	{
		a32_cmp32(cpu, $r[${n}], $r[${m}], IGNORE_RESULT);
	}
end

code	0100000001mmmddd
asm	eor{cond_or_s()} r{d}, r{m}
added	4T
begin
	// eor
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_eor32(cpu, $r[${d}], $r[${m}], !t32_in_it_block(cpu), false);
	}
end

code	11001nnnllllllll
asm	ldmia{cond()} r{n}!, {reglist(l)}
added	4T
thumbee	no
begin
	// ldmia
	if(t32_check_condition(cpu))
	{
		a32_ldm(cpu, ${l}, ${n}, true, false, true, false);
	}
end

code	011B1iiiiinnnddd
asm	ldr{B?b:}{cond()} r{d}, [r{n}, #{i'00:X}]
added	4T
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i} << 2;
		if(${B!test})
			$r.v5[${d}] = a32_ldrb(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
		else
			$r.v5[${d}] = a32_ldr(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	10001iiiiinnnddd
asm	ldrh{cond()} r{d}, [r{n}, #{i'00:X}]
added	4T
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i} << 2;
		$r.v5[${d}] = a32_ldrh(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	0101100mmmnnnddd
asm	ldr{cond()} r{d}, [r{n}, r{m}]
added	4T
thumbee	no
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		$r.v5[${d}] = a32_ldr(cpu, ${n}, $r[${m}], PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	0101100mmmnnnddd
asm	ldr{cond()} r{d}, [r{n}, r{m}, lsl #2]
added	4T
thumbee	yes
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		$r.v5[${d}] = a32_ldr(cpu, ${n}, $r[${m}] << 2, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	0101110mmmnnnddd
asm	ldrb{cond()} r{d}, [r{n}, r{m}]
added	4T
begin
	// ldrb
	if(t32_check_condition(cpu))
	{
		$r.v5[${d}] = a32_ldrb(cpu, ${n}, $r[${m}], PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	0101011mmmnnnddd
asm	ldrsb{cond()} r{d}, [r{n}, r{m}]
added	4T
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		$r.v5[${d}] = a32_ldrsb(cpu, ${n}, $r[${m}], PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	01011S1mmmnnnddd
asm	ldr{S?s:}h{cond()} r{d}, [r{n}, r{m}]
added	4T
thumbee	no
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		if(${S!test})
			$r.v5[${d}] = a32_ldrsh(cpu, ${n}, $r[${m}], PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
		else
			$r.v5[${d}] = a32_ldrh(cpu, ${n}, $r[${m}], PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	01011S1mmmnnnddd
asm	ldr{S?s:}h{cond()} r{d}, [r{n}, r{m}, lsl #1]
added	4T
thumbee	yes
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		if(${S!test})
			$r.v5[${d}] = a32_ldrsh(cpu, ${n}, $r[${m}] << 1, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
		else
			$r.v5[${d}] = a32_ldrh(cpu, ${n}, $r[${m}] << 1, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	01001dddiiiiiiii
asm	ldr{cond()} r{d}, [{i'00!mem_offset}]
added	4T
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i'00};
		$r.v5[${d}] = a32_ldr(cpu, A32_PC_NUM, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	10011dddiiiiiiii
asm	ldr{cond()} r{d}, [r13, #{i'00:X}]
added	4T
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i'00};
		$r.v5[${d}] = a32_ldr(cpu, A32_SP, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	00000iiiiimmmddd
exclude	.....00000......
asm	lsl{cond_or_s()} r{d}, r{m}, #{i}
added	4T
begin
	// lsl
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_lsl32(cpu, $r[${m}], ${i}, !t32_in_it_block(cpu));
	}
end

code	0000000000mmmddd
it	no
asm	mov{cond_or_s()} r{d}, r{m}
added	4T
begin
	// mov
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mov32(cpu, $r[${m}], !t32_in_it_block(cpu), false);
	}
end

code	0100000010sssddd
asm	lsl{cond_or_s()} r{d}, r{s}
added	4T
begin
	// lsl
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_lsl32(cpu, $r[${d}], $r[${s}] & 0xFF, !t32_in_it_block(cpu));
	}
end

code	00001iiiiimmmddd
asm	lsr{cond_or_s()} r{d}, r{m}, #{positive(i)}
added	4T
begin
	// lsr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_lsr32(cpu, $r[${m}], ${positive(i)}, !t32_in_it_block(cpu));
	}
end

code	0100000011sssddd
asm	lsr{cond_or_s()} r{d}, r{s}
added	4T
begin
	// lsr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_lsr32(cpu, $r[${d}], $r[${s}] & 0xFF, !t32_in_it_block(cpu));
	}
end

code	00100dddiiiiiiii
asm	mov{cond_or_s()} r{d}, #{i:X}
added	4T
begin
	// mov
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mov32(cpu, ${i}, !t32_in_it_block(cpu), false);
	}
end

code	01000110dmmmmddd
exclude	........00......	before	6
when	........1....111	it	no
asm	mov{cond()} r{d}, r{m}
added	4T
begin
	// mov
	if(t32_check_condition(cpu))
	{
		$r[${d}] = $r[${m}];
	}
end

code	0100001101mmmddd
asm	mul{cond_or_s()} r{d}, r{m}
added	4T
begin
	// mul
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mul32(cpu, $r[${d}], $r[${m}], !t32_in_it_block(cpu));
	}
end

code	0100001111nnnddd
asm	mvn{cond_or_s()} r{d}, r{n}
added	4T
begin
	// mvn
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mvn32(cpu, $r[${n}], !t32_in_it_block(cpu), false);
	}
end

code	0100001001mmmddd
asm	neg r{d}, r{m}
asm.ual	rsb{cond_or_s()} r{d}, r{m}, #0
added	4T
begin
	// neg
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_rsb32(cpu, $r[${m}], 0, !t32_in_it_block(cpu), false);
	}
end

code	0100001100mmmddd
asm	orr{cond_or_s()} r{d}, r{m}
added	4T
begin
	// orr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_orr32(cpu, $r[${d}], $r[${m}], !t32_in_it_block(cpu), false);
	}
end

code	1011110rllllllll
asm	pop{cond()} {reglist(l+r'000000000000000)}
added	4T
begin
	// pop
	if(t32_check_condition(cpu))
	{
		a32_ldm(cpu, ${l} | (${r!test} ? 1 << A32_PC_NUM : 0), A32_SP, true, false, true, false);
	}
end

code	1011010rllllllll
asm	push{cond()} {reglist(l+r'00000000000000)}
added	4T
begin
	// push
	if(t32_check_condition(cpu))
	{
		a32_stm(cpu, ${l} | (${r!test} ? 1 << A32_LR : 0), A32_SP, false, true, true, false);
	}
end

code	0100000111sssddd
asm	ror{cond_or_s()} r{d}, r{s}
added	4T
begin
	// ror
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_ror32(cpu, $r[${d}], $r[${s}] & 0xFF, !t32_in_it_block(cpu));
	}
end

code	0100000110nnnddd
asm	sbc{cond_or_s()} r{d}, r{n}
added	4T
begin
	// sbc
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_sbc32(cpu, $r[${d}], $r[${n}], !t32_in_it_block(cpu), false);
	}
end

code	11000nnnllllllll
asm	stmia{cond()} r{n}!, {reglist(l)}
added	4T
thumbee	no
begin
	// stmia
	if(t32_check_condition(cpu))
	{
		a32_stm(cpu, ${l}, ${n}, true, false, false, false);
	}
end

code	011B0iiiiinnnddd
asm	str{B?b:}{cond()} r{d}, [r{n}, #{i'00:X}]
added	4T
begin
	// str
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i} << 2;
		if(${B!test})
			a32_strb(cpu, $r.str[${d}], ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
		else
			a32_str(cpu, $r.str[${d}], ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	10000iiiiinnnddd
asm	strh{cond()} r{d}, [r{n}, {i'00:X}]
added	4T
begin
	// str
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i} << 2;
		a32_strh(cpu, $r.str[${d}], ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	0101000mmmnnnddd
asm	str{cond()} r{d}, [r{n}, r{m}]
added	4T
thumbee	no
begin
	// str
	if(t32_check_condition(cpu))
	{
		a32_str(cpu, $r.str[${d}], ${n}, $r[${m}], PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	0101000mmmnnnddd
asm	str{cond()} r{d}, [r{n}, r{m}, lsl #2]
added	4T
thumbee	yes
begin
	// str
	if(t32_check_condition(cpu))
	{
		a32_str(cpu, $r.str[${d}], ${n}, $r[${m}] << 2, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	0101010mmmnnnddd
asm	strb{cond()} r{d}, [r{n}, r{m}]
added	4T
begin
	// str
	if(t32_check_condition(cpu))
	{
		a32_strb(cpu, $r.str[${d}], ${n}, $r[${m}], PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	0101001mmmnnnddd
asm	strh{cond()} r{d}, [r{n}, r{m}]
added	4T
thumbee	no
begin
	// str
	if(t32_check_condition(cpu))
	{
		a32_strh(cpu, $r.str[${d}], ${n}, $r[${m}], PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	0101001mmmnnnddd
asm	strh{cond()} r{d}, [r{n}, r{m}, lsl #1]
added	4T
thumbee	yes
begin
	// str
	if(t32_check_condition(cpu))
	{
		a32_strh(cpu, $r.str[${d}], ${n}, $r[${m}] << 1, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	10010dddiiiiiiii
asm	str r{d}, [r13, {i'00:X}]
added	4T
begin
	// str
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i} << 2;
		a32_str(cpu, $r.str[${d}], $r[A32_SP], offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	0001111iiinnnddd
asm	sub{cond_or_s()} r{d}, r{n}, #{i:X}
added	4T
begin
	// sub
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_sub32(cpu, $r[${n}], ${i}, !t32_in_it_block(cpu), false);
	}
end

code	00111dddiiiiiiii
asm	sub{cond_or_s()} r{d}, #{i:X}
added	4T
begin
	// sub
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_sub32(cpu, $r[${d}], ${i}, !t32_in_it_block(cpu), false);
	}
end

code	0001101mmmnnnddd
asm	sub{cond_or_s()} r{d}, r{n}, r{m}
added	4T
begin
	// sub
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_sub32(cpu, $r[${n}], $r[${m}], !t32_in_it_block(cpu), false);
	}
end

code	101100001iiiiiii
asm	sub r13, #{i'00:X}
asm.ual	sub{cond()} r13, r13, #{i'00:X}
added	4T
begin
	// sub
	if(t32_check_condition(cpu))
	{
		$r[A32_SP] = a32_sub32(cpu, $r[A32_SP], (${i}) << 2, false, false);
	}
end

code	11011111iiiiiiii
asm	swi #{i:X}
asm.ual	svc{cond()} #{i:X}
added	4T
begin
	// swi
	if(t32_check_condition(cpu))
	{
		arm_svc(cpu);
	}
end

code	0100001000mmmnnn
asm	tst{cond()} r{n}, r{m}
added	4T
begin
	// tst
	if(t32_check_condition(cpu))
	{
		a32_tst32(cpu, $r[${n}], $r[${m}], IGNORE_RESULT);
	}
end

code	11011110iiiiiiii
asm	udf #{i:X}
added	4T
begin
	// udf
	arm_undefined(cpu);
end

#### ARMv5T

code	10111110iiiiiiii
asm	bkpt #{i:2X}
added	5T
begin
	// bkpt
	if(t32_check_condition(cpu))
	{
		$pc = $pc_next | 1;
		arm_breakpoint(cpu);
	}
end

code	010001111mmmm@@@
it	end
asm	blx{cond()} r{m}
added	5T
begin
	// blx
	if(t32_check_condition(cpu))
	{
		$lr = $pc.cpsr - 4;
		$cpsr.thumb = $r[${m}] & 1; // must be set first for proper alignment
		$pc = $r[${m}];
	}
end

#### ARMv6

code	10110110011D0AIF
asm	cpsi{D?d:e} {A?a:}{I?i:}{F?f:}
added	6
begin
	// cps
	if(${A!test})
		$cpsr.a = ${D};
	if(${I!test})
		$cpsr.i = ${D};
	if(${F!test})
		$cpsr.f = ${D};
end

code	1011101000nnnddd
asm	rev{cond()} r{d}, r{n}
added	6
begin
	// rev
	if(t32_check_condition(cpu))
	{
		$r[${d}] = bswap_32($r[${n}]);
	}
end

code	1011101001nnnddd
asm	rev16{cond()} r{d}, r{n}
added	6
begin
	// rev16
	if(t32_check_condition(cpu))
	{
		uint32_t value = $r[${n}];
		$r[${d}] = bswap_16(value) | (bswap_16(value >> 16) << 16);
	}
end

code	1011101011nnnddd
asm	revsh{cond()} r{d}, r{n}
added	6
begin
	// revsh
	if(t32_check_condition(cpu))
	{
		$r[${d}] = sign_extend(16, bswap_16($r[${n}]));
	}
end

code	101101100101E@@@
asm	setend {E?B:L}E
added	6, except 6-M
begin
	// setend
	$cpsr.e = ${E};
end

code	10110010U1mmmddd
asm	{U?u:s}xtb{cond()} r{d}, r{m}
added	6
begin
	// sxtb/uxtb
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = uxtb32($r[${m}], 0);
		else
			$r[${d}] = sxtb32($r[${m}], 0);
	}
end

code	10110010U0mmmddd
asm	{U?u:s}xth{cond()} r{d}, r{m}
added	6
begin
	// sxth/uxth
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = uxth32($r[${m}], 0);
		else
			$r[${d}] = sxth32($r[${m}], 0);
	}
end

#### ARMv6T2

code	1011N0i1iiiiinnn
it	no
asm	cb{N?n:}z r{n}, {signextend i'0!offset}
added	6T2
begin
	// cbz/cbnz
	if(${N!test} ? $r[${n}] != 0 : $r[${n}] == 0)
	{
		$pc = ${signextend i'0!offset};
	}
end

code	1011111100000000
asm	nop{cond()}
added	6T2
begin
	// nop
end

#### ARMv7

code	1011111101000000
asm	sev{cond()}
added	6-M, 7
begin
	// sev
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	1011111100100000
asm	wfe{cond()}
added	6-M, 7
begin
	// wfe
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	1011111100110000
asm	wfi{cond()}
added	6-M, 7
begin
	// wfi
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	1011111100010000
asm	yield{cond()}
added	6-M, 7
begin
	// yield
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

#### ARMv8.1

code	10110110000!i@@@
it	no
asm	setpan #{i}
added	8.1
begin
	// setpan
	if(cpu->pstate.mode != 0)
	{
		cpu->pstate.pan = ${i};
	}
end

#### Long jumps (pre-Thumb-2)
# these instructions are also available in Thumb-2 but are interpreted differently

code	11110iiiiiiiiiii
asm	{store_t16()}(add $lr, $pc, {signextend i'000000000000:X})
added	4T
removed	6T2
begin
	// bl/blx
	$lr = ${signextend i'000000000000!offset};
end

code	11111iiiiiiiiiii
asm	bl {t32label()}
added	4T
removed	6T2
begin
	// bl
	uint32_t next = $pc_next;
	$pc = $lr + ${i'0};
	$lr = next | 1;
end

code	11101iiiiiiiiii0
asm	blx {t32label()}
added	5T
removed	6T2
begin
	// blx
	uint32_t next = $pc_next;
	$cpsr.thumb = false; // must be set first for proper alignment
	$pc = $lr + ${i'0};
	$lr = next | 1;
end

#### 32-bit (Thumb-2)
#### Long jumps (Thumb-2)

code	11110iiiiiiiiiii 11i1iiiiiiiiiiii
it	end
asm	bl{cond()} {t32label()}
added	6T2
begin
	// bl
	uint32_t next = $pc_next;
	$pc = ${t32label()};
	$lr = next | 1;
end

code	11110iiiiiiiiiii 11i0iiiiiiiiiii0
it	end
asm	blx{cond()} {t32label()}
added	6T2
thumbee	no
begin
	// blx
	uint32_t next = $pc_next;
	$cpsr.thumb = false; // must be set first for proper alignment
	$pc = ${t32label()};
	$lr = next | 1;
end

#### ARMv6T2
#### Data processing

code	11110i01010Snnnn 0iiiddddiiiiiiii
asm	adc{S?s:}{cond()} r{d}, r{n}, #{immed()}
added	6T2
begin
	// adc
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_adc32(cpu, $r[${n}], ${immed()}, ${S!test}, false);
	}
end

code	11101011010Snnnn @iiiddddiiiimmmm
asm	adc{S?s:}{cond()} r{d}, r{n}, r{m}{shift()}
added	6T2
begin
	// adc
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_adc32(cpu, $r[${n}], ${operand(S)}, ${S!test}, false);
	}
end

code	11110i01000Snnnn 0iiiddddiiiiiiii
exclude	...........1.... ....1111........
asm	add{S?s:}{cond()} r{d}, r{n}, #{immed()}
added	6T2
begin
	// add
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_add32(cpu, $r[${n}], ${immed()}, ${S!test}, false);
	}
end

code	11110i100000nnnn 0iiiddddiiiiiiii
asm	addw{cond()} r{d}, r{n}, #{i:X}
added	6T2
begin
	// addw
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_add32(cpu, $r[${n}], ${i}, false, false);
	}
end

code	11101011000Snnnn @iiiddddiiiimmmm
exclude	...........1.... ....1111........
asm	add{S?s:}{cond()} r{d}, r{n}, r{m}{shift()}
added	6T2
begin
	// add
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_add32(cpu, $r[${n}], ${operand(S)}, ${S!test}, false);
	}
end

code	11110i00000Snnnn 0iiiddddiiiiiiii
exclude	...........1.... ....1111........
asm	and{S?s:}{cond()} r{d}, r{n}, #{immed()}
added	6T2
begin
	// and
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_and32(cpu, $r[${n}], ${immed()}, ${S!test}, false);
	}
end

code	11101010000Snnnn @iiiddddiiiimmmm
exclude	...........1.... ....1111........
asm	and{S?s:}{cond()} r{d}, r{n}, r{m}{shift()}
added	6T2
begin
	// and
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_and32(cpu, $r[${n}], ${operand(S)}, ${S!test}, false);
	}
end

code	11110i00001Snnnn 0iiiddddiiiiiiii
asm	bic{S?s:}{cond()} r{d}, r{n}, #{immed()}
added	6T2
begin
	// bic
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_bic32(cpu, $r[${n}], ${immed()}, ${S!test}, false);
	}
end

code	11101010001Snnnn @iiiddddiiiimmmm
asm	bic{S?s:}{cond()} r{d}, r{n}, r{m}{shift()}
added	6T2
begin
	// bic
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_bic32(cpu, $r[${n}], ${operand(S)}, ${S!test}, false);
	}
end

code	11110i010001nnnn 0iii1111iiiiiiii
asm	cmn{cond()} r{n}, #{immed()}
added	6T2
begin
	// cmn
	if(t32_check_condition(cpu))
	{
		a32_cmn32(cpu, $r[${n}], ${immed()}, IGNORE_RESULT);
	}
end

code	111010110001nnnn @iii1111iiiimmmm
asm	cmn{cond()} r{n}, r{m}{shift()}
added	6T2
begin
	// cmn
	if(t32_check_condition(cpu))
	{
		a32_cmn32(cpu, $r[${n}], ${operand(1)}, IGNORE_RESULT);
	}
end

code	11110i011011nnnn 0iii1111iiiiiiii
asm	cmp{cond()} r{n}, #{immed()}
added	6T2
begin
	// cmp
	if(t32_check_condition(cpu))
	{
		a32_cmp32(cpu, $r[${n}], ${immed()}, IGNORE_RESULT);
	}
end

code	111010111011nnnn @iii1111iiiimmmm
asm	cmp{cond()} r{n}, r{m}{shift()}
added	6T2
begin
	// cmp
	if(t32_check_condition(cpu))
	{
		a32_cmp32(cpu, $r[${n}], ${operand(1)}, IGNORE_RESULT);
	}
end

code	11110i00100Snnnn 0iiiddddiiiiiiii
exclude	...........1.... ....1111........
asm	eor{S?s:}{cond()} r{d}, r{n}, #{immed()}
added	6T2
begin
	// eor
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_eor32(cpu, $r[${n}], ${immed()}, ${S!test}, false);
	}
end

code	11101010100Snnnn @iiiddddiiiimmmm
exclude	...........1.... ....1111........
asm	eor{S?s:}{cond()} r{d}, r{n}, r{m}{shift()}
added	6T2
begin
	// eor
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_eor32(cpu, $r[${n}], ${operand(S)}, ${S!test}, false);
	}
end

code	11110i00010S1111 0iiiddddiiiiiiii
asm	mov{S?s:}{cond()} r{d}, #{immed()}
added	6T2
begin
	// mov
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mov32(cpu, ${immed()}, ${S!test}, false);
	}
end

code	11110i100100IIII 0iiiddddiiiiiiii
asm	movw{cond()} r{d}, #{I'i:X}
added	6T2
begin
	// movw
	if(t32_check_condition(cpu))
	{
		$r[${d}] = ${I'i};
	}
end

code	11110i00011S1111 0iiiddddiiiiiiii
asm	mvn{S?s:}{cond()} r{d}, #{immed()}
added	6T2
begin
	// mvn
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mvn32(cpu, ${immed()}, ${S!test}, false);
	}
end

code	11101010011S1111 @iiiddddiiiimmmm
asm	mvn{S?s:}{cond()} r{d}, r{m}{shift()}
added	6T2
begin
	// mvn
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mvn32(cpu, ${operand(S)}, ${S!test}, false);
	}
end

code	11110i00011Snnnn 0iiiddddiiiiiiii
exclude	............1111 ................
asm	orn{S?s:}{cond()} r{d}, r{n}, #{immed()}
added	6T2
begin
	// orn
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_orn32(cpu, $r[${n}], ${immed()}, ${S!test});
	}
end

code	11101010011Snnnn @iiiddddiiiimmmm
exclude	............1111 ................
asm	orn{S?s:}{cond()} r{d}, r{n}, r{m}{shift()}
added	6T2
begin
	// orn
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_orn32(cpu, $r[${n}], ${operand(S)}, ${S!test});
	}
end

code	11110i00010Snnnn 0iiiddddiiiiiiii
exclude	............1111 ................
asm	orr{S?s:}{cond()} r{d}, r{n}, #{immed()}
added	6T2
begin
	// orr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_orr32(cpu, $r[${n}], ${immed()}, ${S!test}, false);
	}
end

code	11101010010Snnnn @iiiddddiiiimmmm
exclude	............1111 ................
asm	orr{S?s:}{cond()} r{d}, r{n}, r{m}{shift()}
added	6T2
begin
	// orr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_orr32(cpu, $r[${n}], ${operand(S)}, ${S!test}, false);
	}
end

code	11110i01110Snnnn 0iiiddddiiiiiiii
asm	rsb{S?s:}{cond()} r{d}, r{n}, #{immed()}
added	6T2
begin
	// rsb
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_rsb32(cpu, $r[${n}], ${immed()}, ${S!test}, false);
	}
end

code	11101011110Snnnn @iiiddddiiiimmmm
asm	rsb{S?s:}{cond()} r{d}, r{n}, r{m}{shift()}
added	6T2
begin
	// rsb
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_rsb32(cpu, $r[${n}], ${operand(S)}, ${S!test}, false);
	}
end

code	11110i01011Snnnn 0iiiddddiiiiiiii
asm	sbc{S?s:}{cond()} r{d}, r{n}, #{immed()}
added	6T2
begin
	// sbc
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_sbc32(cpu, $r[${n}], ${immed()}, ${S!test}, false);
	}
end

code	11101011011Snnnn @iiiddddiiiimmmm
asm	sbc{S?s:}{cond()} r{d}, r{n}, r{m}{shift()}
added	6T2
begin
	// sbc
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_sbc32(cpu, $r[${n}], ${operand(S)}, ${S!test}, false);
	}
end

code	11110i01101Snnnn 0iiiddddiiiiiiii
exclude	...........1.... ....1111........
asm	sub{S?s:}{cond()} r{d}, r{n}, #{immed()}
added	6T2
begin
	// sub
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_sub32(cpu, $r[${n}], ${immed()}, ${S!test}, false);
	}
end

code	11110i101010nnnn 0iiiddddiiiiiiii
asm	subw{cond()} r{d}, r{n}, #{i:X}
added	6T2
begin
	// subw
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_sub32(cpu, $r[${n}], ${i}, false, false);
	}
end

code	11101011101Snnnn @iiiddddiiiimmmm
exclude	...........1.... ....1111........
asm	sub{S?s:}{cond()} r{d}, r{n}, r{m}{shift()}
added	6T2
begin
	// sub
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_sub32(cpu, $r[${n}], ${operand(S)}, ${S!test}, false);
	}
end

code	111100111101!!!@ 10@0!!!!iiiiiiii
# replaced with ERET
exclude	................ ........00000000	since	7VE
it	end
asm	subs{cond()} r15, r14, #{i:2X}
added	6T2
thumbee	no
begin
	// subs
	if(t32_check_condition(cpu))
	{
		$pc = ($r[14] - ${i}) & ~3;
		a32_set_cpsr(cpu, ~(uint32_t)0, a32_get_spsr(cpu));
	}
end

code	11110i001001nnnn 0iii1111iiiiiiii
asm	teq{cond()} r{n}, #{immed()}
added	6T2
begin
	// teq
	if(t32_check_condition(cpu))
	{
		a32_teq32(cpu, $r[${n}], ${immed()}, IGNORE_RESULT);
	}
end

code	111010101001nnnn @iii1111iiiimmmm
asm	teq{cond()} r{n}, r{m}{shift()}
added	6T2
begin
	// teq
	if(t32_check_condition(cpu))
	{
		a32_teq32(cpu, $r[${n}], ${operand(1)}, IGNORE_RESULT);
	}
end

code	11110i000001nnnn 0iii1111iiiiiiii
asm	tst{cond()} r{n}, #{immed()}
added	6T2
begin
	// tst
	if(t32_check_condition(cpu))
	{
		a32_tst32(cpu, $r[${n}], ${immed()}, IGNORE_RESULT);
	}
end

code	111010100001nnnn @iii1111iiiimmmm
asm	tst{cond()} r{n}, r{m}{shift()}
added	6T2
begin
	// tst
	if(t32_check_condition(cpu))
	{
		a32_tst32(cpu, $r[${n}], ${operand(1)}, IGNORE_RESULT);
	}
end

#### Shifts, rotations and register move

code	11101010010S1111 @iiiddddii10mmmm
asm	asr{S?s:}{cond()} r{d}, r{m}, #{positive(i)}
added	6T2
begin
	// asr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_asr32(cpu, $r[${m}], ${positive(i)}, ${S!test});
	}
end

code	11111010010Snnnn 1111dddd0000mmmm
asm	asr{S?s:}{cond()} r{d}, r{n}, r{m}
added	6T2
begin
	// asr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_asr32(cpu, $r[${n}], $r[${m}], ${S!test});
	}
end

code	11101010010S1111 @iiiddddii00mmmm
exclude	................ .000....00......
asm	lsl{S?s:}{cond()} r{d}, r{m}, #{i}
added	6T2
begin
	// lsl
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_lsl32(cpu, $r[${m}], ${i}, ${S!test});
	}
end

code	11101010010S1111 @000dddd0000mmmm
asm	mov{S?s:}{cond()} r{d}, r{m}
added	6T2
begin
	// mov
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mov32(cpu, $r[${m}], ${S!test}, false);
	}
end

code	11111010000Snnnn 1111dddd0000mmmm
asm	lsl{S?s:}{cond()} r{d}, r{n}, r{m}
added	6T2
begin
	// lsl
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_lsl32(cpu, $r[${n}], $r[${m}], ${S!test});
	}
end

code	11101010010S1111 @iiiddddii01mmmm
asm	lsr{S?s:}{cond()} r{d}, r{m}, #{positive(i)}
added	6T2
begin
	// lsr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_lsr32(cpu, $r[${m}], ${positive(i)}, ${S!test});
	}
end

code	11111010001Snnnn 1111dddd0000mmmm
asm	lsr{S?s:}{cond()} r{d}, r{n}, r{m}
added	6T2
begin
	// lsr
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_lsr32(cpu, $r[${n}], $r[${m}], ${S!test});
	}
end

code	11101010010S1111 @iiiddddii11mmmm
exclude	................ .000....00......
asm	ror{S?s:}{cond()} r{d}, r{m}, #{i}
added	6T2
begin
	// ror
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_ror32(cpu, $r[${m}], ${i}, ${S!test});
	}
end

code	11101010010S1111 @000dddd0011mmmm
asm	rrx{S?s:}{cond()} r{d}, r{m}
added	6T2
begin
	// rrx
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_rrx32(cpu, $r[${m}], ${S!test});
	}
end

code	11111010011Snnnn 1111dddd0000mmmm
asm	ror{S?s:}{cond()} r{d}, r{n}, r{m}
added	6T2
begin
	// ror
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_ror32(cpu, $r[${n}], $r[${m}], ${S!test});
	}
end

#### Others

code	11110Acccciiiiii 10C0Biiiiiiiiiii
exclude	......111....... ................
it	no
asm	b{cond(c)} {signextend A'B'C'i'0!offset}
added	6T2
begin
	// b
	if($c[${c}])
	{
		$pc = ${signextend A'B'C'i'0!offset};
	}
end

code	11110iiiiiiiiiii 10i1iiiiiiiiiiii
it	end
asm	b{cond()} {t32label()}
added	6T2
begin
	// b
	if(t32_check_condition(cpu))
	{
		$pc = ${t32label()};
	}
end

code	11110@1101101111 0lllddddll@mmmmm
asm	bfc{cond()} r{d}, #{l}, #{m-l+1}
added	6T2
begin
	// bfc
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_bfc32(cpu, $r[${d}], ${l}, ${m});
	}
end

code	11110@110110nnnn 0lllddddll@mmmmm
exclude	............1111 ................
asm	bfi{cond()} r{d}, r{n}, #{l}, #{m-l+1}
added	6T2
begin
	// bfi
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_bfi32(cpu, $r[${d}], $r[${n}], ${l}, ${m});
	}
end

code	111100111100mmmm 10@0!!!!@@@@@@@@
it	end
asm	bxj{cond()} r{m}
added	6T2
begin
	// bxj
	if(t32_check_condition(cpu))
	{
		a32_bxj(cpu, $r[${m}]);
	}
end

code	111E1110aaaannnn ddddCCCCbbb0mmmm
asm	cdp{E?2:}{cond()} {C}, {a}, cr{d}, cr{n}, cr{m}, {b}
coproc	cdp
added	6T2
begin
	// cdp/cdp2
	if(t32_check_condition(cpu))
	{
		t32_perform_cdp(cpu, opcode1, opcode2);
	}
end

code	111110101011.... 1111dddd1000mmmm
asm	clz{cond()} r{d}, r{m}
added	6T2
begin
	// clz
	if(t32_check_condition(cpu))
	{
		$r[${d}] = clz32($r[${m}]);
	}
end

code	111100111010!!!! 10@0@1D0AIF@@@@@
it	no
asm	cpsi{D?d:e} {A?a:}{I?i:}{F?f:}
added	6T2
begin
	// cps
	if(${A!test})
		$cpsr.a = ${D};
	if(${I!test})
		$cpsr.i = ${D};
	if(${F!test})
		$cpsr.f = ${D};
end

code	111100111010!!!! 10@0@1D1AIFMMMMM
asm	cpsi{D?d:e} {A?a:}{I?i:}{F?f:}, #{M}
added	6T2
begin
	// cps
	if(${A!test})
		$cpsr.a = ${D};
	if(${I!test})
		$cpsr.i = ${D};
	if(${F!test})
		$cpsr.f = ${D};
	$cpsr.mode = ${M};
end

code	111100111010!!!! 10@0@001@@@MMMMM
asm	cps #{M}
added	6T2
begin
	// cps
	$cpsr.mode = ${M};
end

code	111100111010!!!! 10@0@00000010100
asm	csdb{cond()}
added	6T2
begin
	// csdb
end

code	111100111010!!!! 10@0@0001111oooo
asm	dbg{cond()} #{o:X}
added	6T2
begin
	// dbg
end

code	111E1101UNWLnnnn ddddCCCCoooooooo
asm	{L?ldc:stc}{E?2:}{N?l:}{cond()} {C}, cr{d}, [r{n}, #{U?:-}{o'00:X}]{W?!:}
coproc	ldc
added	6T2
begin
	// ldc/stc/ldc2/stc2
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${o'00};

		if(!${U!test})
		{
			offset = -offset;
		}

		t32_perform_ldc_stc(cpu, opcode1, opcode2, ${n}, offset, PREINDEXED, ${W!test});
	}
end

code	111E1100UN1Lnnnn ddddCCCCoooooooo
asm	{L?ldc:stc}{E?2:}{N?l:}{cond()} {C}, cr{d}, [r{n}], #{U?:-}{o'00:X}
coproc	ldc
added	6T2
begin
	// ldc/stc/ldc2/stc2
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${o'00};

		if(!${U!test})
		{
			offset = -offset;
		}

		t32_perform_ldc_stc(cpu, opcode1, opcode2, ${n}, offset, POSTINDEXED, WRITEBACK);
	}
end

code	111E11001N0Lnnnn ddddCCCCoooooooo
asm	{L?ldc:stc}{E?2:}{N?l:}{cond()} {C}, cr{d}, [r{n}], {o}
coproc	ldc
added	6T2
begin
	// ldc/stc/ldc2/stc2
	if(t32_check_condition(cpu))
	{
		t32_perform_ldc_stc(cpu, opcode1, opcode2, ${n}, 0, NOINDEX, NOWRITEBACK);
	}
end

code	1110100PU0WLnnnn llllllllllllllll
exclude	.......00....... ................
exclude	.......11....... ................
asm	{L?ldm:stm}{U?i:d}{P?b:a}{cond()} r{n}{W?!:}, {reglist(l)}
added	6T2
begin
	// ldm/stm
	if(t32_check_condition(cpu))
	{
		if(${L!test})
		{
			a32_ldm(cpu, ${l}, ${n}, ${U!test}, ${P!test}, ${W!test}, false);
		}
		else
		{
			a32_stm(cpu, ${l}, ${n}, ${U!test}, ${P!test}, ${W!test}, false);
		}
	}
end

code	1111100S1BHLnnnn ttttiiiiiiiiiiii
exclude	.........11..... ................
exclude	.......1.00..... ................
exclude	.......1...0.... ................
exclude	.........1.1.... 1111............
exclude	..........11.... 1111............
exclude	...........01111 ................
asm	{L?ldr:str}{S?s:}{B?:b}{H?h:}{cond()} r{t}, [r{n}, #{i:X}]
added	6T2
begin
	// ldr/str/ldrb/strb/ldrh/strh/ldrsb/ldrsh
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i};

		if(${L!test})
		{
			if(${B!test})
			{
				$r.v5[${t}] = a32_ldr(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
			}
			else if(${S!test})
			{
				if(${H!test})
				{
					$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
				}
				else
				{
					$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
				}
			}
			else
			{
				if(${H!test})
				{
					$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
				}
				else
				{
					$r.v5[${t}] = a32_ldrb(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
				}
			}
		}
		else
		{
			if(${B!test})
			{
				a32_str(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
			}
			else
			{
				if(${H!test})
				{
					a32_strh(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
				}
				else
				{
					a32_strb(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
				}
			}
		}
	}
end

code	1111100S0BHLnnnn tttt11UWiiiiiiii
exclude	.........11..... ................
exclude	.......1.00..... ................
exclude	.......1...0.... ................
exclude	................ ......10........
exclude	.........1.1.... 1111..00........
exclude	..........11.... 1111..00........
exclude	...........01111 ................
asm	{L?ldr:str}{S?s:}{B?:b}{H?h:}{cond()} r{t}, [r{n}, #{U?:-}{i:X}]{W?!:}
added	6T2
begin
	// ldr/str
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i};
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${L!test})
		{
			if(${B!test})
			{
				$r.v5[${t}] = a32_ldr(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
			else if(${S!test})
			{
				if(${H!test})
				{
					$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
				}
				else
				{
					$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
				}
			}
			else
			{
				if(${H!test})
				{
					$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
				}
				else
				{
					$r.v5[${t}] = a32_ldrb(cpu, ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
				}
			}
		}
		else
		{
			if(${B!test})
			{
				a32_str(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
			}
			else
			{
				if(${H!test})
				{
					a32_strh(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
				}
				else
				{
					a32_strb(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, ${W!test}, USE_DEFAULT_MODE);
				}
			}
		}
	}
end

code	1111100S0BHLnnnn tttt10U1iiiiiiii
exclude	.........11..... ................
exclude	.......1.00..... ................
exclude	.......1...0.... ................
exclude	...........01111 ................
asm	{L?ldr:str}{S?s:}{B?:b}{H?h:}{cond()} r{t}, [r{n}], #{U?:-}{i:X}
added	6T2
begin
	// ldr/str
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i};
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${L!test})
		{
			if(${B!test})
			{
				$r.v5[${t}] = a32_ldr(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
			}
			else if(${S!test})
			{
				if(${H!test})
				{
					$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
				else
				{
					$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
			}
			else
			{
				if(${H!test})
				{
					$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
				else
				{
					$r.v5[${t}] = a32_ldrb(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
			}
		}
		else
		{
			if(${B!test})
			{
				a32_str(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
			}
			else
			{
				if(${H!test})
				{
					a32_strh(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
				else
				{
					a32_strb(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
			}
		}
	}
end

code	1111100S0BHLnnnn tttt000000iimmmm
exclude	.........11..... ................
exclude	.......1.00..... ................
exclude	.......1...0.... ................
exclude	.........1.1.... 1111............
exclude	..........11.... 1111............
exclude	...........01111 ................
asm	{L?ldr:str}{S?s:}{B?:b}{H?h:}{cond()} r{t}, [r{n}, r{m}, lsl #{i}]
added	6T2
begin
	// ldr/str
	if(t32_check_condition(cpu))
	{
		uint32_t offset = $r[${m}] << ${i};

		if(${L!test})
		{
			if(${B!test})
			{
				$r.v5[${t}] = a32_ldr(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
			}
			else if(${S!test})
			{
				if(${H!test})
				{
					$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
				else
				{
					$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
			}
			else
			{
				if(${H!test})
				{
					$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
				else
				{
					$r.v5[${t}] = a32_ldrb(cpu, ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
			}
		}
		else
		{
			if(${B!test})
			{
				a32_str(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
			}
			else
			{
				if(${H!test})
				{
					a32_strh(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
				else
				{
					a32_strb(cpu, $r.str[${t}], ${n}, offset, POSTINDEXED, WRITEBACK, USE_DEFAULT_MODE);
				}
			}
		}
	}
end

code	1111100S0BHLnnnn tttt1110iiiiiiii
exclude	.........11..... ................
exclude	.......1.00..... ................
exclude	.......1...0.... ................
asm	{L?ldr:str}{S?s:}{B?:b}{H?h:}t{cond()} r{t}, [r{n}, #{i:2X}]
added	6T2
begin
	// ldrt/strt/ldrbt/strbt/ldrht/strht/lstrsbt/ldrsht
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i};

		if(${L!test})
		{
			if(${B!test})
			{
				$r.v5[${t}] = a32_ldr(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_USER_MODE);
			}
			else if(${S!test})
			{
				if(${H!test})
				{
					$r.v5[${t}] = a32_ldrsh(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_USER_MODE);
				}
				else
				{
					$r.v5[${t}] = a32_ldrsb(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_USER_MODE);
				}
			}
			else
			{
				if(${H!test})
				{
					$r.v5[${t}] = a32_ldrh(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_USER_MODE);
				}
				else
				{
					$r.v5[${t}] = a32_ldrb(cpu, ${n}, offset, PREINDEXED, NOWRITEBACK, USE_USER_MODE);
				}
			}
		}
		else
		{
			if(${B!test})
			{
				a32_str(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, NOWRITEBACK, USE_USER_MODE);
			}
			else
			{
				if(${H!test})
				{
					a32_strh(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, NOWRITEBACK, USE_USER_MODE);
				}
				else
				{
					a32_strb(cpu, $r.str[${t}], ${n}, offset, PREINDEXED, NOWRITEBACK, USE_USER_MODE);
				}
			}
		}
	}
end

code	111010000101nnnn tttt!!!!iiiiiiii
asm	ldrex{cond()} r{t}, [r{n}, #{i:2X}]
added	6T2
begin
	// ldrex
	if(t32_check_condition(cpu))
	{
		$r.v5[${t}] = a32_ldrex(cpu, ${n}, ${i});
	}
end

code	111010000100nnnn ttttddddiiiiiiii
asm	strex{cond()} r{d}, r{t}, [r{n}, #{i:2X}]
added	6T2
begin
	// strex
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_strex(cpu, $r.str[${t}], ${n}, ${i});
	}
end

code	111010001101nnnn tttt!!!!010H!!!!
asm	ldrex{H?h:b}{cond()} r{t}, [r{n}]
added	6T2
begin
	// ldrexh
	if(t32_check_condition(cpu))
	{
		if(${H!test})
		{
			$r.v5[${t}] = a32_ldrexh(cpu, ${n}, 0);
		}
		else
		{
			$r.v5[${t}] = a32_ldrexb(cpu, ${n}, 0);
		}
	}
end

code	111010001100nnnn ttttdddd010H!!!!
asm	strex{H?h:b}{cond()} r{d}, r{t}, [r{n}]
added	6T2
begin
	// strexb/strexh
	if(t32_check_condition(cpu))
	{
		if(${H!test})
		{
			$r[${d}] = a32_strexh(cpu, $r.str[${t}], ${n}, 0);
		}
		else
		{
			$r[${d}] = a32_strexb(cpu, $r.str[${t}], ${n}, 0);
		}
	}
end

code	11101001U1WLnnnn ttttTTTTiiiiiiii
asm	{L?ldr:str}d{cond()} r{t}, r{T}, [r{n}, #{U?:-}{i:2X}]{W?!:}
added	6T2
begin
	// ldrd/strd
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i};
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${L!test})
		{
			a32_ldrd(cpu, ${t}, ${T}, ${n}, offset, PREINDEXED, ${W!test});
		}
		else
		{
			a32_strd(cpu, ${t}, ${T}, ${n}, offset, PREINDEXED, ${W!test});
		}
	}
end

code	11101000U11Lnnnn ttttTTTTiiiiiiii
asm	{L?ldr:str}d{cond()} r{t}, r{T}, [r{n}, #{U?:-}{i:2X}]
added	6T2
begin
	// ldrd/strd
	if(t32_check_condition(cpu))
	{
		uint32_t offset = ${i};
		if(!${U!test})
		{
			offset = -offset;
		}

		if(${L!test})
		{
			a32_ldrd(cpu, ${t}, ${T}, ${n}, offset, POSTINDEXED, WRITEBACK);
		}
		else
		{
			a32_strd(cpu, ${t}, ${T}, ${n}, offset, POSTINDEXED, WRITEBACK);
		}
	}
end

code	111010001101nnnn ttttTTTT0111!!!!
asm	ldrexd{cond()} r{t}, r{T}, [r{n}]
added	6T2, except 7-M
begin
	// ldrexd
	if(t32_check_condition(cpu))
	{
		a32_ldrexd(cpu, ${t}, ${T}, ${n}, 0);
	}
end

code	111010001100nnnn ttttTTTT0111dddd
asm	strexd{cond()} r{d}, r{t}, r{T}, [r{n}]
added	6T2, except 7-M
begin
	// strexd
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_strexd(cpu, ${t}, ${T}, ${n}, 0);
	}
end

code	111E1110aaa0nnnn ddddCCCCbbb1mmmm
asm	mcr{E?2:}{cond()} {C}, {a}, r{d}, cr{n}, cr{m}, {b}
coproc	mcr
added	6T2
begin
	// mcr/mcr2
	if(t32_check_condition(cpu))
	{
		t32_perform_mcr(cpu, opcode1, opcode2, ${d});
	}
end

code	111E1110aaa1nnnn ddddCCCCbbb1mmmm
asm	mrc{E?2:}{cond()} {C}, {a}, r{d}, cr{n}, cr{m}, {b}
coproc	mrc
added	6T2
begin
	// mrc/mrc2
	if(t32_check_condition(cpu))
	{
		t32_perform_mrc(cpu, opcode1, opcode2, ${d});
	}
end

code	111E11000100TTTT ttttCCCCaaaammmm
asm	mcrr{E?2:}{cond()} {C}, {a}, r{t}, r{T}, cr{m}
coproc	mcrr
added	6T2
begin
	// mcrr/mcrr2
	if(t32_check_condition(cpu))
	{
		t32_perform_mcrr(cpu, opcode1, opcode2, ${t}, ${T});
	}
end

code	111E11000101TTTT ttttCCCCaaaammmm
asm	mrrc{E?2:}{cond()} {C}, {a}, r{t}, r{T}, cr{m}
coproc	mrrc
added	6T2
begin
	// mrrc/mrrc2
	if(t32_check_condition(cpu))
	{
		t32_perform_mrrc(cpu, opcode1, opcode2, ${t}, ${T});
	}
end

code	111110110000nnnn aaaadddd0000mmmm
exclude	................ 1111............
asm	mla{cond()} r{d}, r{n}, r{m}, r{a}
added	6T2
begin
	// mla
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mla32(cpu, $r[${n}], $r[${m}], $r[${a}], false);
	}
end

code	111110110000nnnn aaaadddd0001mmmm
asm	mls{cond()} r{d}, r{n}, r{m}, r{a}
added	6T2
begin
	// mls
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mls32($r[${n}], $r[${m}], $r[${a}]);
	}
end

code	111110110000nnnn 1111dddd0000mmmm
asm	mul{cond()} r{d}, r{n}, r{m}
added	4T
begin
	// mul
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_mul32(cpu, $r[${n}], $r[${m}], false);
	}
end

code	11110i101100IIII 0iiiddddiiiiiiii
asm	movt{cond()} r{d}, #{I'i:X}
added	6T2
begin
	// movt
	if(t32_check_condition(cpu))
	{
		$r[${d}] = (${I'i} << 16) | ($r[${d}] & 0x0000FFFF);
	}
end

code	11110011111S!!!! 10@0dddd@@0@@@@@
asm	mrs{cond()} r{d}, {S?s:c}psr
added	6T2, 6-M
begin
	// mrs
	if(t32_check_condition(cpu))
	{
		if(${S!test})
			$r[${d}] = $spsr;
		else
			$r[${d}] = $cpsr;
	}
end

code	11110011100Snnnn 10@0FXsC@@0@@@@@
asm	msr{cond()} {S?s:c}psr_{F?f:}{X?x:}{s?s:}{C?c:}, r{n}
added	6T2, 6-M
begin
	// msr
	if(t32_check_condition(cpu))
	{
		if(${S!test})
			a32_set_spsr(cpu, get_cpsr_spsr_mask(${F!test}, ${X!test}, ${s!test}, ${C!test}), $r[${n}]);
		else
			a32_set_cpsr(cpu, get_cpsr_spsr_mask(${F!test}, ${X!test}, ${s!test}, ${C!test}), $r[${n}]);
	}
end

code	111100111010!!!! 10@0@00000000000
asm	nop{cond()}
added	6T2
begin
	// nop
end

code	111010101100nnnn @iiiddddii00mmmm
asm	pkhbt{cond()} r{d}, r{n}, r{m}, lsl #{i}
added	6T2, 7E-M
begin
	// pkhbt
	if(t32_check_condition(cpu))
	{
		$r[${d}] = ($r[${n}] & 0x0000FFFF) | (($r[${m}] << ${i}) & 0xFFFF0000);
	}
end

code	111010101100nnnn @iiiddddii10mmmm
asm	pkhtb{cond()} r{d}, r{n}, r{m}, asr #{positive(i)}
added	6T2
begin
	// pkhtb
	if(t32_check_condition(cpu))
	{
		if(${i} == 0)
			$r[${d}] = ($r[${n}] & 0xFFFF0000) | ($r[${m}] & 0x80000000 ? 0xFFFF0000 : 0);
		else
			$r[${d}] = ($r[${n}] & 0xFFFF0000) | (((int32_t)$r[${m}] >> ${i}) & 0xFFFF0000);
	}
end

code	111110001001nnnn 1111iiiiiiiiiiii
asm	pld{cond()} [r{n}, #{i:4X}]
added	6T2
begin
	// pld
end

code	111110000001nnnn 11111100iiiiiiii
asm	pld{cond()} [r{n}, #-{i:4X}]
added	6T2
begin
	// pld
end

code	111110000001nnnn 1111000000iimmmm
asm	pld{cond()} [r{n}, r{m}, lsl #{i}]
added	6T2
begin
	// pld
end

code	111110001011nnnn 1111iiiiiiiiiiii
asm	pldw{cond()} [r{n}, #{i:4X}]
added	7+mp
begin
	// pldw
end

code	111110000011nnnn 11111100iiiiiiii
asm	pldw{cond()} [r{n}, #-{i:4X}]
added	7+mp
begin
	// pldw
end

code	111110000011nnnn 1111000000iimmmm
asm	pldw{cond()} [r{n}, r{m}, lsl #{i}]
added	7+mp
begin
	// plds
end

code	111110101000nnnn 1111dddd1000mmmm
asm	qadd{cond()} r{d}, r{m}, r{n}
added	6T2, 7E-M
begin
	// qadd
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_qadd32(cpu, $r[${m}], $r[${n}]);
	}
end

code	111110101001nnnn 1111dddd0U01mmmm
asm	{U?u:}qadd16{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// qadd16/uqadd16
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = qadd16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)qadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		else
			$r[${d}] = uqadd16($r[${n}], $r[${m}]) | ((uint32_t)uqadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
	}
end

code	111110101000nnnn 1111dddd0U01mmmm
asm	{U?u:}qadd8{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// qadd8/uqadd8
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = qadd8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)qadd8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)qadd8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)qadd8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
		else
			$r[${d}] = uqadd8($r[${n}], $r[${m}]) | ((uint32_t)uqadd8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)uqadd8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)uqadd8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
	}
end

code	111110101010nnnn 1111dddd0U01mmmm
asm	{U?u:}qasx{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// qaddsubx/uqaddsubx or qasx/uqasx
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = uqsub16($r[${n}], $r[${m}] >> 16) | ((uint32_t)uqadd16($r[${n}] >> 16, $r[${m}]) << 16);
		else
			$r[${d}] = qsub16($r[${n}], $r[${m}] >> 16) | ((uint32_t)(uint16_t)qadd16($r[${n}] >> 16, $r[${m}]) << 16);
	}
end

code	111110101000nnnn 1111dddd1001mmmm
asm	qdadd{cond()} r{d}, r{m}, r{n}
added	6T2, 7E-M
begin
	// qdadd
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_qdadd32(cpu, $r[${m}], $r[${n}]);
	}
end

code	111110101000nnnn 1111dddd1011mmmm
asm	qdsub{cond()} r{d}, r{m}, r{n}
added	6T2, 7E-M
begin
	// qdsub
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_qdsub32(cpu, $r[${m}], $r[${n}]);
	}
end

code	111110101110nnnn 1111dddd0U01mmmm
asm	{U?u:}qsax{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// qsubaddx/uqsubaddx or qsax/uqsax
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = uqadd16($r[${n}], $r[${m}] >> 16) | ((uint32_t)uqsub16($r[${n}] >> 16, $r[${m}]) << 16);
		else
			$r[${d}] = qadd16($r[${n}], $r[${m}] >> 16) | ((uint32_t)(uint16_t)qsub16($r[${n}] >> 16, $r[${m}]) << 16);
	}
end

code	111110101000nnnn 1111dddd1010mmmm
asm	qsub{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// qsub
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_qsub32(cpu, $r[${m}], $r[${n}]);
	}
end

code	111110101101nnnn 1111dddd0U01mmmm
asm	{U?u:}qsub16{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// qsub16/uqsub16
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = qsub16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)qsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		else
			$r[${d}] = uqsub16($r[${n}], $r[${m}]) | ((uint32_t)uqsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
	}
end

code	111110101100nnnn 1111dddd0U01mmmm
asm	{U?u:}qsub8{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// qsub8/uqsub8
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = qsub8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)qsub8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)qsub8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)qsub8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
		else
			$r[${d}] = uqsub8($r[${n}], $r[${m}]) | ((uint32_t)uqsub8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)uqsub8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)uqsub8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
	}
end

code	111110101001nnnn 1111dddd0UH0mmmm
asm	{U?u:s}{H?h:}add16{cond()} r{d}, r{m}, r{n}
added	6T2, 7E-M
begin
	// sadd16/uadd16/shadd16/uhadd16
	if(t32_check_condition(cpu))
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhadd16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_uhadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
			else
				$r[${d}] = a32_shadd16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_shadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_uadd16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_uadd16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
			else
				$r[${d}] = a32_sadd16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_sadd16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
		}
	}
end

code	111110101000nnnn 1111dddd0UH0mmmm
asm	{U?u:s}{H?h:}add8{cond()} r{d}, r{m}, r{n}
added	6T2, 7E-M
begin
	// sadd8/uadd8/shadd8/uhadd8
	if(t32_check_condition(cpu))
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhadd8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)a32_uhadd8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)a32_uhadd8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)a32_uhadd8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
			else
				$r[${d}] = a32_shadd8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)a32_shadd8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)a32_shadd8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)a32_shadd8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_uadd8(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint8_t)a32_uadd8(cpu, $r[${n}] >> 8, $r[${m}] >> 8, 1) << 8) | ((uint32_t)(uint8_t)a32_uadd8(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16) | ((uint32_t)(uint8_t)a32_uadd8(cpu, $r[${n}] >> 24, $r[${m}] >> 24, 3) << 24);
			else
				$r[${d}] = a32_sadd8(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint8_t)a32_sadd8(cpu, $r[${n}] >> 8, $r[${m}] >> 8, 1) << 8) | ((uint32_t)(uint8_t)a32_sadd8(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16) | ((uint32_t)(uint8_t)a32_sadd8(cpu, $r[${n}] >> 24, $r[${m}] >> 24, 3) << 24);
		}
	}
end

code	111110101010nnnn 1111dddd0UH0mmmm
asm	{U?u:s}{H?h:}asx{cond()} r{d}, r{m}, r{n}
added	6T2, 7E-M
begin
	// saddsubx/uaddsubx/shaddsubx/uhaddsubx or sasx/uasx/shasx/uhasx
	if(t32_check_condition(cpu))
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhsub16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_uhadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
			else
				$r[${d}] = a32_shsub16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_shadd16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_usub16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_uadd16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
			else
				$r[${d}] = a32_ssub16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_sadd16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
		}
	}
end

code	111110101110nnnn 1111dddd0UH0mmmm
asm	{U?u:s}{H?h:}sax{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// ssubaddx/usubaddx/shsubaddx/uhsubaddx or ssax/usax/shsax/uhsax
	if(t32_check_condition(cpu))
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhadd16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_uhsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
			else
				$r[${d}] = a32_shadd16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_shsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_uadd16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_usub16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
			else
				$r[${d}] = a32_sadd16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_ssub16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
		}
	}
end

code	111110101101nnnn 1111dddd0UH0mmmm
asm	{U?u:s}{H?h:}sub16{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// ssub16/usub16/shsub16/uhsub16
	if(t32_check_condition(cpu))
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhsub16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_uhsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
			else
				$r[${d}] = a32_shsub16($r[${n}], $r[${m}]) | ((uint32_t)(uint16_t)a32_shsub16($r[${n}] >> 16, $r[${m}] >> 16) << 16);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_usub16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_usub16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
			else
				$r[${d}] = a32_ssub16(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint16_t)a32_ssub16(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16);
		}
	}
end

code	111110101100nnnn 1111dddd0UH0mmmm
asm	{U?u:s}{H?h:}sub8{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// ssub8/usub8/shsub8/uhsub8
	if(t32_check_condition(cpu))
	{
		if(${H!test})
		{
			if(${U!test})
				$r[${d}] = a32_uhsub8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)a32_uhsub8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)a32_uhsub8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)a32_uhsub8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
			else
				$r[${d}] = a32_shsub8($r[${n}], $r[${m}]) | ((uint32_t)(uint8_t)a32_shsub8($r[${n}] >> 8, $r[${m}] >> 8) << 8) | ((uint32_t)(uint8_t)a32_shsub8($r[${n}] >> 16, $r[${m}] >> 16) << 16) | ((uint32_t)(uint8_t)a32_shsub8($r[${n}] >> 24, $r[${m}] >> 24) << 24);
		}
		else
		{
			if(${U!test})
				$r[${d}] = a32_usub8(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint8_t)a32_usub8(cpu, $r[${n}] >> 8, $r[${m}] >> 8, 1) << 8) | ((uint32_t)(uint8_t)a32_usub8(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16) | ((uint32_t)(uint8_t)a32_usub8(cpu, $r[${n}] >> 24, $r[${m}] >> 24, 3) << 24);
			else
				$r[${d}] = a32_ssub8(cpu, $r[${n}], $r[${m}], 0) | ((uint32_t)(uint8_t)a32_ssub8(cpu, $r[${n}] >> 8, $r[${m}] >> 8, 1) << 8) | ((uint32_t)(uint8_t)a32_ssub8(cpu, $r[${n}] >> 16, $r[${m}] >> 16, 2) << 16) | ((uint32_t)(uint8_t)a32_ssub8(cpu, $r[${n}] >> 24, $r[${m}] >> 24, 3) << 24);
		}
	}
end

code	111110101001mmmm 1111dddd1010mmmm
asm	rbit{cond()} r{d}, r{m}
added	6T2
begin
	// rbit
	if(t32_check_condition(cpu))
	{
		$r[${d}] = rbit32($r[${m}]);
	}
end

code	111110101001mmmm 1111dddd1000mmmm
asm	rev{cond()} r{d}, r{m}
added	6T2
begin
	// rev
	if(t32_check_condition(cpu))
	{
		$r[${d}] = bswap_32($r[${m}]);
	}
end

code	111110101001mmmm 1111dddd1001mmmm
asm	rev16{cond()} r{d}, r{m}
added	6T2
begin
	// rev16
	if(t32_check_condition(cpu))
	{
		uint32_t value = $r[${m}];
		$r[${d}] = bswap_16(value) | (bswap_16(value >> 16) << 16);
	}
end

code	111110101001mmmm 1111dddd1011mmmm
asm	revsh{cond()} r{d}, r{m}
added	6T2
begin
	// revsh
	if(t32_check_condition(cpu))
	{
		$r[${d}] = sign_extend(16, bswap_16($r[${m}]));
	}
end

code	11110@11U100nnnn 0lllddddll@wwwww
asm	{U?u:s}bfx{cond()} r{d}, r{n}, #{l}, #{w+1}
added	6T2
begin
	// sbfx/ubfx
	if(t32_check_condition(cpu))
	{
		uint32_t value = $r[${n}] >> ${l};
		if(${U!test} || ((value >> ${w}) & 1) != 0)
			value &= (1 << ${w}) - 1;
		else
			value |= -1 << ${w};
		$r[${d}] = value;
	}
end

code	111110101010nnnn 1111dddd1000mmmm
asm	sel{cond()} r{d}, r{n}, r{m}
added	6T2, 7E-M
begin
	// sel
	if(t32_check_condition(cpu))
	{
		uint32_t a = $r[${n}];
		uint32_t b = $r[${m}];
		uint32_t value = 0;
		value |= ($cpsr.ge0 ? a : b) & 0x000000FF;
		value |= ($cpsr.ge1 ? a : b) & 0x0000FF00;
		value |= ($cpsr.ge2 ? a : b) & 0x00FF0000;
		value |= ($cpsr.ge3 ? a : b) & 0xFF000000;
		$r[${d}] = value;
	}
end

code	111110110001mmmm nnnndddd00xyssss
exclude	................ 1111............
asm	smla{x?t:b}{y?t:b}{cond()} r{d}, r{m}, r{s}, r{n}
added	6T2, 7E-M
begin
	// smla
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_smla32(cpu, ${x!test} ? $r[${m}] >> 16 : $r[${m}], ${y!test} ? $r[${s}] >> 16 : $r[${s}], $r[${n}]);
	}
end

code	111110110001mmmm 1111dddd00xyssss
asm	smul{x?t:b}{y?t:b}{cond()} r{d}, r{m}, r{s}
added	6T2, 7E-M
begin
	// smul
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_smul32(cpu, ${x!test} ? $r[${m}] >> 16 : $r[${m}], ${y!test} ? $r[${s}] >> 16 : $r[${s}]);
	}
end

code	111110111100mmmm llllhhhh10xyssss
asm	smlal{x?t:b}{y?t:b}{cond()} r{l}, r{h}, r{m}, r{s}
added	6T2, 7E-M
begin
	// smlal
	if(t32_check_condition(cpu))
	{
		a32_smlal64(cpu, ${l}, ${h}, ${x!test} ? $r[${m}] >> 16 : $r[${m}], ${y!test} ? $r[${s}] >> 16 : $r[${s}]);
	}
end

code	111110110011mmmm nnnndddd000yssss
exclude	................ 1111............
asm	smlaw{y?t:b}{cond()} r{d}, r{m}, r{s}, r{n}
added	6T2, 7E-M
begin
	// smlaw
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_smlaw32(cpu, $r[${m}], ${y!test} ? $r[${s}] >> 16 : $r[${s}], $r[${n}]);
	}
end

code	111110110011mmmm 1111dddd000yssss
asm	smulw{y?t:b}{cond()} r{d}, r{m}, r{s}
added	6T2, 7E-M
begin
	// smulw
	if(t32_check_condition(cpu))
	{
		$r[${d}] = a32_smulw32(cpu, $r[${m}], ${y!test} ? $r[${s}] >> 16 : $r[${s}]);
	}
end

code	111110110010mmmm nnnndddd000Xssss
exclude	................ 1111............
asm	smlad{X?x:}{cond()} r{d}, r{m}, r{s}, r{n}
added	6T2, 7E-M
begin
	// smlad
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111110110010mmmm 1111dddd000Xssss
asm	smuad{X?x:}{cond()} r{d}, r{m}, r{s}
added	6T2, 7E-M
begin
	// smuad
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111110111100mmmm nnnndddd110Xssss
asm	smlald{X?x:}{cond()} r{d}, r{m}, r{s}, r{n}
added	6T2, 7E-M
begin
	// smlald
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111110110100mmmm nnnndddd000Xssss
exclude	................ 1111............
asm	smlsd{X?x:}{cond()} r{d}, r{m}, r{s}, r{n}
added	6T2, 7E-M
begin
	// smlsd
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111110110100mmmm 1111dddd000Xssss
asm	smusd{X?x:}{cond()} r{d}, r{m}, r{s}
added	6T2, 7E-M
begin
	// smusd
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111110111101mmmm nnnndddd110Xssss
asm	smlsld{X?x:}{cond()} r{d}, r{m}, r{s}, r{n}
added	6T2, 7E-M
begin
	// smlsd
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111110111au0mmmm ddddnnnn0000ssss
asm	{u?u:s}{a?mla:mul}l{cond()} r{d}, r{n}, r{m}, r{s}
added	6T2
begin
	// smull/umull/smlal/umlal
	if(t32_check_condition(cpu))
	{
		if(${u!test})
		{
			a32_umlal32(cpu, ${d}, ${n}, $r[${m}], $r[${s}], false, ${a!test});
		}
		else
		{
			a32_smlal32(cpu, ${d}, ${n}, $r[${m}], $r[${s}], false, ${a!test});
		}
	}
end

code	111110110101mmmm nnnndddd000Rssss
exclude	................ 1111............
asm	smmla{R?r:}{cond()} r{d}, r{m}, r{s}, r{n}
added	6T2, 7E-M
begin
	// smmla
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111110110101mmmm 1111dddd000Rssss
asm	smmul{R?r:}{cond()} r{d}, r{m}, r{s}
added	6T2, 7E-M
begin
	// smmul
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111110110110mmmm nnnndddd000Rssss
asm	smmls{R?r:}{cond()} r{d}, r{m}, r{s}, r{n}
added	6T2, 7E-M
begin
	// smmls
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	11110@11U0h0mmmm 0IIIddddII@iiiii
exclude	................ .000....00......
asm	{U?u:s}sat{cond()} r{d}, #{i+1}, r{m}, {h?asr:lsl} #{I}
added	6T2
begin
	// ssat/usat
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	11110@11U000mmmm 0000dddd00@iiiii
asm	{U?u:s}sat{cond()} r{d}, #{i+1}, r{m}
added	6T2
begin
	// ssat/usat
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	11110@11U010mmmm 0000dddd00@@iiii
asm	{U?u:s}sat16{cond()} r{d}, #{i+1}, r{m}
added	6T2, 7E-M
begin
	// ssat16/usat16
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	11111010010Unnnn 1111dddd1@rrmmmm
exclude	............1111 ................
asm	{U?u:s}xtab{cond()} r{d}, r{n}, r{m}, ror #{r*8}
added	6T2, 7E-M
begin
	// sxtab/uxtab
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = $r[${n}] + uxtb32($r[${m}], ${r} * 8);
		else
			$r[${d}] = $r[${n}] + sxtb32($r[${m}], ${r} * 8);
	}
end

code	11111010010U1111 1111dddd1@rrmmmm
asm	{U?u:s}xtb{cond()} r{d}, r{m}, ror #{r*8}
added	6T2
begin
	// sxtb/uxtb
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = uxtb32($r[${m}], ${r} * 8);
		else
			$r[${d}] = sxtb32($r[${m}], ${r} * 8);
	}
end

code	11111010001Unnnn 1111dddd1@rrmmmm
exclude	............1111 ................
asm	{U?u:s}xtab16{cond()} r{d}, r{n}, r{m}, ror #{r*8}
added	6T2, 7E-M
begin
	// sxtab16/uxtab16
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	11111010001U1111 1111dddd1@rrmmmm
asm	{U?u:s}xtb16{cond()} r{d}, r{m}, ror #{r*8}
added	6T2, 7E-M
begin
	// sxtb16/uxtb16
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	11111010000Unnnn 1111dddd1@rrmmmm
exclude	............1111 ................
asm	{U?u:s}xtah{cond()} r{d}, r{n}, r{m}, ror #{r*8}
added	6T2, 7E-M
begin
	// sxtah/uxtah
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = $r[${n}] + uxth32($r[${m}], ${r} * 8);
		else
			$r[${d}] = $r[${n}] + sxth32($r[${m}], ${r} * 8);
	}
end

code	11111010000U1111 1111dddd1@rrmmmm
asm	{U?u:s}xth{cond()} r{d}, r{m}, ror #{r*8}
added	6T2
begin
	// sxth/uxth
	if(t32_check_condition(cpu))
	{
		if(${U!test})
			$r[${d}] = uxtb32($r[${m}], 0);
		else
			$r[${d}] = sxtb32($r[${m}], 0);
	}
end

code	111010001101nnnn !!!!@@@@000Hmmmm
it	end
asm	tb{H?h:b}{cond()} [r{n}, r{m}{H?, lsl #1:}]
added	6T2
begin
	// tbb/tbh
	if(t32_check_condition(cpu))
	{
		uint32_t address = $r[${n}];
		uint16_t displacement;

		e32_check_nullptr(cpu, address);

		if(${H!test})
			displacement = a32_read16(cpu, address + $r[${m}] * 2);
		else
			displacement = a32_read8(cpu, address + $r[${m}]);

		$pc = $pc + displacement;
	}
end

code	111101111111iiii 1010iiiiiiiiiiii
asm	udf #{i:X}
added	6T2
begin
	// udf
	arm_undefined(cpu);
end

code	111110111110mmmm llllhhhh0110ssss
asm	umaal{cond()} r{l}, r{h}, r{m}, r{s}
added	6T2, 7E-M
begin
	// umaal
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111110110111mmmm nnnndddd0000ssss
exclude	................ 1111............
asm	usada8{cond()} r{d}, r{m}, r{s}, r{n}
added	6T2, 7E-M
begin
	// usada8
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111110110111mmmm 1111dddd0000ssss
asm	usad8{cond()} r{d}, r{m}, r{s}
added	6T2, 7E-M
begin
	// usad8
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	1110100PU0W1nnnn !!@@@@@@@@@@@@@@
exclude	.......01....... ................
exclude	.......10....... ................
asm	rfe{U?i:d}{P?b:a}{cond()} r{n}{W?!:}
added	6T2
begin
	// rfe
	if(t32_check_condition(cpu))
	{
		a32_rfe(cpu, ${n}, ${U!test}, ${P!test}, ${W!test});
	}
end

code	1110100PU0W0!!@! !!@@@@@@@@@@MMMM
exclude	.......01....... ................
exclude	.......10....... ................
asm	srs{U?i:d}{P?b:a}{cond()} r13{W?!:}, #{M}
added	6T2
begin
	// srs
	if(t32_check_condition(cpu))
	{
		a32_srs(cpu, ${M}, ${U!test}, ${P!test}, ${W!test});
	}
end

#### ARMv7

code	111100111011!!!! 10@0!!!!0010!!!!
asm	clrex{cond()}
added	7
begin
	// clrex
	if(t32_check_condition(cpu))
	{
		a32_clear_exclusive(cpu);
	}
end

code	111100111011!!!! 10@0!!!!0101oooo
asm	dmb{cond()} #{o:X}
added	6-M, 7
begin
	// dmb
end

code	111100111011!!!! 10@0!!!!0100oooo
exclude	................ ............0000	before	7-M
exclude	................ ............0100	before	7-M
asm	dsb{cond()} {o:X}
added	6-M, 7
begin
	// dsb
end

code	111100111011!!!! 10@0!!!!0110oooo
asm	isb{cond()} {o:X}
added	6-M, 7
begin
	// isb
end

code	111110011001nnnn 1111iiiiiiiiiiii
asm	pli{cond()} [r{n}, #{i:4X}]
added	7
begin
	// pli
end

code	111110010001nnnn 11111100iiiiiiii
asm	pli{cond()} [r{n}, #-{i:4X}]
added	7
begin
	// pli
end

code	111110010001nnnn 1111000000iimmmm
asm	pli{cond()} [r{n}, r{m}, lsl #{i}]
added	7
begin
	// pli
end

code	111100111010!!!! 10@0@00000000100
asm	sev{cond()}
added	7
begin
	// sev
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111100111010!!!! 10@0@00000000010
asm	wfe{cond()}
added	7
begin
	// wfe
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111100111010!!!! 10@0@00000000011
asm	wfi{cond()}
added	7
begin
	// wfi
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111100111010!!!! 10@0@00000000001
asm	yield{cond()}
added	7
begin
	// yield
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

code	111101111111iiii 1000@@@@@@@@@@@@
asm	smc{cond()} #{i:X}
added	7+mp
begin
	// smc
	if(t32_check_condition(cpu))
	{
		arm_smc(cpu);
	}
end

#### Virtualization extensions

code	111100111101!!!@ 10@0!!!!iiiiiiii
it	end
asm	eret{cond()}
added	7VE
begin
	// eret
	if(t32_check_condition(cpu))
	{
		a32_eret(cpu);
	}
end

code	111101111110iiii 1000iiiiiiiiiiii
asm	hvc{cond()} #{i:X}
added	7VE
begin
	// hvc
	if(t32_check_condition(cpu))
	{
		arm_hvc(cpu);
	}
end

code	111100111110MMMM 10@0dddd@@1m@@@@
asm	mrs{cond()} r{d}, {banked_register(m'M)}
added	7VE
begin
	// mrs
	if(t32_check_condition(cpu))
	{
		// TODO
		$r[${d}] = cpu->r[a32_banked_register_numbers[${m'M}]];
	}
end

code	111100111111MMMM 10@0dddd@@1m@@@@
asm	mrs{cond()} r{d}, {banked_spsr(m'M)}
added	7VE
begin
	// mrs
	if(t32_check_condition(cpu))
	{
		// TODO
		$r[${d}] = cpu->r[a32_banked_spsr_numbers[${m'M}]];
	}
end

code	111100111000nnnn 10@0MMMM@@1m@@@@
asm	msr{cond()} {banked_register(m'M)}, r{n}
added	7VE
begin
	// msr
	if(t32_check_condition(cpu))
	{
		// TODO
		cpu->r[a32_banked_register_numbers[${m'M}]] = $r[${n}];
	}
end

code	111100111001nnnn 10@0MMMM@@1m@@@@
asm	msr{cond()} {banked_spsr(m'M)}, r{n}
added	7VE
begin
	// msr
	if(t32_check_condition(cpu))
	{
		// TODO
		cpu->r[a32_banked_spsr_numbers[${m'M}]] = $r[${n}];
	}
end

code	1111101110U1nnnn !!!!dddd1111mmmm
asm	{U?u:s}div{cond()} r{d}, r{n}, r{m}
# TODO: and v7-R
added	7VE
begin
	// sdiv/udiv
	if(t32_check_condition(cpu))
	{
		// TODO: if ARMv7-R and SCTLR.DZ=1, make undefined instruction exception
		if($r[${m}] == 0)
			$r[${d}] = 0; /* TODO: or GenerateIntegerZeroDivide */
		else if(${U!test})
			$r[${d}] = (uint32_t)$r[${n}] / (uint32_t)$r[${m}];
		else
			$r[${d}] = (int32_t)$r[${n}] / (int32_t)$r[${m}];
	}
end

code	111100111011!!!! 10@0!!!!01000100
it	no
asm	pssbb
added	7-M
begin
	// pssbb
	// TODO
end

code	111100111011!!!! 10@0!!!!01000000
it	no
asm	ssbb
added	7-M
begin
	// ssbb
	// TODO
end

#### Used for ThumbEEE

code	111100111011!!!! 10@0!!!!0001!!!!
it	no
asm	enterx
added	7
removed	8
begin
	// enterx
	$cpsr.thumbee = true;
end

code	111100111011!!!! 10@0!!!!0000!!!!
it	no
asm	leavex
added	7
removed	8
begin
	// leavex
	$cpsr.thumbee = false;
end

######## ThumbEE

code	11001010nmmmmnnn
asm	chka{cond()} r{n}, r{m}
added	7
removed	8
thumbee	yes
begin
	// chka
	if(t32_check_condition(cpu))
	{
		if($r[${n}] <= $r[${m}])
		{
			e32_break_index_check(cpu);
		}
	}
end

code	11000001Lhhhhhhh
asm	hb{L?l:}{cond()} #{h:2X}
added	7
removed	8
thumbee	yes
begin
	// chka
	if(t32_check_condition(cpu))
	{
		if(${L!test})
		{
			$lr = $pc_next | 1;
		}
		cpu->r[PC] = cpu->teehbr + (${h} << 5);
	}
end

code	110001iiiiihhhhh
asm	hblp{cond()} #{i:2X}, #{h:2X}
added	7
removed	8
thumbee	yes
begin
	// chka
	if(t32_check_condition(cpu))
	{
		$lr = $pc_next | 1;
		$r[8] = ${i} << 5;
		cpu->r[PC] = cpu->teehbr + (${h} << 5);
	}
end

code	11000000iiihhhhh
asm	hbp{cond()} #{i}, #{h:2X}
added	7
removed	8
thumbee	yes
begin
	// chka
	if(t32_check_condition(cpu))
	{
		$r[8] = ${i} << 5;
		cpu->r[PC] = cpu->teehbr + (${h} << 5);
	}
end

code	1100110iiiiiittt
asm	ldr{cond()} r{t}, [r9, #{i'00:2X}]
added	7
removed	8
thumbee	yes
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		$r.v5[${t}] = a32_ldr(cpu, 9, ${i'00}, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	11001011iiiiittt
asm	ldr{cond()} r{t}, [r10, #{i'00:2X}]
added	7
removed	8
thumbee	yes
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		$r.v5[${t}] = a32_ldr(cpu, 10, ${i'00}, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	1100100iiinnnttt
asm	ldr{cond()} r{t}, [r{n}, #-{i'00:2X}]
added	7
removed	8
thumbee	yes
begin
	// ldr
	if(t32_check_condition(cpu))
	{
		$r.v5[${t}] = a32_ldr(cpu, ${n}, -${i'00}, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

code	1100111iiiiiittt
asm	str{cond()} r{t}, [r9, #{i'00:2X}]
added	7
removed	8
thumbee	yes
begin
	// str
	if(t32_check_condition(cpu))
	{
		a32_str(cpu, $r.str[${t}], 9, ${i'00}, PREINDEXED, NOWRITEBACK, USE_DEFAULT_MODE);
	}
end

#### ARMv8.1

code	11111010110Cnnnn 1111dddd10ssmmmm
exclude	................ ..........11....
asm	crc32{C?c:}{s?b;h;w;}{cond()} r{d}, r{n}, r{m}
added	8.1
begin
	// crc32/crc32c
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

#### ARMv8.2

code	111100111010!!!! 10@0@00000010000
asm	esb{cond()}
added	8.2
begin
	// esb
	if(t32_check_condition(cpu))
	{
		// TODO
	}
end

######## Coprocessor instructions

isa	coproc

mrc	p15, 0, c0, c0, 0
# TODO	p15, 0, c0, c0, 4
# TODO	p15, 0, c0, c0, 7
# TODO: since ARM3 specifically
added	2
begin
	// mrc midr
	$result = arm_get_midr(cpu);
end

mrc	p15, 0, c1, c0, 0
# TODO: unsure
added	3
begin
	// mrc sctlr/sctlr_el1
	$result = cpu->sctlr_el1;
end

mcr	p15, 0, c1, c0, 0
# TODO: unsure
added	3
begin
	// mcr sctlr/sctlr_el1
	cpu->sctlr_el1 = $operand;
end

mrc	p15, 0, c1, c1, 0
# TODO: unsure
added	7
begin
	// mrc scr/scr_el3
	$result = cpu->scr_el3;
end

mcr	p15, 0, c1, c1, 0
# TODO: unsure
added	7
begin
	// mcr scr/scr_el3
	cpu->scr_el3 = $operand;
end

mrc	p15, 4, c1, c0, 0
# TODO: unsure
added	6
begin
	// mrc hsctlr/sctlr_el2
	$result = cpu->sctlr_el2;
end

mcr	p15, 4, c1, c0, 0
# TODO: unsure
added	6
begin
	// mcr hsctlr/sctlr_el2
	cpu->sctlr_el2 = $operand;
end

mrc	p15, 4, c1, c1, 0
# TODO: unsure
added	6
begin
	// mrc hcr/hcr_el2
	$result = cpu->hcr_el2 & 0xFFFFFFFF;
end

mcr	p15, 4, c1, c1, 0
# TODO: unsure
added	6
begin
	// mcr hcr/hcr_el2
	cpu->hcr_el2 = ($operand & ~(uint64_t)0xFFFFFFFF) | ($operand & 0xFFFFFFFF);
end

mrc	p15, 4, c1, c1, 4
# TODO: unsure
added	8
begin
	// mrc hcr/hcr_el2
	$result = cpu->hcr_el2 >> 16;
end

mcr	p15, 4, c1, c1, 4
# TODO: unsure
added	8
begin
	// mcr hcr/hcr_el2
	cpu->hcr_el2 = ($operand & ~0xFFFFFFFF) | ((uint64_t)$operand << 32);
end

mrc	p14, 7, c0, c0, 0
added	5TEJ
begin
	// mrc jidr
	$result = cpu->jidr;
end

mrc	p14, 7, c1, c0, 0
added	5TEJ
begin
	// mrc joscr
	$result = cpu->joscr;
end

mcr	p14, 7, c1, c0, 0
added	5TEJ
begin
	// mcr joscr
	cpu->joscr = $operand;
end

mrc	p14, 7, c2, c0, 0
added	5TEJ
begin
	// mrc jmcr
	$result = cpu->jmcr;
end

mcr	p14, 7, c2, c0, 0
added	5TEJ
begin
	// mcr jmcr
	cpu->jmcr = $operand;
end

mrc	p14, 7, c3, c0, 0
added	5TEJ
begin
	// mrc jaolr
	$result = cpu->jaolr;
end

mcr	p14, 7, c3, c0, 0
added	5TEJ
begin
	// mcr jaolr
	cpu->jaolr = $operand;
end

mrc	p14, 6, c1, c0, 0
added	7
begin
	// mrc teehbr
	$result = cpu->teehbr;
end

mcr	p14, 6, c1, c0, 0
added	7
begin
	// mcr teehbr
	cpu->teehbr = $operand;
end

mrc	p15, 0, c0, c1, 0
# TODO: unsure
added	7
begin
	// mrc id_pfr0
	$result = arm_get_id_pfr0(cpu);
end

mrc	p15, 0, c4, c0, 0
# TODO: unsure
added	6
begin
	// mrc sctlr/sctlr_el2
	$result = cpu->sctlr_el2;
end

mcr	p15, 0, c4, c0, 0
# TODO: unsure
added	6
begin
	// mcr sctlr/sctlr_el2
	cpu->sctlr_el2 = $operand;
end

mrc	p15, 0, c12, c0, 0
# TODO: unsure
added	6
begin
	// mrc vbar/vbar_el1
	$result = cpu->vbar_el1;
end

mcr	p15, 0, c12, c0, 0
# TODO: unsure
added	6
begin
	// mcr vbar/vbar_el1
	cpu->vbar_el1 = $operand;
end

mrc	p15, 2, c12, c0, 0
# TODO: unsure
added	6
begin
	// mrc hvbar/vbar_el2
	$result = cpu->vbar_el2;
end

mcr	p15, 2, c12, c0, 0
# TODO: unsure
added	6
begin
	// mcr hvbar/vbar_el2
	cpu->vbar_el2 = $operand;
end

######## FPA

code	!!!@110L.T......Tddd0001........
asm	{L?ldf:stf}{cond()}{T?s;d;e;p} f{d}, {mem_operand()}
added	FPA
begin
	// ldf/sdf
	if(${L!test})
	{
		switch(${T})
		{
		case 0b00:
			cpu->fpa.f[${d}] = fpa_read32fp(cpu, $address);
			break;
		case 0b01:
			cpu->fpa.f[${d}] = fpa_read64fp(cpu, $address);
			break;
		case 0b10:
			cpu->fpa.f[${d}] = fpa_read80fp(cpu, $address);
			break;
		case 0b11:
			// TODO: depends on FPSR.EP
			break;
		}
	}
	else
	{
		switch(${T})
		{
		case 0b00:
			fpa_write32fp(cpu, $address, cpu->fpa.f[${d}]);
			break;
		case 0b01:
			fpa_write64fp(cpu, $address, cpu->fpa.f[${d}]);
			break;
		case 0b10:
			fpa_write80fp(cpu, $address, cpu->fpa.f[${d}]);
			break;
		case 0b11:
			// TODO: depends on FPSR.EP
			break;
		}
	}
end

code	!!!@110L.T......Tddd0010........
asm	{L?lfm:sfm}{cond()} f{d}, {positive(T)}, {mem_operand()}
added	FPA
begin
	// lfm/sfm
	// TODO
end

code	!!!@11100000Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	adf{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// adf
	// TODO
	cpu->fpa.f[${d}] = cpu->fpa.f[${n}] + ${fpa_operand(m)};
end

code	!!!@11100001Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	muf{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// muf
	// TODO
	cpu->fpa.f[${d}] = cpu->fpa.f[${n}] * ${fpa_operand(m)};
end

code	!!!@11100010Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	suf{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// suf
	// TODO
	cpu->fpa.f[${d}] = cpu->fpa.f[${n}] - ${fpa_operand(m)};
end

code	!!!@11100011Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	rsf{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// rsf
	// TODO
	cpu->fpa.f[${d}] = ${fpa_operand(m)} - cpu->fpa.f[${n}];
end

code	!!!@11100100Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	dvf{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// dvf
	// TODO
	cpu->fpa.f[${d}] = cpu->fpa.f[${n}] / ${fpa_operand(m)};
end

code	!!!@11100101Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	rdf{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// rdf
	// TODO
	cpu->fpa.f[${d}] = ${fpa_operand(m)} / cpu->fpa.f[${n}];
end

code	!!!@11100110Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	pow{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// pow
	// TODO
	cpu->fpa.f[${d}] = powl(cpu->fpa.f[${n}], ${fpa_operand(m)});
end

code	!!!@11100111Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	rpw{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// rpw
	// TODO
	cpu->fpa.f[${d}] = powl(${fpa_operand(m)}, cpu->fpa.f[${n}]);
end

code	!!!@11101000Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	rmf{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// rmf
	// TODO
	cpu->fpa.f[${d}] = remainderl(cpu->fpa.f[${n}], ${fpa_operand(m)});
end

code	!!!@11101001Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	fml{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// muf
	// TODO
	cpu->fpa.f[${d}] = cpu->fpa.f[${n}] * ${fpa_operand(m)};
end

code	!!!@11101010Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	fdv{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// dvf
	// TODO
	cpu->fpa.f[${d}] = cpu->fpa.f[${n}] / ${fpa_operand(m)};
end

code	!!!@11101011Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	frd{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// rdf
	// TODO
	cpu->fpa.f[${d}] = ${fpa_operand(m)} / cpu->fpa.f[${n}];
end

code	!!!@11101100Snnn0ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	pol{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, f{n}, {fpa_operand(m)}
added	FPA
begin
	// pol
	// TODO
	cpu->fpa.f[${d}] = atan2l(cpu->fpa.f[${n}], ${fpa_operand(m)}); // TODO: which order
end

code	!!!@11100000S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	mvf{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// mvf
	// TODO
	cpu->fpa.f[${d}] = ${fpa_operand(m)};
end

code	!!!@11100001S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	mnf{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// mnf
	// TODO
	cpu->fpa.f[${d}] = -${fpa_operand(m)};
end

code	!!!@11100010S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	abs{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// abs
	// TODO
	cpu->fpa.f[${d}] = fabsl(${fpa_operand(m)});
end

code	!!!@11100011S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	rnd{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// rnd
	// TODO
	cpu->fpa.f[${d}] = nearbyintl(${fpa_operand(m)});
end

code	!!!@11100100S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	sqt{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// rnd
	// TODO
	cpu->fpa.f[${d}] = sqrtl(${fpa_operand(m)});
end

code	!!!@11100101S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	log{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// log
	// TODO
	cpu->fpa.f[${d}] = log10l(${fpa_operand(m)});
end

code	!!!@11100110S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	lgn{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// lgn
	// TODO
	cpu->fpa.f[${d}] = logl(${fpa_operand(m)});
end

code	!!!@11100111S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	exp{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// exp
	// TODO
	cpu->fpa.f[${d}] = expl(${fpa_operand(m)});
end

code	!!!@11101000S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	sin{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// sin
	// TODO
	cpu->fpa.f[${d}] = sinl(${fpa_operand(m)});
end

code	!!!@11101001S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	cos{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// cos
	// TODO
	cpu->fpa.f[${d}] = cosl(${fpa_operand(m)});
end

code	!!!@11101010S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	tan{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// tan
	// TODO
	cpu->fpa.f[${d}] = tanl(${fpa_operand(m)});
end

code	!!!@11101011S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	asn{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// asin
	// TODO
	cpu->fpa.f[${d}] = asinl(${fpa_operand(m)});
end

code	!!!@11101100S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	acs{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// acos
	// TODO
	cpu->fpa.f[${d}] = acosl(${fpa_operand(m)});
end

code	!!!@11101101S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	atn{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// atan
	// TODO
	cpu->fpa.f[${d}] = atanl(${fpa_operand(m)});
end

code	!!!@11101110S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	urd{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// urd
	// TODO
	cpu->fpa.f[${d}] = nearbyintl(${fpa_operand(m)});
end

code	!!!@11101111S...1ddd0001SRR0mmmm
exclude	............1...........1.......
exclude	.........................00.....
asm	nrm{cond()}{S?s;d;e;.}{R?.;p;m;z} f{d}, {fpa_operand(m)}
added	FPA
begin
	// nrm
	// TODO
	cpu->fpa.f[${d}] = ${fpa_operand(m)};
end

code	!!!@111000010nnndddd00010RR10mmm
exclude	.........................00.....
asm	fix{cond()}{R?.;p;m;z} r{d}, f{m}
added	FPA
begin
	// fix
	$result = cpu->fpa.f[${m}];
end

code	!!!@111000110...dddd00010001....
asm	rfs{cond()} r{d}
added	FPA
begin
	// rfs
	$result = cpu->fpa.fpsr;
end

code	!!!@111001010...dddd00010001....
asm	rfc{cond()} r{d}
added	FPA
begin
	// rfc
	$result = cpu->fpa.fpcr;
end

code	!!!@11100000Snnndddd0001SRR1....
exclude	............1...........1.......
exclude	.........................00.....
asm	flt{cond()}{S?s;d;e;.}{R?.;p;m;z} f{n}, r{d}
added	FPA
begin
	// flt
	cpu->fpa.f[${n}] = $operand;
end

code	!!!@111000100...dddd00010001....
asm	wfs{cond()} r{d}
added	FPA
begin
	// wfs
	cpu->fpa.fpsr = $operand;
end

code	!!!@111001000...dddd00010001....
asm	wfc{cond()} r{d}
added	FPA
begin
	// wfc
	cpu->fpa.fpsr = $operand;
end

######## VFPv1
# $s[n] and $d[n] access scalar single and double floating point registers
# these encodes require that the n inden be rotated left by 1, so $d[${n}] would be paired with $s[${n!rol}]
# the shorthands $s.v[n,ix] and $d.v[n,ix] access the registers as 8 and 4 element register banks, respectively
# the shorthand $s.?[n,ix] and $d.?[n,ix] access them as bank registers, except if they fall into the first bank, in which case ix is ignored and treated as 0

code	!!!@11100d00nnnndddd101sN0m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................11.......	except	D32
exclude	.......................1..1.....	except	D32
asm	fmac{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
asm.ual	vmla{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv1
begin
	// fmacs/fmacd
	if(${s!test})
	{
		// TODO
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = $d.v[${d},ix] + $d.v[${N'n},ix] * $d.?[${m},ix];
	}
	else
	{
		// TODO
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = $s.v[${d!rol},ix] + $s.v[${N'n!rol},ix] * $s.?[${m!rol},ix];
	}
end

code	!!!@11100d00nnnndddd101sN1m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................11.......	except	D32
exclude	.......................1..1.....	except	D32
asm	fnmac{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
asm.ual	vmls{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv1
begin
	// fnmacs/fnmacd
	if(${s!test})
	{
		// TODO
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = $d.v[${d},ix] - $d.v[${N'n},ix] * $d.?[${m},ix];
	}
	else
	{
		// TODO
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = $s.v[${d!rol},ix] - $s.v[${N'n!rol},ix] * $s.?[${m!rol},ix];
	}
end

code	!!!@11100d01nnnndddd101sN0m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................11.......	except	D32
exclude	.......................1..1.....	except	D32
asm	fmsc{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
asm.ual	vnmls{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv1
begin
	// fmscs/fmscd
	if(${s!test})
	{
		// TODO
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = -$d.v[${d},ix] + $d.v[${N'n},ix] * $d.?[${m},ix];
	}
	else
	{
		// TODO
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = -$s.v[${d!rol},ix] + $s.v[${N'n!rol},ix] * $s.?[${m!rol},ix];
	}
end

code	!!!@11100d01nnnndddd101sN1m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................11.......	except	D32
exclude	.......................1..1.....	except	D32
asm	fnmsc{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
asm.ual	vnmla{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv1
begin
	// fnmscs/fnmscd
	if(${s!test})
	{
		// TODO
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = -$d.v[${d},ix] - $d.v[${N'n},ix] * $d.?[${m},ix];
	}
	else
	{
		// TODO
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = -$s.v[${d!rol},ix] - $s.v[${N'n!rol},ix] * $s.?[${m!rol},ix];
	}
end

code	!!!@11100d10nnnndddd101sN0m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................11.......	except	D32
exclude	.......................1..1.....	except	D32
asm	fmul{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
asm.ual	vmul.{s?f64:f32}{cond()} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv1
begin
	// fmuls/fmuld
	if(${s!test})
	{
		// TODO
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = $d.v[${N'n},ix] * $d.?[${m},ix];
	}
	else
	{
		// TODO
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = $s.v[${N'n!rol},ix] * $s.?[${m!rol},ix];
	}
end

code	!!!@11100d10nnnndddd101sN1m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................11.......	except	D32
exclude	.......................1..1.....	except	D32
asm	fnmul{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
asm.ual	vnmul{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv1
begin
	// fnmuls/fnmuld
	if(${s!test})
	{
		// TODO
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = -($d.v[${N'n},ix] * $d.?[${m},ix]);
	}
	else
	{
		// TODO
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = -($s.v[${N'n!rol},ix] * $s.?[${m!rol},ix]);
	}
end

code	!!!@11100d11nnnndddd101sN0m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................11.......	except	D32
exclude	.......................1..1.....	except	D32
asm	fadd{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
asm.ual	vadd{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv1
begin
	// fadds/faddd
	if(${s!test})
	{
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = $d.v[${N'n},ix] + $d.?[${m},ix];
	}
	else
	{
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = $s.v[${N'n!rol},ix] + $s.?[${m!rol},ix];
	}
end

code	!!!@11100d11nnnndddd101sN1m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................11.......	except	D32
exclude	.......................1..1.....	except	D32
asm	fsub{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
asm.ual	vsub{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv1
begin
	// fsubs/fsubd
	if(${s!test})
	{
		// TODO
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = $d.v[${N'n},ix] - $d.?[${m},ix];
	}
	else
	{
		// TODO
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = $s.v[${N'n!rol},ix] - $s.?[${m!rol},ix];
	}
end

code	!!!@11101d00nnnndddd101sN0m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................11.......	except	D32
exclude	.......................1..1.....	except	D32
asm	fdiv{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
asm.ual	vdiv{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv1
begin
	// fdivs/fdivd
	if(${s!test})
	{
		// TODO
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = $d.v[${N'n},ix] / $d.?[${m},ix];
	}
	else
	{
		// TODO
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = $s.v[${N'n!rol},ix] / $s.?[${m!rol},ix];
	}
end

code	!!!@11101d110000dddd101s01m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................1..1.....	except	D32
asm	fcpy{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,m)}
asm.ual	vmov{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,m)}
added	VFPv1
begin
	// fcpys/fcpyd
	if(${s!test})
	{
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = $d.?[${m},ix];
	}
	else
	{
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = $s.?[${m!rol},ix];
	}
end

code	!!!@11101d110000dddd101s11m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................1..1.....	except	D32
asm	fabs{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,m)}
asm.ual	vabs{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,m)}
added	VFPv1
begin
	// fabss/fabsd
	if(${s!test})
	{
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = fabs($d.?[${m},ix]);
	}
	else
	{
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = fabsf($s.?[${m!rol},ix]);
	}
end

code	!!!@11101d110001dddd101s01m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................1..1.....	except	D32
asm	fneg{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,m)}
asm.ual	vneg{s?.f64:.f32}{cond()} {vfpop(s,d)}, {vfpop(s,m)}
added	VFPv1
begin
	// fnegs/fnegd
	if(${s!test})
	{
		// TODO
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = -$d.?[${m},ix];
	}
	else
	{
		// TODO
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = -$s.?[${m!rol},ix];
	}
end

code	!!!@11101d110001dddd101s11m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................1..1.....	except	D32
asm	fsqrt{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,m)}
asm.ual	vsqrt{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,m)}
added	VFPv1
begin
	// fsqrts/fsqrtd
	if(${s!test})
	{
		// TODO
		for(uint8_t ix = 0; ix < ${dveclen(d)}; ix++)
			$d.v[${d},ix] = sqrt($d.?[${m},ix]);
	}
	else
	{
		// TODO
		for(uint8_t ix = 0; ix < ${sveclen(d)}; ix++)
			$s.v[${d!rol},ix] = sqrtf($s.?[${m!rol},ix]);
	}
end

code	!!!@11101d110100dddd101se1m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
exclude	.......................1..1.....	except	D32
asm	fcmp{e?e:}{s?d:s}{cond()} {vfpop(s,d)}, {vfpop(s,m)}
asm.ual	vcmp{e?e:}{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,m)}
added	VFPv1
begin
	// fcmps/fcmpd/fcmpes/fcmped
	if(${s!test})
	{
		// TODO
		a32_cmp64fp(cpu, $d[${d}], $d[${m}]); // TODO: exceptions on signaling NaN (e=0) and all NaN (e=1)
	}
	else
	{
		// TODO
		a32_cmp32fp(cpu, $s[${d!rol}], $s[${m!rol}]); // TODO: exceptions on signaling NaN (e=0) and all NaN (e=1)
	}
end

code	!!!@11101d110101dddd101se1.0....
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
asm	fcmp{e?e:}z{s?d:s}{cond()} {vfpop(s,d)}
asm.ual	vcmp{e?e:}{cond()}.{s?f64:f32} {vfpop(s,d)}, #0.0
added	VFPv1
begin
	// fcmpzs/fcmpezd/fcmpzs/fcmpezd
	if(${s!test})
	{
		// TODO
		a32_cmp64fp(cpu, $d[${d}], 0.0); // TODO: exceptions on signaling NaN (e=0) and all NaN (e=1)
	}
	else
	{
		// TODO
		a32_cmp32fp(cpu, $s[${d!rol}], 0.0f); // TODO: exceptions on signaling NaN (e=0) and all NaN (e=1)
	}
end

code	!!!@11101d110111dddd101s11m0mmmm
exclude	.........1.............0........	except	D32
exclude	.......................1..1.....	except	D32
asm	fcvt{s?sd:ds}{cond()} {vfpop(!s,d)}, {vfpop(s,m)}
asm	vcvt{cond()}.{s?f32.f64:f64.f32} {vfpop(!s,d)}, {vfpop(s,m)}
added	VFPv1D
begin
	// fcvtds/fcvtsd
	if(${s!test})
	{
		$d[${d}] = $s[${m!rol}];
	}
	else
	{
		$s[${d!rol}] = $d[${m}];
	}
end

code	!!!@11101d111000dddd101s01m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
asm	fuito{s?d:s}{cond()} {vfpop(s,d)}, s{m!rol}
asm.ual	vcvt{cond()}.{s?f64:f32}.u32 {vfpop(s,d)}, s{m!rol}
added	VFPv1
begin
	// fuitos/fuitod
	if(${s!test})
	{
		// TODO
		$d[${d}] = (uint32_t)float_as_word($s[${m!rol}]);
	}
	else
	{
		// TODO
		$s[${d!rol}] = (uint32_t)float_as_word($s[${m!rol}]);
	}
end

code	!!!@11101d111000dddd101s11m0mmmm
exclude	.......................1........	except	dp
exclude	.........1.............1........	except	D32
asm	fsito{s?d:s}{cond()} {vfpop(s,d)}, s{m!rol}
asm.ual	vcvt{cond()}.{s?f64:f32}.s32 {vfpop(s,d)}, s{m!rol}
added	VFPv1
begin
	// fsitos/fsitod
	if(${s!test})
	{
		// TODO
		$d[${d}] = (int32_t)float_as_word($s[${m!rol}]);
	}
	else
	{
		// TODO
		$s[${d!rol}] = (int32_t)float_as_word($s[${m!rol}]);
	}
end

code	!!!@11101d111100dddd101sr1m0mmmm
exclude	.......................1........	except	dp
exclude	.......................1..1.....	except	D32
asm	ftoui{r?z:}{s?d:s}{cond()} s{d!rol}, {vfpop(s,m)}
asm.ual	vcvt{r?r:}{cond()}.u32.{s?f64:f32} s{d!rol}, {vfpop(s,m)}
added	VFPv1
begin
	// ftouis/ftouid/ftouizs/ftouizd
	if(${r!test})
	{
		if(${s!test})
		{
			// TODO
			$s[${d!rol}] = word_as_float((uint32_t)$d[${m}]);
		}
		else
		{
			// TODO
			$s[${d!rol}] = word_as_float((uint32_t)$s[${m!rol}]);
		}
	}
	else
	{
		if(${s!test})
		{
			// TODO
			$s[${d!rol}] = word_as_float((uint32_t)nearbyint($d[${m}]));
		}
		else
		{
			// TODO
			$s[${d!rol}] = word_as_float((uint32_t)nearbyintf($s[${m!rol}]));
		}
	}
end

code	!!!@11101d111101dddd101sr1m0mmmm
exclude	.......................1........	except	dp
exclude	.......................1..1.....	except	D32
asm	ftosi{r?z:}{s?d:s}{cond()} s{d!rol}, {vfpop(s,m)}
asm.ual	vcvt{r?r:}{cond()}.s32.{s?f64:f32} s{d!rol}, {vfpop(s,m)}
added	VFPv1
begin
	// ftosis/ftosid/ftosizs/ftosizd
	if(${r!test})
	{
		if(${s!test})
		{
			// TODO
			$s[${d!rol}] = word_as_float((int32_t)$d[${m}]);
		}
		else
		{
			// TODO
			$s[${d!rol}] = word_as_float((int32_t)$s[${m!rol}]);
		}
	}
	else
	{
		if(${s!test})
		{
			// TODO
			$s[${d!rol}] = word_as_float((int32_t)nearbyint($d[${m}]));
		}
		else
		{
			// TODO
			$s[${d!rol}] = word_as_float((int32_t)nearbyintf($s[${m!rol}]));
		}
	}
end

code	!!!@1101Ud0L....dddd1010.......o
asm	{L?fld:fst}s{cond()} s{d!rol}, {mem_operand()}
asm.ual	{L?vldr:vstr}{cond()} s{d!rol}, {mem_operand()}
added	VFPv1
begin
	// flds/fsts
	if(${L!test})
	{
		$s[${d!rol}] = a32_read32fp(cpu, $address);
	}
	else
	{
		a32_write32fp(cpu, $address, $s[${d!rol}]);
	}
end

code	!!!@1101Ud0L....dddd1011.......o
exclude	.........1......................	except	D32
asm	{L?fld:fst}d{cond()} d{d}, {mem_operand()}
asm.ual	{L?vldr:vstr}{cond()} d{d}, {mem_operand()}
added	VFPv1D, AdvSIMDv1
begin
	// fldd/fstd
	if(${L!test})
	{
		$d[${d}] = a32_read64fp(cpu, $address);
	}
	else
	{
		a32_write64fp(cpu, $address, $d[${d}]);
	}
end

code	!!!@110PUdWLnnnndddd1010oooooooo
exclude	.......00.......................
exclude	.......11.1.....................
exclude	.......1..0.....................
asm	{L?fldm:fstm}{P?db:ia}s{cond()} r{n}{W?!:}, {sreglist(d,o)}
asm.ual	{L?vldm:vstm}{P?db:ia}{cond()}.f32 r{n}{W?!:}, {sreglist(d,o)}
added	VFPv1
begin
	// fldms/fstms
	uint8_t count = 0;

	if(${L!test})
	{
		for(count = 0; count < ${o}; count++)
		{
			$s[${d!rol} + count] = a32_read32fp(cpu, $address + ${o} * 4);
		}
	}
	else
	{
		for(count = 0; count < ${o}; count++)
		{
			a32_write32fp(cpu, $address + ${o} * 4, $s[${d!rol} + count]);
		}
	}
end

code	!!!@110PUdWLnnnndddd1011ooooooo0
exclude	.......00.......................
exclude	.......11.1.....................
exclude	.......1..0.....................
exclude	.........1......................	except	D32
asm	{L?fldm:fstm}{P?db:ia}d{cond()} r{n}{W?!:}, {dreglist(d,o)}
asm.ual	{L?vldm:vstm}{P?db:ia}{cond()}.f64 r{n}{W?!:}, {dreglist(d,o)}
added	VFPv1D, AdvSIMDv1
begin
	// fldmd/fstmd
	uint8_t count = 0;

	if(${L!test})
	{
		for(count = 0; count < ${o}; count++)
		{
			$d[${d} + count] = a32_read64fp(cpu, $address + ${o} * 8);
		}
	}
	else
	{
		for(count = 0; count < ${o}; count++)
		{
			a32_write64fp(cpu, $address + ${o} * 8, $d[${d} + count]);
		}
	}
end

code	!!!@110PUdWLnnnndddd1011ooooooo1
exclude	.......00.......................
exclude	.......11.1.....................
exclude	.......1..0.....................
exclude	.........1......................	except	D32
asm	{L?fldm:fstm}{P?db:ia}x{cond()} r{n}{W?!:}, {dreglist(d,o)}
# no UAL syntax, supported on VFPv1xD as well
added	VFPv1
begin
	// fldmx/fstmx
	uint8_t count = 0;
	uint32_t address = $address;

	if(cpu->vfp.stmx_standard_format2)
		address += 4;

	if(${L!test})
	{
		if(cpu->vfp.stmx_standard_format2)
		{
			uint32_t format_bits = a32_read32(cpu, $address);
			cpu->vfp.format_bits = (cpu->vfp.format_bits & ~(((1 << ${o}) - 1) << ${d})) | (format_bits & (((1 << ${o}) - 1) << ${d}));
		}

		for(count = 0; count < ${o}; count++)
		{
			$d.both[${d} + count] = a32_read64(cpu, address + ${o} * 8);
		}
	}
	else
	{
		if(cpu->vfp.stmx_standard_format2)
		{
			a32_write32(cpu, $address, cpu->vfp.format_bits & (((1 << ${o}) - 1) << ${d}));
		}

		for(count = 0; count < ${o}; count++)
		{
			a32_write64(cpu, address + ${o} * 8, $d.both[${d} + count]);
		}
	}
end

code	!!!@11100000nnnndddd1010N001@@@@
asm	fmsr{cond()} s{N'n!rol}, r{d}
asm.ual	vmov{cond()} s{N'n!rol}, r{d}
added	VFPv1
begin
	// fmsr

	$s[${N'n!rol}] = word_as_float($operand);
end

code	!!!@11100001nnnndddd1010N001@@@@
asm	fmrs{cond()} r{d}, s{N'n!rol}
asm.ual	vmov{cond()} r{d}, s{N'n!rol}
added	VFPv1
begin
	// fmrs

	$result = float_as_word($s[${N'n!rol}]);
end

code	!!!@111000H0nnnndddd1011N001@@@@
exclude	........................1.......	except	D32
asm	fmd{H?h:l}r{cond()} d{N'n}, r{d}
asm.ual	vmov{cond()} d{N'n}[{H?1:0}], r{d}
added	VFPv1D, AdvSIMDv1
begin
	// fmdlr/fmdhr

	if(${H!test})
		$d.high[${n}] = $operand;
	else
		$d.low[${n}] = $operand;
end

code	!!!@111000H1nnnndddd1011N001@@@@
exclude	........................1.......	except	D32
asm	fmrd{H?h:l}{cond()} r{d}, d{N'n}
asm.ual	vmov{cond()} r{d}, d{N'n}[{H?1:0}]
added	VFPv1D, AdvSIMDv1
begin
	// fmrdl/fmrdh

	if(${H!test})
		$result = $d.high[${n}];
	else
		$result = $d.low[${n}];
end

code	!!!@11101110nnnndddd10100@@1@@@@
exclude	............0000................
exclude	............0001................
exclude	............1000................
asm	fmxr{cond()} c{n}, r{d}
asm.ual	vmsr{cond()} c{n}, r{d}
added	VFPv1, AdvSIMDv1

code	!!!@111011100000dddd10100@@1@@@@
asm	fmxr{cond()} fpsid, r{d}
asm.ual	vmsr{cond()} fpsid, r{d}
added	VFPv1, AdvSIMDv1
begin
	// fmxr fpsid

	cpu->vfp.fpsid = $operand;
end

code	!!!@111011100001dddd10100@@1@@@@
asm	fmxr{cond()} fpscr, r{d}
asm.ual	vmsr{cond()} fpscr, r{d}
added	VFPv1, AdvSIMDv1
begin
	// fmxr fpscr

	cpu->vfp.fpscr = $operand;
end

code	!!!@111011101000dddd10100@@1@@@@
asm	fmxr{cond()} fpexc, r{d}
asm.ual	vmsr{cond()} fpexc, r{d}
added	VFPv1, AdvSIMDv1
begin
	// fmxr fpexc

	cpu->vfp.fpexc = $operand;
end

code	!!!@11101111nnnndddd10100@@1@@@@
exclude	............0000................
exclude	............0001................
exclude	............1000................
asm	fmrx{cond()} r{d}, c{n}
asm.ual	vmrs{cond()} r{d}, c{n}
added	VFPv1, AdvSIMDv1

code	!!!@111011110000dddd10100@@1@@@@
asm	fmrx{cond()} r{d}, fpsid
asm.ual	vmrs{cond()} r{d}, fpsid
added	VFPv1, AdvSIMDv1
begin
	// fmrx fpsid

	$result = cpu->vfp.fpsid;
end

code	!!!@111011110001dddd10100@@1@@@@
asm	fmrx{cond()} r{d}, fpscr
asm.ual	vmrs{cond()} r{d}, fpscr
added	VFPv1, AdvSIMDv1
begin
	// fmrx fpscr

	$result = cpu->vfp.fpscr;
end

code	!!!@111011111000dddd10100@@1@@@@
asm	fmrx{cond()} r{d}, fpexc
asm.ual	vmrs{cond()} r{d}, fpexc
added	VFPv1, AdvSIMDv1
begin
	// fmrx fpexc

	$result = cpu->vfp.fpexc;
end

######## VFPv2

code	!!!@11000100nnnndddd101100m1mmmm
exclude	..........................1.....	except	D32
asm	fmdrr{cond()} d{m}, r{d}, r{n}
asm.ual	vmov{cond()} d{m}, r{d}, r{n}
added	VFPv2, AdvSIMDv1
begin
	// fmdrr

	$d.low[${m}] = $operand.l;
	$d.high[${m}] = $operand.h;
end

code	!!!@11000101nnnndddd101100m1mmmm
exclude	..........................1.....	except	D32
asm	fmrrd{cond()} r{d}, r{n}, d{m}
asm.ual	vmov{cond()} r{d}, r{n}, d{m}
added	VFPv2, AdvSIMDv1
begin
	// fmrrd

	$result.l = $d.low[${m}];
	$result.h = $d.high[${m}];
end

code	!!!@11000100nnnndddd101000m1mmmm
asm	fmsrr{cond()} {{s{m!rol}, s{m!rol+1}}}, r{d}, r{n}
asm.ual	vmov{cond()} s{m!rol}, s{m!rol+1}, r{d}, r{n}
added	VFPv2
begin
	// fmsrr

	$s[${m!rol}] = $operand.l;
	$s[${m!rol} + 1] = $operand.h;
end

code	!!!@11000101nnnndddd101000m1mmmm
asm	fmrrs{cond()} r{d}, r{n}, {{s{m!rol}, s{m!rol+1}}}
asm.ual	vmov{cond()} r{d}, r{n}, s{m!rol}, s{m!rol+1}
added	VFPv2
begin
	// fmrrs

	$result.l = $s[${m!rol}];
	$result.h = $s[${m!rol} + 1];
end

######## VFPv3

code	!!!@11101d11101Udddd101sx1I0iiii
exclude	.......................1........	except	dp
exclude	.........1.............1........
asm	vcvt{cond()}.{s?f64:f32}.{U?u:s}{x?16:32} {vfpop(s,d)}, {vfpop(s,d)}, #{16<<s+i'I}
added	VFPv3
begin
	// vcvt

	// TODO
end

code	!!!@11101d11111Udddd101sx1I0iiii
exclude	.......................1........	except	dp
exclude	.........1.............1........
asm	vcvt{cond()}.{U?u:s}{x?16:32}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,d)}, #{16<<s+i'I}
added	VFPv3D
begin
	// vcvt

	// TODO
end

code	!!!@11101d11iiiidddd101s@0@0iiii
exclude	.......................1........	except	dp
asm	vmov{cond()}.{s?f64:f32} {vfpop(s,d)}, #{i:2X}
added	VFPv3
begin
	// vmov

	// TODO
end

code	!!!@11101d11001odddd101@T1m0mmmm
asm	vcvt{T?t:b}{cond()}.{o?f16.f32:f32.f16} s{d!rol}, s{m!rol}
added	VFPv3+fp16
begin
	// vcvtb/vcvtt

	// TODO
end

######## VFPv4

code	!!!@11101d10nnnndddd101sNom0mmmm
exclude	.......................1........	except	dp
asm	vfm{o?s:a}{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv4
begin
	// vmfs/vmfa

	// TODO
end

code	!!!@11101d01nnnndddd101sNom0mmmm
exclude	.......................1........	except	dp
asm	vfnm{o?a:s}{cond()}.{s?f64:f32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv4
begin
	// vfnma/vfnms

	// TODO
end

######## VFPv5 (FPv5)

isa	T32

code	11111101d1111RR dddd101sU1m0mmmmm
exclude	............... .......1.........	except	dp
it	no
asm	vcvt{R?a;n;p;m}.{U?u:s}32.f{s?64:32} s{d!rol}, {vfpop(s,m)}
added	VFPv5
begin
	// vcvta/vcvtn/vcvtp/vcvtm

	// TODO
end

code	111011101d110111 dddd101s11m0mmmm
asm	vcvt{cond()}.f64.f32 d{d}, s{m!rol}
added	VFPv5+dp
begin
	// vcvt

	// TODO
end

code	111111101d00nnnn dddd101sNom0mmmm
exclude	................ .......1........	except	dp
it	no
asm	v{o?min:max}m.f{s?64:32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv5
begin
	// vmaxm/vminm

	// TODO
end

code	111111101d1110RR dddd101s01m0mmmm
exclude	................ .......1........	except	dp
it	no
asm	vrint{R?a;n;p;m}.f{s?64:32} {vfpop(s,d)}, {vfpop(s,m)}
added	VFPv5
begin
	// vrinta/vrintn/vrintp/vrintm

	// TODO
end

code	111011101d110111 dddd101s01m0mmmm
exclude	................ .......1........	except	dp
asm	vrintx{cond()}.f{s?64:32} {vfpop(s,d)}, {vfpop(s,m)}
added	VFPv5
begin
	// vrinta/vrintn/vrintp/vrintm

	// TODO
end

code	111011101d110110 dddd101so1m0mmmm
exclude	................ .......1........	except	dp
asm	vrint{o?z:r}{cond()}.f{s?64:32} {vfpop(s,d)}, {vfpop(s,m)}
added	VFPv5
begin
	// vrintr/vrintz

	// TODO
end

code	111111100dccnnnn dddd101sN0m0mmmm
exclude	................ .......1........	except	dp
it	no
asm	vsel{c?eq;vs;ge;gt}.f{s?64:32} {vfpop(s,d)}, {vfpop(s,N'n)}, {vfpop(s,m)}
added	VFPv5
begin
	// vselge/vselgt/vseleq/vselvs

	// TODO
end

######## Advanced SIMD
######## Coprocessor instructions

isa	coproc

code	!!!@111000H0nnnndddd1011NH11@@@@
asm	vmov{cond()}.16 d{N'n}[{H}], r{d}
added	AdvSIMDv1
begin
	// vmov
	// TODO
end

code	!!!@111001H0nnnndddd1011NHH1@@@@
asm	vmov{cond()}.8 d{N'n}[{H}], r{d}
added	AdvSIMDv1
begin
	// vmov
	// TODO
end

code	!!!@1110U0H1nnnndddd1011NH11@@@@
asm.ual	vmov{cond()}.{U?u:s}16 r{d}, d{N'n}[{H}]
added	VFPv1D, AdvSIMDv1
begin
	// vmov
	// TODO
	$result = 0;
end

code	!!!@1110U1H1nnnndddd1011NHH1@@@@
asm.ual	vmov{cond()}.{U?u:s}8 r{d}, d{N'n}[{H}]
added	VFPv1D, AdvSIMDv1
begin
	// vmov
	// TODO
	$result = 0;
end

######## Advanced SIMD Main instructions

isa	A32+T32

code.a	1111001U0dSSnnnndddd0111NQm1mmmm
code.t	111U11110dSSnnnndddd0111NQm1mmmm
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vaba{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vaba
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1dSSnnnndddd0101N0m0mmmm
code.t	111U11111dSSnnnndddd0101N0m0mmmm
exclude	..........11....................
exclude	...................1............
asm	vabal{cond()}.{U?u:s}{8<<S} q{d>>1}, d{N'n}, d{m}
added	AdvSIMDv1
begin
	// vabal
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0111NQm0mmmm
code.t	111U11110dSSnnnndddd0111NQm0mmmm
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vabd{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vabd
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0101N0m0mmmm
code.t	111U11110dSSnnnndddd0101N0m0mmmm
exclude	..........11....................
exclude	...................1............
asm	vabdl{cond()}.{U?u:s}{8<<S} q{d>>1}, d{N'n}, d{m}
added	AdvSIMDv1
begin
	// vabdl
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110d10nnnndddd1101NQm0mmmm
code.t	111111110d10nnnndddd1101NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vabd{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vabd
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS01dddd00110Qm0mmmm
code.t	111111111d11SS01dddd00110Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vabs{cond()}.s{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vabs
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d111001dddd01110Qm0mmmm
code.t	111111111d111001dddd01110Qm0mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vabs{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vabs
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110do0nnnndddd1110NQm1mmmm
code.t	111111110do0nnnndddd1110NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	v{o?acge;acgt}{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vacge/vacgt
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100dSSnnnndddd1000NQm0mmmm
code.t	111011110dSSnnnndddd1000NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vadd{cond()}.i{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vadd
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100d00nnnndddd1101NQm0mmmm
code.t	111011110d00nnnndddd1101NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vadd{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vadd
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101dSSnnnndddd0100N0m0mmmm
code.t	111011111dSSnnnndddd0100N0m0mmmm
exclude	..........11....................
exclude	...............1................
exclude	...............................1
asm	vaddhn{cond()}.i{8<<S} d{d}, q{N'n>>1}, q{m>>1}
added	AdvSIMDv1
begin
	// vaddhn
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1dSSnnnndddd000QN0m0mmmm
code.t	111U11111dSSnnnndddd000QN0m0mmmm
exclude	..........11....................
exclude	...............1.......1........
exclude	...................1............
asm	vadd{Q?w:l}{cond()}.{U?u:s}{8<<S} q{d>>1}, {Q?q:d}{N'n>>Q}, d{m}
added	AdvSIMDv1
begin
	// vaddw/vaddl
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100d00nnnndddd0001NQm1mmmm
code.t	111011110d00nnnndddd0001NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vand{cond()} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vand
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001i1d000iiiddddiii10Q11iiii
code.t	111i11111d000iiiddddiii10Q11iiii
exclude	....................11..........
exclude	...................1.....1......
asm	vbic{cond()}.{simd_operand_type()} {Q?q:d}{d>>Q}, #{simd_operand()}
added	AdvSIMDv1
begin
	// vbic
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100d01nnnndddd0001NQm1mmmm
code.t	111011110d01nnnndddd0001NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vbic{cond()} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vbic
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110doonnnndddd0001NQm1mmmm
code.t	111111110doonnnndddd0001NQm1mmmm
exclude	..........00....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	v{o?;bsl;bit;bif}{cond()} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vbsl/vbit/vbif
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110dSSnnnndddd1000NQm1mmmm
code.t	111111110dSSnnnndddd1000NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vceq{cond()}.i{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vceq
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100d00nnnndddd1110NQm0mmmm
code.t	111011110d00nnnndddd1110NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vceq{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vceq
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS01dddd00010Qm0mmmm
code.t	111111111d11SS01dddd00010Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vceq{cond()}.i{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #0
added	AdvSIMDv1
begin
	// vceq
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d111001dddd01010Qm0mmmm
code.t	111111111d111001dddd01010Qm0mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vceq{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #0
added	AdvSIMDv1+sp
begin
	// vceq
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0011NQm1mmmm
code.t	111U11110dSSnnnndddd0011NQm1mmmm
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcge{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vcge
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110d00nnnndddd1110NQm0mmmm
code.t	111111110d00nnnndddd1110NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcge{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vcge
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS01dddd00001Qm0mmmm
code.t	111111111d11SS01dddd00001Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcge{cond()}.s{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #0
added	AdvSIMDv1
begin
	// vcge
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d111001dddd01001Qm0mmmm
code.t	111111111d111001dddd01001Qm0mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcge{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #0
added	AdvSIMDv1+sp
begin
	// vcge
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0011NQm0mmmm
code.t	111U11110dSSnnnndddd0011NQm0mmmm
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcgt{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vcgt
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110d10nnnndddd1110NQm0mmmm
code.t	111111110d10nnnndddd1110NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcgt{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vcgt
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS01dddd00000Qm0mmmm
code.t	111111111d11SS01dddd00000Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcgt{cond()}.s{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #0
added	AdvSIMDv1
begin
	// vcgt
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d111001dddd01000Qm0mmmm
code.t	111111111d111001dddd01000Qm0mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcgt{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #0
added	AdvSIMDv1+sp
begin
	// vcgt
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS01dddd00011Qm0mmmm
code.t	111111111d11SS01dddd00011Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcle{cond()}.s{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #0
added	AdvSIMDv1
begin
	// vcle
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d111001dddd01011Qm0mmmm
code.t	111111111d111001dddd01011Qm0mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcle{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #0
added	AdvSIMDv1+sp
begin
	// vcle
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS00dddd10000Qm0mmmm
code.t	111111111d11SS00dddd10000Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcls{cond()}.s{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vcls
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS01dddd00100Qm0mmmm
code.t	111111111d11SS01dddd00100Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vclt{cond()}.s{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #0
added	AdvSIMDv1
begin
	// vclt
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d111001dddd01100Qm0mmmm
code.t	111111111d111001dddd01100Qm0mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vclt{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #0
added	AdvSIMDv1+sp
begin
	// vclt
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS00dddd10001Qm0mmmm
code.t	111111111d11SS00dddd10001Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vclz{cond()}.s{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vclz
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d110000dddd01010Qm0mmmm
code.t	111111111d110000dddd01010Qm0mmmm
exclude	............00..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcnt{cond()} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vcnt
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d111011dddd011ooQm0mmmm
code.t	111111111d111011dddd011ooQm0mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcvt{cond()}.{o?f32.s32;f32.u32;s32.f32;u32.f32} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vcvt
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1d1iiiiidddd111o0Qm1mmmm
code.t	111U11111d1iiiiidddd111o0Qm1mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vcvt{cond()}.{o'U?f32.s32;f32.u32;s32.f32;u32.f32} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #{32-i}
added	AdvSIMDv1+sp
begin
	// vcvt
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d110110dddd011o00m0mmmm
code.t	111111111d110110dddd011o00m0mmmm
exclude	...................1...1........
exclude	.......................0.......1
asm	vcvt{cond()}.{o?f32.f16:f16.f32} {o?q:d}{d}, {o?d:q}{m}
added	AdvSIMDv1+fp16
begin
	// vcvt
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11iiiidddd11000Qm0mmmm
code.t	111111111d11iiiidddd11000Qm0mmmm
exclude	...................1.....1......
exclude	.............000................
asm	vdup{cond()}.{vidx_size(i)} {Q?q:d}{d>>Q}, d{m}[{vidx(i)}]
added	AdvSIMDv1
begin
	// vdup
	if(${cond()})
	{
		// TODO
	}
end

code.a	cccc11101SQ0ddddtttt1011D0S1@@@@
code.t	111011101SQ0ddddtttt1011D0S1@@@@
exclude	..........1....1................
exclude	.........1................1.....
asm	vdup{cond()}.{S?32;16;8;} {Q?q:d}{d>>Q}, r{t}
added	AdvSIMDv1
begin
	// vdup
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110d00nnnndddd0001NQm1mmmm
code.t	111111110d00nnnndddd0001NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	veor{cond()} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// veor
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101d11nnnnddddiiiiNQm0mmmm
code.t	111011111d11nnnnddddiiiiNQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
exclude	....................1....0......
asm	vext{cond()}.i8 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}, #{i}
added	AdvSIMDv1
begin
	// vext
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd00o0NQm0mmmm
code.t	111U11110dSSnnnndddd00o0NQm0mmmm
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vh{o?sub:add}{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vhadd/vhsub
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101000dL0nnnndddd0111SSAAmmmm
code.t	111110010dL0nnnndddd0111SSAAmmmm
exclude	..........................1.....
asm	{L?vld:vst}1{cond()}.{8<<S} {{d{d}}}, [r{n}{A?;::64;::128;::256}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld1/vst1
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101000dL0nnnndddd1010SSAAmmmm
code.t	111110010dL0nnnndddd1010SSAAmmmm
exclude	..........................11....
asm	{L?vld:vst}1{cond()}.{8<<S} {{d{d}, d{d+1}}}, [r{n}{A?;::64;::128;::256}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld1/vst1
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101000dL0nnnndddd0110SSAAmmmm
code.t	111110010dL0nnnndddd0110SSAAmmmm
exclude	..........................1.....
asm	{L?vld:vst}1{cond()}.{8<<S} {{d{d}, d{d+1}, d{d+2}}}, [r{n}{A?;::64;::128;::256}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld1/vst1
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101000dL0nnnndddd0010SSAAmmmm
code.t	111110010dL0nnnndddd0010SSAAmmmm
asm	{L?vld:vst}1{cond()}.{8<<S} {{d{d}, d{d+1}, d{d+2}, d{d+3}}}, [r{n}{A?;::64;::128;::256}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld1/vst1
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101001dL0nnnnddddSS00iiiAmmmm
code.t	111110011dL0nnnnddddSS00iiiAmmmm
exclude	....................11..........
exclude	....................00.....1....
exclude	....................01....1.....
exclude	....................10...1......
exclude	....................10....01....
exclude	....................10....10....
asm	{L?vld:vst}1{cond()}.{8<<S} {{d{d}[{i>>S}]}}, [r{n}{A'S?;;;;;::16;::32;}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld1/vst1
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101001dL0nnnndddd1100SS0Ammmm
code.t	111110011dL0nnnndddd1100SS0Ammmm
exclude	........................11......
exclude	........................00.1....
asm	{L?vld:vst}1{cond()}.{8<<S} {{d{d}[]}}, [r{n}{A'S?;;;;;::16;::32;}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld1/vst1
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101001dL0nnnndddd1100SS1Ammmm
code.t	111110011dL0nnnndddd1100SS1Ammmm
exclude	........................11......
exclude	........................00.1....
asm	{L?vld:vst}1{cond()}.{8<<S} {{d{d}[], d{d+1}[]}}, [r{n}{A'S?;;;;;::16;::32;}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld1/vst1
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101000dL0nnnndddd1000SSAAmmmm
code.t	111110010dL0nnnndddd1000SSAAmmmm
exclude	........................11......
exclude	..........................11....
asm	{L?vld:vst}2{cond()}.{8<<S} {{d{d}, d{d+1}}}, [r{n}{A?;::64;::128;::256}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld2/vst2
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101000dL0nnnndddd1001SSAAmmmm
code.t	111110010dL0nnnndddd1001SSAAmmmm
exclude	........................11......
exclude	..........................11....
asm	{L?vld:vst}2{cond()}.{8<<S} {{d{d}, d{d+2}}}, [r{n}{A?;::64;::128;::256}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld2/vst2
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101000dL0nnnndddd0011SSAAmmmm
code.t	111110010dL0nnnndddd0011SSAAmmmm
exclude	........................11......
asm	{L?vld:vst}2{cond()}.{8<<S} {{d{d}, d{d+1}, d{d+2}, d{d+3}}}, [r{n}{A?;::64;::128;::256}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld2/vst2
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101001dL0nnnnddddSS01iiiAmmmm
code.t	111110011dL0nnnnddddSS01iiiAmmmm
exclude	....................11..........
exclude	....................10....1.....
asm	{L?vld:vst}2{cond()}.{8<<S} {{d{d}[{i>>S}], d{d+1+i'A>>S&1}[{i>>S}]}}, [r{n}{A'S?;;;;::8;::16;::32;}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld2/vst2
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101001dL0nnnndddd1101SSTAmmmm
code.t	111110011dL0nnnndddd1101SSTAmmmm
exclude	........................11......
asm	{L?vld:vst}2{cond()}.{8<<S} {{d{d}[], d{d+1+T}[]}}, [r{n}{A'S?;;;;::16;::32;::64;}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld2/vst2
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101000dL0nnnndddd010TSS0Ammmm
code.t	111110010dL0nnnndddd010TSS0Ammmm
exclude	........................11......
asm	{L?vld:vst}3{cond()}.{8<<S} {{d{d}, d{d+1<<T}, d{d+2<<T}}}, [r{n}{A?;::64}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld3/vst3
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101001dL0nnnnddddSS10iii0mmmm
code.t	111110011dL0nnnnddddSS10iii0mmmm
exclude	....................11..........
exclude	....................10....1.....
asm	{L?vld:vst}3{cond()}.{8<<S} {{d{d}[{i>>S}], d{d+1+i'0>>S&1}[{i>>S}], d{d+2+i'0>>S&1*2}[{i>>S}]}}, [r{n}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld3/vst3
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101001dL0nnnndddd1110SST0mmmm
code.t	111110011dL0nnnndddd1110SST0mmmm
exclude	........................11......
asm	{L?vld:vst}3{cond()}.{8<<S} {{d{d}[], d{d+1<<T}[], d{d+2<<T}[]}}, [r{n}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld3/vst3
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101000dL0nnnndddd000TSSAAmmmm
code.t	111110010dL0nnnndddd000TSSAAmmmm
exclude	........................11......
added	AdvSIMDv1
asm	{L?vld:vst}4{cond()}.{8<<S} {{d{d}, d{d+1<<T}, d{d+2<<T}, d{d+3<<T}}}, [r{n}{A?;::64;::128;::256}]{simd_postindex(m)}
begin
	// vld4/vst4
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101001dL0nnnnddddSS11iiaAmmmm
code.t	111110011dL0nnnnddddSS11iiaAmmmm
exclude	....................11..........
exclude	....................10....11....
asm	{L?vld:vst}4{cond()}.{8<<S} {{d{d}[{i'a>>S}], d{d+1+i'a'0>>S&1}[{i'a>>S}], d{d+2+i'a'0>>S&1*2}[{i'a>>S}], d{d+3+i'a'0>>S&1*3}[{i'a>>S}]}}, [r{n}{S'a'A?;::32;;::32;;::64;;::64;;::64;::128;}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld4/vst4
	if(${cond()})
	{
		// TODO
	}
end

code.a	111101001dL0nnnndddd1111SSTAmmmm
code.t	111110011dL0nnnndddd1111SSTAmmmm
exclude	........................11.0....
asm	{L?vld:vst}4{cond()}.{S?8;16;32;32} {{d{d}[], d{d+1<<T}[], d{d+2<<T}[], d{d+3<<T}[]}}, [r{n}{S'A?;::32;;::64;;::64;;::128}]{simd_postindex(m)}
added	AdvSIMDv1
begin
	// vld4/vst4
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0110NQmommmm
code.t	111U11110dSSnnnndddd0110NQmommmm
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	v{o?min:max}{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vmax/vmin
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100do0nnnndddd1111NQm0mmmm
code.t	111U11110do0nnnndddd1111NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	v{o?min:max}{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vmax/vmin
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001o0dSSnnnndddd1001NQm0mmmm
code.t	111o11110dSSnnnndddd1001NQm0mmmm
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	v{o?mls:mla}{cond()}.i{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vmla/vmls
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1dSSnnnndddd10o0N0m0mmmm
code.t	111U11111dSSnnnndddd10o0N0m0mmmm
exclude	..........11....................
exclude	...................1............
asm	v{o?mls:mla}l{cond()}.{U?u:s}{8<<S} Q{d>>1}, d{N'n}, d{m}
added	AdvSIMDv1
begin
	// vmla/vmls
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100do0nnnndddd1101NQm1mmmm
code.t	111011110do0nnnndddd1101NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	v{o?mls:mla}{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vmla/vmls
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001Q1d.Snnnndddd0o00N1m0mmmm
code.t	111Q11111d.Snnnndddd0o00N1m0mmmm
exclude	..........11....................
exclude	..........00....................
exclude	.......1.......1................	for	ARM
exclude	.......1...........1............	for	ARM
exclude	...1...........1................	for	Thumb
exclude	...1...............1............	for	Thumb
asm	v{o?mls:mla}{cond()}.i{S?16:32} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, d{mask(m,4-S)}[{m<<S>>4}]
added	AdvSIMDv1
begin
	// vmla/vmls
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001Q1d10nnnndddd0o01N1m0mmmm
code.t	111Q11111d10nnnndddd0o01N1m0mmmm
exclude	.......1.......1................	for	ARM
exclude	.......1...........1............	for	ARM
exclude	...1...........1................	for	Thumb
exclude	...1...............1............	for	Thumb
asm	v{o?mls:mla}{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, d{m&15}[{m>>4}]
added	AdvSIMDv1+sp
begin
	// vmla/vmls
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1d.Snnnndddd0o10N1m0mmmm
code.t	111U11111d.Snnnndddd0o10N1m0mmmm
exclude	..........11....................
exclude	..........00....................
exclude	...................1............
asm	v{o?mls:mla}l{cond()}.{U?u:s}{S?16:32} q{d>>1}, d{N'n}, d{mask(m,4-S)}[{m<<S>>4}]
added	AdvSIMDv1
begin
	// vmlal/vmlsl
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001i1d000iiiddddiiii0Qo1iiii
code.t	111i11111d000iiiddddiiii0Qo1iiii
exclude	....................0..1..0.....
exclude	.....................0.1..0.....
exclude	...................1.....1......
asm	vmov{cond()}{simd_operand_type()} {Q?q:d}{d>>Q}, #{simd_operand()}
added	AdvSIMDv1
begin
	// vmov
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1diii000dddd101000m1mmmm
code.t	111U11111diii000dddd101000m1mmmm
exclude	..........000...................
exclude	..........11....................
exclude	..........1.1...................
exclude	...........11...................
exclude	...................1............
asm	vmovl{cond()}.{U?u:s}{i<<3} q{d>>1}, d{m}
added	AdvSIMDv1
begin
	// vmovl
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS10dddd001000m0mmmm
code.t	111111111d11SS10dddd001000m0mmmm
exclude	............11..................
exclude	...............................1
asm	vmovn{cond()}.i{16<<S} d{d}, q{m>>1}
added	AdvSIMDv1
begin
	// vmovn
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001o0dSSnnnndddd1001NQm1mmmm
code.t	111o11110dSSnnnndddd1001NQm1mmmm
exclude	..........11....................
exclude	.......1..1.....................	for	ARM
exclude	.......1...1....................	for	ARM
exclude	...1......1.....................	for	Thumb
exclude	...1.......1....................	for	Thumb
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vmul{cond()}.{o?p:i}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vmul
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1dSSnnnndddd11o0N0m0mmmm
code.t	111U11111dSSnnnndddd11o0N0m0mmmm
exclude	..........11....................
exclude	.......1..............1.........	for	ARM
exclude	...1..................1.........	for	Thumb
exclude	..........1...........1.........
exclude	...........1..........1.........
exclude	...................1............
asm	vmull{cond()}.{o'U?s;u;p} q{d>>1}, d{n}, d{m}
added	AdvSIMDv1
begin
	// vmull
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110d00nnnndddd1101NQm1mmmm
code.t	111111110d00nnnndddd1101NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vmul{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vmul
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001Q1d.Snnnndddd1000N1m0mmmm
code.t	111Q11111d.Snnnndddd1000N1m0mmmm
exclude	..........11....................
exclude	..........00....................
exclude	.......1...........1............	for	ARM
exclude	.......1.......1................	for	ARM
exclude	...1...............1............	for	Thumb
exclude	...1...........1................	for	Thumb
asm	vmul{cond()}.i{16<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, d{mask(m,4-S)}[{m<<S>>4}]
added	AdvSIMDv1
begin
	// vmul
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001Q1d10nnnndddd1001N1m0mmmm
code.t	111Q11111d10nnnndddd1001N1m0mmmm
exclude	.......1...........1............	for	ARM
exclude	.......1.......1................	for	ARM
exclude	...1...............1............	for	Thumb
exclude	...1...........1................	for	Thumb
asm	vmul{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, d{m&15}[{m>>4}]
added	AdvSIMDv1+sp
begin
	// vmul
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1d.Snnnndddd1010N1m0mmmm
code.t	111U11111d.Snnnndddd1010N1m0mmmm
exclude	..........11....................
exclude	..........00....................
exclude	...................1............
asm	vmull{cond()}.{U?u:s}{16<<S} q{d>>1}, d{N'n}, d{mask(m,4-S)}[{m<<S>>4}]
added	AdvSIMDv1
begin
	// vmull
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001i1d000iiiddddiiii0Q11iiii
code.t	111i11111d000iiiddddiiii0Q11iiii
exclude	.....................0.1........
exclude	....................0..1........
exclude	....................111.........
exclude	...................1.....1......
asm	vmvn{cond()}.{simd_operand_type()} {Q?q:d}{d>>Q}, #{simd_operand()}
added	AdvSIMDv1
begin
	// vmvn
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d110000dddd01011Qm0mmmm
code.t	111111111d110000dddd01011Qm0mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vmvn{cond()} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vmvn
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS01dddd00111Qm0mmmm
code.t	111111111d11SS01dddd00111Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vneg{cond()}.s{16<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vneg
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d111001dddd01111Qm0mmmm
code.t	111111111d111001dddd01111Qm0mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vneg{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vneg
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100d11nnnndddd0001NQm1mmmm
code.t	111011110d11nnnndddd0001NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vorn{cond()} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vorn
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001i1d000iiiddddiii10Q01iiii
code.t	111i11111d000iiiddddiii10Q01iiii
exclude	....................11..........
exclude	...................1.....1......
asm	vorr{cond()}.{simd_operand_type()} {Q?q:d}{d>>Q}, #{simd_operand()}
added	AdvSIMDv1
begin
	// vorr
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100d10nnnndddd0001NQm1mmmm
code.t	111011110d10nnnndddd0001NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vorr{cond()} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vorr
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS00dddd0110UQm0mmmm
code.t	111111111d11SS00dddd0110UQm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vpadal{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vpadal
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100dSSnnnndddd1011N0m1mmmm
code.t	111011110dSSnnnndddd1011N0m1mmmm
exclude	..........11....................
asm	vpadd{cond()}.i{8<<S} d{d}, d{N'n}, d{m}
added	AdvSIMDv1
begin
	// vpadd
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110d00nnnndddd1101N0m0mmmm
code.t	111111110d00nnnndddd1101N0m0mmmm
asm	vpadd{cond()}.f32 d{d}, d{N'n}, d{m}
added	AdvSIMDv1+sp
begin
	// vpadd
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS00dddd0010UQm0mmmm
code.t	111111111d11SS00dddd0010UQm0mmmm
exclude	...................1.....1......
exclude	.........................1.....1
asm	vpaddl{cond()}.{U?u:s}{16<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vpaddl
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd1010N0mommmm
code.t	111U11110dSSnnnndddd1010N0mommmm
exclude	..........11....................
asm	vp{o?min:max}{cond()}.{U?u:s}{8<<S} d{d}, d{N'n}, d{m}
added	AdvSIMDv1
begin
	// vpmax/vpmin
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110do0nnnndddd1111N0m0mmmm
code.t	111111110do0nnnndddd1111N0m0mmmm
asm	vp{o?min:max}{cond()}.f32 d{d}, d{N'n}, d{m}
added	AdvSIMDv1+sp
begin
	// vpmax/vpmin
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS00dddd01110Qm0mmmm
code.t	111111111d11SS00dddd01110Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vqabs{cond()}.s{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vqabs
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0000NQm1mmmm
code.t	111U11110dSSnnnndddd0000NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vqadd{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vqadd
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101d.Snnnndddd10o1N0m0mmmm
code.t	111011111d.Snnnndddd10o1N0m0mmmm
exclude	..........11....................
exclude	..........00....................
exclude	...................1............
asm	vqd{o?mlsl:mlal}{cond()}.s{16<<S} q{d>>1}, d{N'n}, d{m}
added	AdvSIMDv1
begin
	// vqdmlal/vqdmlsl
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101d.Snnnndddd0o11N1m0mmmm
code.t	111011111d.Snnnndddd0o11N1m0mmmm
exclude	..........11....................
exclude	..........00....................
exclude	...................1............
asm	vqd{o?mlsl:mlal}{cond()}.s{16<<S} q{d>>1}, d{N'n}, d{mask(m,4-S)}[{m<<S>>4}]
added	AdvSIMDv1
begin
	// vqdmlal/vqdmlsl
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100d.Snnnndddd1101NQm0mmmm
code.t	111011110d.Snnnndddd1101NQm0mmmm
exclude	..........11....................
exclude	..........00....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vqdmulh{cond()}.s{16<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vqdmulh
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001Q1d.Snnnndddd1100N1m0mmmm
code.t	111Q11111d.Snnnndddd1100N1m0mmmm
exclude	..........11....................
exclude	..........00....................
exclude	...............1.........1......
exclude	...................1.....1......
asm	vqdmulh{cond()}.s{16<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, d{mask(m,4-S)}[{m<<S>>4}]
added	AdvSIMDv1
begin
	// vqdmulh
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101d.Snnnndddd1101N0m0mmmm
code.t	111011111d.Snnnndddd1101N0m0mmmm
exclude	..........11....................
exclude	..........00....................
exclude	...................1............
asm	vqdmull{cond()}.s{16<<S} q{d>>1}, d{N'n}, d{m}
added	AdvSIMDv1
begin
	// vqdmull
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101d.Snnnndddd1011N1m0mmmm
code.t	111011111d.Snnnndddd1011N1m0mmmm
exclude	..........11....................
exclude	..........00....................
exclude	...................1............
asm	vqdmull{cond()}.s{16<<S} q{d>>1}, d{N'n}, d{mask(m,4-S)}[{m<<S>>4}]
added	AdvSIMDv1
begin
	// vqdmull
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS10dddd0010Uom0mmmm
code.t	111111111d11SS10dddd0010Uom0mmmm
exclude	........................00......
exclude	............11..................
exclude	...............................1
asm	vqmov{U?:u}n{cond()}.{U'o?u:s}{16<<S} d{d}, q{m>>1}
added	AdvSIMDv1
begin
	// vqmovn/vqmovun
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS00dddd01111Qm0mmmm
code.t	111111111d11SS00dddd01111Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vqneg{cond()}.s{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vqneg
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110d.Snnnndddd1011NQm0mmmm
code.t	111111110d.Snnnndddd1011NQm0mmmm
exclude	..........00....................
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vqrdmulh{cond()}.s{16<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vqrdmulh
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001Q1dSSnnnndddd1101N1m0mmmm
code.t	111Q11111dSSnnnndddd1101N1m0mmmm
exclude	..........00....................
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
asm	vqrdmulh{cond()}.s{16<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, d{mask(m,4-S)}[{m<<S>>4}]
added	AdvSIMDv1
begin
	// vqrdmulh
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0101NQm1mmmm
code.t	111U11110dSSnnnndddd0101NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vqrshl{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vqrshl
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1diiiiiidddd100U01m1mmmm
code.t	111U11111diiiiiidddd100U01m1mmmm
exclude	..........000...................
exclude	.......0...............0........	for	ARM
exclude	...0...................0........	for	Thumb
exclude	...............................1
asm	vqrshr{U?;;u;}n{cond()}.{U?;s;s;u}{simd_shift_size(i'0)} d{d}, q{m>>1}, #{simd_shift_amount_neg(i)}
added	AdvSIMDv1
begin
	// vqrshrn/vqrshrun
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0100NQm1mmmm
code.t	111U11110dSSnnnndddd0100NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vqshl{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vqshl
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1d001iiidddd011U0Qm1mmmm
code.t	111U11111d001iiidddd011U0Qm1mmmm
exclude	.......0...............0........	for	ARM
exclude	...0...................0........	for	Thumb
exclude	...................1.....1......
exclude	.........................1.....1
asm	vqshl{U?;;u;}.{U?;s;s;u}8 {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #{i}
added	AdvSIMDv1
begin
	// vqshl/vqshlu
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1diiiiiidddd011ULQm1mmmm
code.t	111U11111diiiiiidddd011ULQm1mmmm
exclude	..........000...........0.......
exclude	.......0...............0........	for	ARM
exclude	...0...................0........	for	Thumb
exclude	...................1.....1......
exclude	.........................1.....1
asm	vqshl{U?;;u;}.{U?;s;s;u}{simd_shift_size(L'i)} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #{simd_shift_amount(L'i)}
added	AdvSIMDv1
begin
	// vqshl/vqshlu
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1diiiiiidddd100U00m1mmmm
code.t	111U11111diiiiiidddd100U00m1mmmm
exclude	..........000...................
exclude	.......0...............0........	for	ARM
exclude	...0...................0........	for	Thumb
exclude	...............................1
asm	vqshr{U?;;u;}n{cond()}.{U?;s;s;u}{simd_shift_size(i'0)} d{d}, q{m>>1}, #{simd_shift_amount_neg(i)}
added	AdvSIMDv1
begin
	// vqshrn/vqshrun
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0010NQm1mmmm
code.t	111U11110dSSnnnndddd0010NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vqsub{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vqsub
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111dSSnnnndddd0100N0m0mmmm
code.t	111111111dSSnnnndddd0100N0m0mmmm
exclude	..........11....................
exclude	...............1................
exclude	...............................1
asm	vraddhn{cond()}.i{16<<S} d{d}, q{N'n>>1}, q{m>>1}
added	AdvSIMDv1
begin
	// vraddhn
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d111011dddd010F0Qm0mmmm
code.t	111111111d111011dddd010F0Qm0mmmm
exclude	.......................1........	except	sp
exclude	...................1.....1......
exclude	.........................1.....1
asm	vrecpe{cond()}.{F?f:u}32 {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vrecpe
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100d00nnnndddd1111NQm1mmmm
code.t	111011110d00nnnndddd1111NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vrecps{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vrecps
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS00dddd000ooQm0mmmm
code.t	111111111d11SS00dddd000ooQm0mmmm
exclude	............11..................
exclude	............1...........1.......
exclude	............1..........1........
exclude	.............1.........1........
exclude	.......................11.......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vrev{o?64;32;16}{cond()}.{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vrev16/vrev32/vrev64
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0001NQm0mmmm
code.t	111U11110dSSnnnndddd0001NQm0mmmm
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vrhadd{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vrhadd
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0101NQm0mmmm
code.t	111U11110dSSnnnndddd0101NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vrshl{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vrshl
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1diiiiiidddd0010LQm1mmmm
code.t	111U11111diiiiiidddd0010LQm1mmmm
exclude	..........000...........0.......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vrshr.{U?u:s}{simd_shift_size(L'i)} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #{simd_shift_amount_neg(L'i)}
added	AdvSIMDv1
begin
	// vrshr
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101d001iiidddd100001m1mmmm
code.t	111011111d001iiidddd100001m1mmmm
exclude	...............................1
asm	vrshrn.i8 d{d}, q{m>>1}, #{8-i}
added	AdvSIMDv1
begin
	// vrshrn
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101d01iiiidddd100001m1mmmm
code.t	111011111d01iiiidddd100001m1mmmm
exclude	...............................1
asm	vrshrn.i16 d{d}, q{m>>1}, #{16-i}
added	AdvSIMDv1
begin
	// vrshrn
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101d1iiiiidddd100001m1mmmm
code.t	111011111d1iiiiidddd100001m1mmmm
exclude	...............................1
asm	vrshrn.i32 d{d}, q{m>>1}, #{32-i}
added	AdvSIMDv1
begin
	// vrshrn
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d111011dddd010F1Qm0mmmm
code.t	111111111d111011dddd010F1Qm0mmmm
exclude	.......................1........	except	sp
exclude	...................1.....1......
exclude	.........................1.....1
asm	vrsqrte{cond()}.{F?f:u}32 {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vrsqrte
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100d10nnnndddd1111NQm1mmmm
code.t	111011110d10nnnndddd1111NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vrsqrts{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vrsqrts
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1diiiiiidddd0011LQm1mmmm
code.t	111U11111diiiiiidddd0011LQm1mmmm
exclude	..........000...........0.......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vrsra.{U?u:s}{simd_shift_size(L'i)} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #{simd_shift_amount_neg(L'i)}
added	AdvSIMDv1
begin
	// vrsra
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111dSSnnnndddd0110N0m0mmmm
code.t	111111111dSSnnnndddd0110N0m0mmmm
exclude	..........11....................
exclude	...............1................
exclude	...............................1
asm	vrsubhn{cond()}.i{16<<S} d{d}, q{N'n>>1}, q{m>>1}
added	AdvSIMDv1
begin
	// vrsubhn
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101diiiiiidddd0101LQm1mmmm
code.t	111011111diiiiiidddd0101LQm1mmmm
exclude	..........000...........0.......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vshl{cond()}.i{simd_shift_size(L'i)} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #{simd_shift_amount(L'i)}
added	AdvSIMDv1
begin
	// vshl
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U0dSSnnnndddd0100NQm0mmmm
code.t	111U11110dSSnnnndddd0100NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vshl{cond()}.{U?u:s}{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vshl
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1diiiiiidddd101000m1mmmm
code.t	111U11111diiiiiidddd101000m1mmmm
exclude	..........000...................
exclude	...................1............
asm	vshll{cond()}.{U?u:s}{simd_shift_size(i)} q{d>>1}, d{m}, #{simd_shift_amount(i)}
added	AdvSIMDv1
begin
	// vshll
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS10dddd001100m0mmmm
code.t	111111111d11SS10dddd001100m0mmmm
exclude	............11..................
exclude	...................1............
asm	vshll{cond()}.i{8<<S} q{d>>1}, d{m}, #{8<<S}
added	AdvSIMDv1
begin
	// vshll
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1diiiiiidddd0000LQm1mmmm
code.t	111U11111diiiiiidddd0000LQm1mmmm
exclude	..........000...........0.......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vshr{cond()}.{U?u:s}{simd_shift_size(L'i)} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #{simd_shift_amount_neg(L'i)}
added	AdvSIMDv1
begin
	// vshr
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101diiiiiidddd100000m1mmmm
code.t	111011111diiiiiidddd100000m1mmmm
exclude	..........000...................
exclude	...............................1
asm	vshrn{cond()}.i{simd_shift_size(i'0)} d{d}, q{m>>1}, #{simd_shift_amount_neg(i)}
added	AdvSIMDv1
begin
	// vshrn
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111diiiiiidddd0101LQm1mmmm
code.t	111111111diiiiiidddd0101LQm1mmmm
exclude	..........000...........0.......
asm	vsli{cond()}.{simd_shift_size(L'i)} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #{simd_shift_amount(L'i)}
added	AdvSIMDv1
begin
	// vsli
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1diiiiiidddd0001LQm1mmmm
code.t	111U11111diiiiiidddd0001LQm1mmmm
exclude	..........000...........0.......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vsra{cond()}.{U?u:s}{simd_shift_size(L'i)} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #{simd_shift_amount_neg(L'i)}
added	AdvSIMDv1
begin
	// vsra
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111diiiiiidddd0100LQm1mmmm
code.t	111111111diiiiiidddd0100LQm1mmmm
exclude	..........000...........0.......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vsri{cond()}.{simd_shift_size(L'i)} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}, #{simd_shift_amount_neg(L'i)}
added	AdvSIMDv1
begin
	// vsri
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100110dSSnnnndddd1000NQm0mmmm
code.t	111111110dSSnnnndddd1000NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vsub{cond()}.i{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vsub
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100d10nnnndddd1101NQm0mmmm
code.t	111011110d10nnnndddd1101NQm0mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vsub{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1+sp
begin
	// vsub
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100101dSSnnnndddd0110N0m0mmmm
code.t	111011111dSSnnnndddd0110N0m0mmmm
exclude	..........11....................
exclude	...............1................
exclude	...............................1
asm	vsubhn{cond()}.i{8<<S} d{d}, q{N'n>>1}, q{m>>1}
added	AdvSIMDv1
begin
	// vsubhn
	if(${cond()})
	{
		// TODO
	}
end

code.a	1111001U1dSSnnnndddd001QN0m0mmmm
code.t	111U11111dSSnnnndddd001QN0m0mmmm
exclude	..........11....................
exclude	...............1.......1........
exclude	...................1............
asm	vsub{Q?w:l}{cond()}.{U?u:s}{8<<S} q{d>>1}, {Q?q:d}{N'n>>Q}, d{m}
added	AdvSIMDv1
begin
	// vsubw/vsubl
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS10dddd00000Qm0mmmm
code.t	111111111d11SS10dddd00000Qm0mmmm
exclude	............00..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vswp{cond()} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vswp
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11nnnndddd1000Nom0mmmm
code.t	111111111d11nnnndddd1000Nom0mmmm
asm	v{o?tbx:tbl}{cond()}.8 d{d}, {{d{N'n}}}, d{m}
added	AdvSIMDv1
begin
	// vtbl/vtbx
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11nnnndddd1001Nom0mmmm
code.t	111111111d11nnnndddd1001Nom0mmmm
asm	v{o?tbx:tbl}{cond()}.8 d{d}, {{d{N'n}, d{N'n+1}}}, d{m}
added	AdvSIMDv1
begin
	// vtbl/vtbx
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11nnnndddd1010Nom0mmmm
code.t	111111111d11nnnndddd1010Nom0mmmm
asm	v{o?tbx:tbl}{cond()}.8 d{d}, {{d{N'n}, d{N'n+1}, d{N'n+2}}}, d{m}
added	AdvSIMDv1
begin
	// vtbl/vtbx
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11nnnndddd1011Nom0mmmm
code.t	111111111d11nnnndddd1011Nom0mmmm
asm	v{o?tbx:tbl}{cond()}.8 d{d}, {{d{N'n}, d{N'n+1}, d{N'n+2}, d{N'n+3}}}, d{m}
added	AdvSIMDv1
begin
	// vtbl/vtbx
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS10dddd00001Qm0mmmm
code.t	111111111d11SS10dddd00001Qm0mmmm
exclude	............11..................
exclude	...................1.....1......
exclude	.........................1.....1
asm	vtrn{cond()}.{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vtrn
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100100dSSnnnndddd1000NQm1mmmm
code.t	111011110dSSnnnndddd1000NQm1mmmm
exclude	..........11....................
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vtst{cond()}.{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vtst
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS10dddd00010Qm0mmmm
code.t	111111111d11SS10dddd00010Qm0mmmm
exclude	............11..................
exclude	............10...........0......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vuzp{cond()}.{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vuzp
	if(${cond()})
	{
		// TODO
	}
end

code.a	111100111d11SS10dddd00011Qm0mmmm
code.t	111111111d11SS10dddd00011Qm0mmmm
exclude	............11..................
exclude	............10...........0......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vzip{cond()}.{8<<S} {Q?q:d}{d>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv1
begin
	// vzip
	if(${cond()})
	{
		// TODO
	}
end

######## Advanced SIMDv2

code.a	111100100do0nnnndddd1100NQm1mmmm
code.t	111011110do0nnnndddd1100NQm1mmmm
exclude	...............1.........1......
exclude	...................1.....1......
exclude	.........................1.....1
asm	vfm{o?s:a}{cond()}.f32 {Q?q:d}{d>>Q}, {Q?q:d}{N'n>>Q}, {Q?q:d}{m>>Q}
added	AdvSIMDv2+sp
begin
	// vfma/vfms
	if(${cond()})
	{
		// TODO
	}
end

######## Jazelle, Java bytecode
isa	J32

code	00
asm	nop
added	JVM
usedby	5TEJ
begin
	// nop
end

code	01
asm	aconst_null
added	JVM
usedby	5TEJ
begin
	// aconst_null
	j32_push_word(cpu, 0);
end

code	02
asm	iconst_m1
added	JVM
usedby	5TEJ
begin
	// iconst_m1
	j32_push_word(cpu, -1);
end

code	03
asm	iconst_0
added	JVM
usedby	5TEJ
begin
	// iconst_0
	j32_push_word(cpu, 0);
end

code	04
asm	iconst_1
added	JVM
usedby	5TEJ
begin
	// iconst_1
	j32_push_word(cpu, 1);
end

code	05
asm	iconst_2
added	JVM
usedby	5TEJ
begin
	// iconst_2
	j32_push_word(cpu, 2);
end

code	06
asm	iconst_3
added	JVM
usedby	5TEJ
begin
	// iconst_3
	j32_push_word(cpu, 3);
end

code	07
asm	iconst_4
added	JVM
usedby	5TEJ
begin
	// iconst_4
	j32_push_word(cpu, 4);
end

code	08
asm	iconst_5
added	JVM
usedby	5TEJ
begin
	// iconst_5
	j32_push_word(cpu, 5);
end

code	09
asm	lconst_0
added	JVM
usedby	5TEJ
begin
	// lconst_0
	j32_push_dword(cpu, 0);
end

code	0A
asm	lconst_1
added	JVM
usedby	5TEJ
begin
	// lconst_1
	j32_push_dword(cpu, 1);
end

code	0B
asm	fconst_0
added	JVM
usedby	5TEJ
begin
	// fconst_0
	j32_push_float(cpu, 0.0f);
end

code	0C
asm	fconst_1
added	JVM
usedby	5TEJ
begin
	// fconst_1
	j32_push_float(cpu, 1.0f);
end

code	0D
asm	fconst_2
added	JVM
usedby	5TEJ
begin
	// fconst_2
	j32_push_float(cpu, 2.0f);
end

code	0E
asm	dconst_0
added	JVM
usedby	5TEJ
begin
	// dconst_0
	j32_push_double(cpu, 0.0);
end

code	0F
asm	dconst_1
added	JVM
usedby	extension
begin
	// dconst_1
	j32_push_double(cpu, 1.0);
end

code	10 v:i8
asm	bipush {v:2X}
added	JVM
usedby	5TEJ
begin
	// bipush
	j32_push_word(cpu, sign_extend(8, ${v}));
end

code	11 v:i16
asm	sipush {v:4X}
added	JVM
usedby	5TEJ
begin
	// sipush
	j32_push_word(cpu, sign_extend(16, ${v}));
end

code	12 x:i8
asm	ldc #{x}
added	JVM
usedby	extension
begin
	// ldc
	j32_push_word(cpu, j32_load_const_word(cpu, ${x}));
end

code	13 x:i16
asm	ldc_w #{x}
added	JVM
usedby	extension
begin
	// ldc_w
	j32_push_word(cpu, j32_load_const_word(cpu, ${x}));
end

code	14 x:i16
asm	ldc2_w #{x}
added	JVM
usedby	extension
begin
	// ldc2_w
	j32_push_dword(cpu, j32_load_const_dword(cpu, ${x}));
end

code	15 x:iW
asm	iload #{x}
added	JVM
usedby	5TEJ
begin
	// iload
	j32_push_word(cpu, j32_read_local_word(cpu, ${x}));
end

code	16 x:iW
asm	lload #{x}
added	JVM
usedby	5TEJ
begin
	// lload
	j32_push_dword(cpu, j32_read_local_dword(cpu, ${x}));
end

code	17 x:iW
asm	fload #{x}
added	JVM
usedby	5TEJ
begin
	// fload
	j32_push_word(cpu, j32_read_local_word(cpu, ${x}));
end

code	18 x:iW
asm	dload #{x}
added	JVM
usedby	5TEJ
begin
	// dload
	j32_push_dword(cpu, j32_read_local_dword(cpu, ${x}));
end

code	19 x:iW
asm	aload #{x}
added	JVM
usedby	5TEJ
begin
	// aload
	j32_push_word(cpu, j32_read_local_word(cpu, ${x}));
end

code	1A
asm	iload_0
added	JVM
usedby	5TEJ
begin
	// iload_0
	j32_push_word(cpu, j32_read_local_word(cpu, 0));
end

code	1B
asm	iload_1
added	JVM
usedby	5TEJ
begin
	// iload_1
	j32_push_word(cpu, j32_read_local_word(cpu, 1));
end

code	1C
asm	iload_2
added	JVM
usedby	5TEJ
begin
	// iload_2
	j32_push_word(cpu, j32_read_local_word(cpu, 2));
end

code	1D
asm	iload_3
added	JVM
usedby	5TEJ
begin
	// iload_3
	j32_push_word(cpu, j32_read_local_word(cpu, 3));
end

code	1E
asm	lload_0
added	JVM
usedby	5TEJ
begin
	// lload_0
	j32_push_dword(cpu, j32_read_local_dword(cpu, 0));
end

code	1F
asm	lload_1
added	JVM
usedby	5TEJ
begin
	// lload_1
	j32_push_dword(cpu, j32_read_local_dword(cpu, 1));
end

code	20
asm	lload_2
added	JVM
usedby	5TEJ
begin
	// lload_2
	j32_push_dword(cpu, j32_read_local_dword(cpu, 2));
end

code	21
asm	lload_3
added	JVM
usedby	5TEJ
begin
	// lload_3
	j32_push_dword(cpu, j32_read_local_dword(cpu, 3));
end

code	22
asm	fload_0
added	JVM
usedby	5TEJ
begin
	// fload_0
	j32_push_word(cpu, j32_read_local_word(cpu, 0));
end

code	23
asm	fload_1
added	JVM
usedby	5TEJ
begin
	// fload_1
	j32_push_word(cpu, j32_read_local_word(cpu, 1));
end

code	24
asm	fload_2
added	JVM
usedby	5TEJ
begin
	// fload_2
	j32_push_word(cpu, j32_read_local_word(cpu, 2));
end

code	25
asm	fload_3
added	JVM
usedby	5TEJ
begin
	// fload_3
	j32_push_word(cpu, j32_read_local_word(cpu, 3));
end

code	26
asm	dload_0
added	JVM
usedby	5TEJ
begin
	// dload_0
	j32_push_dword(cpu, j32_read_local_dword(cpu, 0));
end

code	27
asm	dload_1
added	JVM
usedby	5TEJ
begin
	// dload_1
	j32_push_dword(cpu, j32_read_local_dword(cpu, 1));
end

code	28
asm	dload_2
added	JVM
usedby	5TEJ
begin
	// dload_2
	j32_push_dword(cpu, j32_read_local_dword(cpu, 2));
end

code	29
asm	dload_3
added	JVM
usedby	5TEJ
begin
	// dload_3
	j32_push_dword(cpu, j32_read_local_dword(cpu, 3));
end

code	2A
asm	aload_0
added	JVM
usedby	5TEJ
begin
	// aload_0
	j32_push_word(cpu, j32_read_local_word(cpu, 0));
end

code	2B
asm	aload_1
added	JVM
usedby	5TEJ
begin
	// aload_1
	j32_push_word(cpu, j32_read_local_word(cpu, 1));
end

code	2C
asm	aload_2
added	JVM
usedby	5TEJ
begin
	// aload_2
	j32_push_word(cpu, j32_read_local_word(cpu, 2));
end

code	2D
asm	aload_3
added	JVM
usedby	5TEJ
begin
	// aload_3
	j32_push_word(cpu, j32_read_local_word(cpu, 3));
end

code	2E
asm	iaload
added	JVM
usedby	5TEJ
begin
	// iaload
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_push_word(cpu, j32_get_array_word(cpu, arrayref, index));
end

code	2F
asm	laload
added	JVM
usedby	5TEJ
begin
	// laload
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_push_dword(cpu, j32_get_array_dword(cpu, arrayref, index));
end

code	30
asm	faload
added	JVM
usedby	5TEJ
begin
	// faload
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_push_word(cpu, j32_get_array_word(cpu, arrayref, index));
end

code	31
asm	daload
added	JVM
usedby	5TEJ
begin
	// daload
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_push_dword(cpu, j32_get_array_dword(cpu, arrayref, index));
end

code	32
asm	aaload
added	JVM
usedby	5TEJ
begin
	// aaload
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_push_word(cpu, j32_get_array_reference(cpu, arrayref, index));
end

code	33
asm	baload
added	JVM
usedby	5TEJ
begin
	// baload
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_push_word(cpu, j32_get_array_byte(cpu, arrayref, index));
end

code	34
asm	caload
added	JVM
usedby	5TEJ
begin
	// caload
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_push_word(cpu, j32_get_array_hword(cpu, arrayref, index));
end

code	35
asm	saload
added	JVM
usedby	5TEJ
begin
	// saload
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_push_word(cpu, j32_get_array_hword(cpu, arrayref, index));
end

code	36 x:iW
asm	istore #{x}
added	JVM
usedby	5TEJ
begin
	// istore
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, ${x}, value);
end

code	37 x:iW
asm	lstore #{x}
added	JVM
usedby	5TEJ
begin
	// lstore
	uint64_t value = j32_pop_dword(cpu);
	j32_write_local_dword(cpu, ${x}, value);
end

code	38 x:iW
asm	fstore #{x}
added	JVM
usedby	5TEJ
begin
	// fstore
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, ${x}, value);
end

code	39 x:iW
asm	dstore #{x}
added	JVM
usedby	5TEJ
begin
	// dstore
	uint64_t value = j32_pop_dword(cpu);
	j32_write_local_dword(cpu, ${x}, value);
end

code	3A x:iW
asm	astore #{x}
added	JVM
usedby	5TEJ
begin
	// astore
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, ${x}, value);
end

code	3B
asm	istore_0
added	JVM
usedby	5TEJ
begin
	// istore_0
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 0, value);
end

code	3C
asm	istore_1
added	JVM
usedby	5TEJ
begin
	// istore_1
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 1, value);
end

code	3D
asm	istore_2
added	JVM
usedby	5TEJ
begin
	// istore_2
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 2, value);
end

code	3E
asm	istore_3
added	JVM
usedby	5TEJ
begin
	// istore_3
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 3, value);
end

code	3F
asm	lstore_0
added	JVM
usedby	5TEJ
begin
	// lstore_0
	uint64_t value = j32_pop_dword(cpu);
	j32_write_local_dword(cpu, 0, value);
end

code	40
asm	lstore_1
added	JVM
usedby	5TEJ
begin
	// lstore_1
	uint64_t value = j32_pop_dword(cpu);
	j32_write_local_dword(cpu, 1, value);
end

code	41
asm	lstore_2
added	JVM
usedby	5TEJ
begin
	// lstore_2
	uint64_t value = j32_pop_dword(cpu);
	j32_write_local_dword(cpu, 2, value);
end

code	42
asm	lstore_3
added	JVM
usedby	5TEJ
begin
	// lstore_3
	uint64_t value = j32_pop_dword(cpu);
	j32_write_local_dword(cpu, 3, value);
end

code	43
asm	fstore_0
added	JVM
usedby	5TEJ
begin
	// fstore_0
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 0, value);
end

code	44
asm	fstore_1
added	JVM
usedby	5TEJ
begin
	// fstore_1
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 1, value);
end

code	45
asm	fstore_2
added	JVM
usedby	5TEJ
begin
	// fstore_2
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 2, value);
end

code	46
asm	fstore_3
added	JVM
usedby	5TEJ
begin
	// fstore_3
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 3, value);
end

code	47
asm	dstore_0
added	JVM
usedby	5TEJ
begin
	// dstore_0
	uint64_t value = j32_pop_dword(cpu);
	j32_write_local_dword(cpu, 0, value);
end

code	48
asm	dstore_1
added	JVM
usedby	5TEJ
begin
	// dstore_1
	uint64_t value = j32_pop_dword(cpu);
	j32_write_local_dword(cpu, 1, value);
end

code	49
asm	dstore_2
added	JVM
usedby	5TEJ
begin
	// dstore_2
	uint64_t value = j32_pop_dword(cpu);
	j32_write_local_dword(cpu, 2, value);
end

code	4A
asm	dstore_3
added	JVM
usedby	5TEJ
begin
	// dstore_3
	uint64_t value = j32_pop_dword(cpu);
	j32_write_local_dword(cpu, 3, value);
end

code	4B
asm	astore_0
added	JVM
usedby	5TEJ
begin
	// astore_0
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 0, value);
end

code	4C
asm	astore_1
added	JVM
usedby	5TEJ
begin
	// astore_1
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 1, value);
end

code	4D
asm	astore_2
added	JVM
usedby	5TEJ
begin
	// astore_2
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 2, value);
end

code	4E
asm	astore_3
added	JVM
usedby	5TEJ
begin
	// astore_3
	uint32_t value = j32_pop_word(cpu);
	j32_write_local_word(cpu, 3, value);
end

code	4F
asm	iastore
added	JVM
usedby	5TEJ
begin
	// iastore
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t value = j32_pop_word(cpu);
	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_set_array_word(cpu, arrayref, index, value);
end

code	50
asm	lastore
added	JVM
usedby	5TEJ
begin
	// lastore
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint64_t value = j32_pop_dword(cpu);
	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_set_array_dword(cpu, arrayref, index, value);
end

code	51
asm	fastore
added	JVM
usedby	5TEJ
begin
	// fastore
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t value = j32_pop_word(cpu);
	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_set_array_word(cpu, arrayref, index, value);
end

code	52
asm	dastore
added	JVM
usedby	5TEJ
begin
	// dastore
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint64_t value = j32_pop_dword(cpu);
	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_set_array_dword(cpu, arrayref, index, value);
end

code	53
asm	aastore
added	JVM
usedby	5TEJ
begin
	// aastore
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t value = j32_pop_word(cpu);
	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_set_array_reference(cpu, arrayref, index, value);
end

code	54
asm	bastore
added	JVM
usedby	5TEJ
begin
	// bastore
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t value = j32_pop_word(cpu);
	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_set_array_byte(cpu, arrayref, index, value);
end

code	55
asm	castore
added	JVM
usedby	5TEJ
begin
	// castore
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t value = j32_pop_word(cpu);
	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_set_array_hword(cpu, arrayref, index, value);
end

code	56
asm	sastore
added	JVM
usedby	5TEJ
begin
	// sastore
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t value = j32_pop_word(cpu);
	uint32_t index = j32_pop_word(cpu);
	uint32_t arrayref = j32_pop_word(cpu);
	j32_set_array_hword(cpu, arrayref, index, value);
end

code	57
asm	pop
added	JVM
usedby	5TEJ
begin
	// pop
	j32_pop_word(cpu);
end

code	58
asm	pop2
added	JVM
usedby	5TEJ
begin
	// pop2
	j32_pop_word(cpu);
	j32_pop_word(cpu);
end

code	59
asm	dup
added	JVM
usedby	5TEJ
begin
	// dup
	j32_push_word(cpu, j32_peek_word(cpu, 0));
end

code	5A
asm	dup_x1
added	JVM
usedby	5TEJ
begin
	// dup_x1
	uint32_t value1 = j32_pop_word(cpu);
	uint32_t value2 = j32_pop_word(cpu);
	j32_push_word(cpu, value1);
	j32_push_word(cpu, value2);
	j32_push_word(cpu, value1);
end

code	5B
asm	dup_x2
added	JVM
usedby	5TEJ
begin
	// dup_x2
	uint32_t value1 = j32_pop_word(cpu);
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value3 = j32_pop_word(cpu);
	j32_push_word(cpu, value1);
	j32_push_word(cpu, value3);
	j32_push_word(cpu, value2);
	j32_push_word(cpu, value1);
end

code	5C
asm	dup2
added	JVM
usedby	5TEJ
begin
	// dup2
	j32_push_word(cpu, j32_peek_word(cpu, 1));
	j32_push_word(cpu, j32_peek_word(cpu, 1));
end

code	5D
asm	dup2_x1
added	JVM
usedby	5TEJ
begin
	// dup2_x1
	uint32_t value1 = j32_pop_word(cpu);
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value3 = j32_pop_word(cpu);
	j32_push_word(cpu, value2);
	j32_push_word(cpu, value1);
	j32_push_word(cpu, value3);
	j32_push_word(cpu, value2);
	j32_push_word(cpu, value1);
end

code	5E
asm	dup2_x2
added	JVM
usedby	5TEJ
begin
	// dup2_x2
	uint32_t value1 = j32_pop_word(cpu);
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value3 = j32_pop_word(cpu);
	uint32_t value4 = j32_pop_word(cpu);
	j32_push_word(cpu, value2);
	j32_push_word(cpu, value1);
	j32_push_word(cpu, value4);
	j32_push_word(cpu, value3);
	j32_push_word(cpu, value2);
	j32_push_word(cpu, value1);
end

code	5F
asm	swap
added	JVM
usedby	5TEJ
begin
	// swap
	uint32_t value1 = j32_pop_word(cpu);
	uint32_t value2 = j32_pop_word(cpu);
	j32_push_word(cpu, value1);
	j32_push_word(cpu, value2);
end

code	60
asm	iadd
added	JVM
usedby	5TEJ
begin
	// iadd
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	j32_push_word(cpu, value1 + value2);
end

code	61
asm	ladd
added	JVM
usedby	5TEJ
begin
	// ladd
	uint64_t value2 = j32_pop_dword(cpu);
	uint64_t value1 = j32_pop_dword(cpu);
	j32_push_dword(cpu, value1 + value2);
end

code	62
asm	fadd
added	JVM
usedby	extension
begin
	// fadd
	float value2 = j32_pop_float(cpu);
	float value1 = j32_pop_float(cpu);
	j32_push_float(cpu, value1 + value2);
end

code	63
asm	dadd
added	JVM
usedby	extension
begin
	// dadd
	double value2 = j32_pop_double(cpu);
	double value1 = j32_pop_double(cpu);
	j32_push_double(cpu, value1 + value2);
end

code	64
asm	isub
added	JVM
usedby	5TEJ
begin
	// isub
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	j32_push_word(cpu, value1 - value2);
end

code	65
asm	lsub
added	JVM
usedby	5TEJ
begin
	// lsub
	uint64_t value2 = j32_pop_dword(cpu);
	uint64_t value1 = j32_pop_dword(cpu);
	j32_push_dword(cpu, value1 - value2);
end

code	66
asm	fsub
added	JVM
usedby	extension
begin
	// fsub
	float value2 = j32_pop_float(cpu);
	float value1 = j32_pop_float(cpu);
	j32_push_float(cpu, value1 - value2);
end

code	67
asm	dsub
added	JVM
usedby	extension
begin
	// dsub
	double value2 = j32_pop_double(cpu);
	double value1 = j32_pop_double(cpu);
	j32_push_double(cpu, value1 - value2);
end

code	68
asm	imul
added	JVM
usedby	5TEJ
begin
	// imul
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	j32_push_word(cpu, value1 * value2);
end

code	69
asm	lmul
added	JVM
usedby	5TEJ
begin
	// lmul
	uint64_t value2 = j32_pop_dword(cpu);
	uint64_t value1 = j32_pop_dword(cpu);
	j32_push_dword(cpu, value1 * value2);
end

code	6A
asm	fmul
added	JVM
usedby	extension
begin
	// fsub
	float value2 = j32_pop_float(cpu);
	float value1 = j32_pop_float(cpu);
	j32_push_float(cpu, value1 * value2);
end

code	6B
asm	dmul
added	JVM
usedby	extension
begin
	// dmul
	double value2 = j32_pop_double(cpu);
	double value1 = j32_pop_double(cpu);
	j32_push_double(cpu, value1 * value2);
end

code	6C
asm	idiv
added	JVM
usedby	5TEJ
begin
	// idiv
	int32_t value2 = j32_pop_word(cpu);
	int32_t value1 = j32_pop_word(cpu);
	// TODO: check 0
	j32_push_word(cpu, value1 / value2);
end

code	6D
asm	ldiv
added	JVM
usedby	extension
begin
	// ldiv
	uint64_t value2 = j32_pop_dword(cpu);
	uint64_t value1 = j32_pop_dword(cpu);
	// TODO: check 0
	j32_push_dword(cpu, value1 / value2);
end

code	6E
asm	fdiv
added	JVM
usedby	extension
begin
	// fsub
	float value2 = j32_pop_float(cpu);
	float value1 = j32_pop_float(cpu);
	j32_push_float(cpu, value1 / value2);
end

code	6F
asm	ddiv
added	JVM
usedby	extension
begin
	// ddiv
	double value2 = j32_pop_double(cpu);
	double value1 = j32_pop_double(cpu);
	j32_push_double(cpu, value1 / value2);
end

code	70
asm	irem
added	JVM
usedby	extension
begin
	// irem
	int32_t value2 = j32_pop_word(cpu);
	int32_t value1 = j32_pop_word(cpu);
	j32_push_word(cpu, value1 % value2);
end

code	71
asm	lrem
added	JVM
usedby	extension
begin
	// lrem
	uint64_t value2 = j32_pop_dword(cpu);
	uint64_t value1 = j32_pop_dword(cpu);
	j32_push_dword(cpu, value1 % value2);
end

code	72
asm	frem
added	JVM
usedby	extension
begin
	// frem
	float value2 = j32_pop_float(cpu);
	float value1 = j32_pop_float(cpu);
	j32_push_float(cpu, remainderf(value1, value2));
end

code	73
asm	drem
added	JVM
usedby	extension
begin
	// drem
	double value2 = j32_pop_double(cpu);
	double value1 = j32_pop_double(cpu);
	j32_push_double(cpu, remainder(value1, value2));
end

code	74
asm	ineg
added	JVM
usedby	5TEJ
begin
	// ineg
	uint32_t value = j32_pop_word(cpu);
	j32_push_word(cpu, -value);
end

code	75
asm	lneg
added	JVM
usedby	5TEJ
begin
	// lneg
	uint64_t value = j32_pop_dword(cpu);
	j32_push_dword(cpu, -value);
end

code	76
asm	fneg
added	JVM
usedby	5TEJ
begin
	// fneg
	float value = j32_pop_float(cpu);
	j32_push_float(cpu, -value);
end

code	77
asm	dneg
added	JVM
usedby	extension
begin
	// dneg
	double value = j32_pop_double(cpu);
	j32_push_double(cpu, -value);
end

code	78
asm	ishl
added	JVM
usedby	5TEJ
begin
	// ishl
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	j32_push_word(cpu, value1 << value2);
end

code	79
asm	lshl
added	JVM
usedby	extension
begin
	// lshl
	uint32_t value2 = j32_pop_word(cpu);
	uint64_t value1 = j32_pop_dword(cpu);
	j32_push_dword(cpu, value1 << value2);
end

code	7A
asm	ishr
added	JVM
usedby	5TEJ
begin
	// ishr
	int32_t value2 = j32_pop_word(cpu);
	int32_t value1 = j32_pop_word(cpu);
	j32_push_word(cpu, value1 >> value2);
end

code	7B
asm	lshr
added	JVM
usedby	extension
begin
	// lshr
	int32_t value2 = j32_pop_word(cpu);
	int64_t value1 = j32_pop_dword(cpu);
	j32_push_dword(cpu, value1 >> value2);
end

code	7C
asm	iushr
added	JVM
usedby	5TEJ
begin
	// iushr
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	j32_push_word(cpu, value1 >> value2);
end

code	7D
asm	lushr
added	JVM
usedby	extension
begin
	// lushr
	uint32_t value2 = j32_pop_word(cpu);
	uint64_t value1 = j32_pop_dword(cpu);
	j32_push_dword(cpu, value1 >> value2);
end

code	7E
asm	iand
added	JVM
usedby	5TEJ
begin
	// iand
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	j32_push_word(cpu, value1 & value2);
end

code	7F
asm	land
added	JVM
usedby	5TEJ
begin
	// land
	uint32_t value2 = j32_pop_word(cpu);
	uint64_t value1 = j32_pop_dword(cpu);
	j32_push_dword(cpu, value1 & value2);
end

code	80
asm	ior
added	JVM
usedby	5TEJ
begin
	// ior
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	j32_push_word(cpu, value1 | value2);
end

code	81
asm	lor
added	JVM
usedby	5TEJ
begin
	// lor
	uint32_t value2 = j32_pop_word(cpu);
	uint64_t value1 = j32_pop_dword(cpu);
	j32_push_dword(cpu, value1 | value2);
end

code	82
asm	ixor
added	JVM
usedby	5TEJ
begin
	// iand
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	j32_push_word(cpu, value1 ^ value2);
end

code	83
asm	lxor
added	JVM
usedby	5TEJ
begin
	// lxor
	uint32_t value2 = j32_pop_word(cpu);
	uint64_t value1 = j32_pop_dword(cpu);
	j32_push_dword(cpu, value1 ^ value2);
end

code	84 x:iW c:iW
asm	iinc #{x} {c}
added	JVM
usedby	5TEJ
begin
	// iinc
	j32_write_local_word(cpu, ${x}, j32_read_local_word(cpu, ${x}) + sign_extend(${c!size}, ${c}));
end

code	85
asm	i2l
added	JVM
usedby	5TEJ
begin
	// i2l
	int32_t value = j32_pop_word(cpu);
	j32_push_dword(cpu, (int64_t)value);
end

code	86
asm	i2f
added	JVM
usedby	extension
begin
	// i2f
	int32_t value = j32_pop_word(cpu);
	j32_push_float(cpu, (float)value);
end

code	87
asm	i2d
added	JVM
usedby	extension
begin
	// i2d
	int32_t value = j32_pop_word(cpu);
	j32_push_double(cpu, (double)value);
end

code	88
asm	l2i
added	JVM
usedby	5TEJ
begin
	// l2i
	int64_t value = j32_pop_dword(cpu);
	j32_push_word(cpu, (int32_t)value);
end

code	89
asm	l2f
added	JVM
usedby	extension
begin
	// l2f
	int64_t value = j32_pop_dword(cpu);
	j32_push_float(cpu, (float)value);
end

code	8A
asm	l2d
added	JVM
usedby	extension
begin
	// l2d
	int64_t value = j32_pop_dword(cpu);
	j32_push_double(cpu, (double)value);
end

code	8B
asm	f2i
added	JVM
usedby	extension
begin
	// f2i
	float value = j32_pop_float(cpu);
	j32_push_word(cpu, (int32_t)value);
end

code	8C
asm	f2l
added	JVM
usedby	extension
begin
	// f2l
	float value = j32_pop_float(cpu);
	j32_push_dword(cpu, (int64_t)value);
end

code	8D
asm	f2d
added	JVM
usedby	extension
begin
	// f2d
	float value = j32_pop_float(cpu);
	j32_push_double(cpu, (double)value);
end

code	8E
asm	d2i
added	JVM
usedby	extension
begin
	// d2i
	double value = j32_pop_double(cpu);
	j32_push_word(cpu, (int32_t)value);
end

code	8F
asm	d2l
added	JVM
usedby	extension
begin
	// d2l
	double value = j32_pop_double(cpu);
	j32_push_dword(cpu, (int64_t)value);
end

code	90
asm	d2f
added	JVM
usedby	extension
begin
	// d2f
	double value = j32_pop_double(cpu);
	j32_push_float(cpu, (float)value);
end

code	91
asm	i2b
added	JVM
usedby	5TEJ
begin
	// i2b
	uint32_t value = j32_pop_word(cpu);
	j32_push_word(cpu, (int8_t)value);
end

code	92
asm	i2c
added	JVM
usedby	5TEJ
begin
	// i2c
	uint32_t value = j32_pop_word(cpu);
	j32_push_word(cpu, (int16_t)value);
end

code	93
asm	i2s
added	JVM
usedby	5TEJ
begin
	// i2s
	uint32_t value = j32_pop_word(cpu);
	j32_push_word(cpu, (int16_t)value);
end

code	94
asm	lcmp
added	JVM
usedby	5TEJ
begin
	// lcmp
	int64_t value2 = j32_pop_dword(cpu);
	int64_t value1 = j32_pop_dword(cpu);
	if(value1 < value2)
		j32_push_word(cpu, -1);
	else if(value1 > value2)
		j32_push_word(cpu, 1);
	else
		j32_push_word(cpu, 0);
end

code	95
asm	fcmpl
added	JVM
usedby	extension
begin
	// fcmpl
	float value2 = j32_pop_float(cpu);
	float value1 = j32_pop_float(cpu);
	if(isnan(value1) || isnan(value2) || value1 < value2)
		j32_push_word(cpu, -1);
	else if(value1 > value2)
		j32_push_word(cpu, 1);
	else
		j32_push_word(cpu, 0);
end

code	96
asm	fcmpg
added	JVM
usedby	extension
begin
	// fcmpg
	float value2 = j32_pop_float(cpu);
	float value1 = j32_pop_float(cpu);
	if(isnan(value1) || isnan(value2) || value1 > value2)
		j32_push_word(cpu, 1);
	else if(value1 < value2)
		j32_push_word(cpu, -1);
	else
		j32_push_word(cpu, 0);
end

code	97
asm	dcmpl
added	JVM
usedby	extension
begin
	// dcmpl
	double value2 = j32_pop_double(cpu);
	double value1 = j32_pop_double(cpu);
	if(isnan(value1) || isnan(value2) || value1 < value2)
		j32_push_word(cpu, -1);
	else if(value1 > value2)
		j32_push_word(cpu, 1);
	else
		j32_push_word(cpu, 0);
end

code	98
asm	dcmpg
added	JVM
usedby	extension
begin
	// dcmpg
	double value2 = j32_pop_double(cpu);
	double value1 = j32_pop_double(cpu);
	if(isnan(value1) || isnan(value2) || value1 > value2)
		j32_push_word(cpu, 1);
	else if(value1 < value2)
		j32_push_word(cpu, -1);
	else
		j32_push_word(cpu, 0);
end

code	99 d:i16
asm	ifeq {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// ifeq
	uint32_t value = j32_pop_word(cpu);
	if(value == 0)
		$pc = ${signextend d!offset};
end

code	9A d:i16
asm	ifne {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// ifne
	uint32_t value = j32_pop_word(cpu);
	if(value != 0)
		$pc = ${signextend d!offset};
end

code	9B d:i16
asm	iflt {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// iflt
	uint32_t value = j32_pop_word(cpu);
	if(value < 0)
		$pc = ${signextend d!offset};
end

code	9C d:i16
asm	ifge {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// ifge
	uint32_t value = j32_pop_word(cpu);
	if(value >= 0)
		$pc = ${signextend d!offset};
end

code	9D d:i16
asm	ifgt {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// ifgt
	uint32_t value = j32_pop_word(cpu);
	if(value > 0)
		$pc = ${signextend d!offset};
end

code	9E d:i16
asm	ifle {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// ifle
	uint32_t value = j32_pop_word(cpu);
	if(value <= 0)
		$pc = ${signextend d!offset};
end

code	9F d:i16
asm	if_icmpeq {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// if_icmpeq
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	if(value1 == value2)
		$pc = ${signextend d!offset};
end

code	A0 d:i16
asm	if_icmpne {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// if_icmpne
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	if(value1 != value2)
		$pc = ${signextend d!offset};
end

code	A1 d:i16
asm	if_icmplt {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// if_icmplt
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	if(value1 < value2)
		$pc = ${signextend d!offset};
end

code	A2 d:i16
asm	if_icmpge {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// if_icmpge
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	if(value1 >= value2)
		$pc = ${signextend d!offset};
end

code	A3 d:i16
asm	if_icmpgt {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// if_icmpgt
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	if(value1 > value2)
		$pc = ${signextend d!offset};
end

code	A4 d:i16
asm	if_icmple {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// if_icmple
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	if(value1 <= value2)
		$pc = ${signextend d!offset};
end

code	A5 d:i16
asm	if_acmpeq {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// if_acmpeq
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	if(value1 == value2)
		$pc = ${signextend d!offset};
end

code	A6 d:i16
asm	if_acmpne {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// if_acmpne
	uint32_t value2 = j32_pop_word(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	if(value1 != value2)
		$pc = ${signextend d!offset};
end

code	A7 d:i16
asm	goto {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// goto
	$pc = ${signextend d!offset};
end

code	A8 d:i16
asm	jsr {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// jsr
	j32_push_word(cpu, $pc);
	$pc = ${signextend d!offset};
end

code	A9 x:iW
asm	ret #{x}
added	JVM
usedby	5TEJ
begin
	// ret
	$pc = j32_read_local_word(cpu, ${x});
end

code	AA :padding d:i32 l:i32 h:i32 :label[h-l+1]
asm	tableswitch {d!offset} {l:X} {h:X}
added	JVM
usedby	extension
begin
	// tableswitch
	int32_t index = j32_pop_word(cpu);
	if(index < (int32_t)${l} || index > (int32_t)${h})
		$pc = ${d!offset};
	else
		$pc = j32_fetch32_from(cpu, $pc + (index - ${l}) * 4);
end

code	AB :padding d:i32 n:i32 :pair[n]
asm	lookupswitch {d!offset} {n}
added	JVM
usedby	extension
begin
	// lookupswitch
	int32_t index = j32_pop_word(cpu);
	uint32_t offset = ${d!offset};
	for(uint32_t pair_index = 0; pair_index < ${n}; pair_index++)
	{
		int32_t match = j32_fetch32(cpu);
		uint32_t pair_offset = j32_fetch32(cpu);
		if(index == match)
		{
			offset = $old_pc + pair_offset;
			break;
		}
	}
	$pc = offset;
end

code	AC
asm	ireturn
added	JVM

code	AD
asm	lreturn
added	JVM

code	AE
asm	freturn
added	JVM

code	AF
asm	dreturn
added	JVM

code	B0
asm	areturn
added	JVM

code	B1
asm	return
added	JVM

code	B2 x:i16
asm	getstatic #{x}
added	JVM

code	B3 x:i16
asm	putstatic #{x}
added	JVM

code	B4 x:i16
asm	getfield #{x}
added	JVM

code	B5 x:i16
asm	putfield #{x}
added	JVM

code	B6 x:i16
asm	invokevirtual #{x}
added	JVM

code	B7 x:i16
asm	invokespecial #{x}
added	JVM

code	B8 x:i16
asm	invokestatic #{x}
added	JVM

code	B9 x:i16 c:i8 _:i8
asm	invokeinterface #{x} {c}
added	JVM

code	BA x:i16 _:i8 n:i8
asm	invokedynamic #{x}
added	JVM

code	BB x:i16
asm	new #{x}
added	JVM

code	BC t:i8
asm	newarray #{t}
added	JVM

code	BD x:i16
asm	anewarray #{x}
added	JVM

code	BE
asm	arraylength
added	JVM
usedby	5TEJ
begin
	// arraylength
	if((cpu->joscr & JOSCR_DISABLE_ARRAY_INSTRUCTIONS))
		j32_break(cpu, opcode);

	uint32_t arrayref = j32_pop_word(cpu);
	j32_push_word(cpu, j32_get_array_length(cpu, arrayref));
end

code	BF
asm	athrow
added	JVM

code	C0
asm	checklast
added	JVM

code	C1
asm	instanceof
added	JVM

code	C2
asm	monitorenter
added	JVM

code	C3
asm	monitorexit
added	JVM

code	C4
asm	wide{make_wide()}
added	JVM
usedby	extension
begin
	// wide
	j32_wide = true;
	goto restart;
end

code	C5 x:i16 d:i8
asm	multianewarray #{x} {d}
added	JVM

code	C6 d:i16
asm	ifnull {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// ifnull
	uint32_t value = j32_pop_word(cpu);
	if(value == 0)
		$pc = ${signextend d!offset};
end

code	C7 d:i16
asm	ifnonnull {signextend d!offset}
added	JVM
usedby	5TEJ
begin
	// ifnonnull
	uint32_t value = j32_pop_word(cpu);
	if(value != 0)
		$pc = ${signextend d!offset};
end

code	C8 d:i32
asm	goto_w {signextend d!offset}
added	JVM
usedby	extension
begin
	// goto_w
	$pc = ${signextend d!offset};
end

code	C9 d:i32
asm	jsr_w {signextend d!offset}
added	JVM
usedby	extension
begin
	// jsr_w
	j32_push_word(cpu, $pc);
	$pc = ${signextend d!offset};
end

code	CA
asm	breakpoint
added	JVM

code	CB x:i8
asm	ldc_quick #{x}
added	picoJava

code	CC x:i16
asm	ldc_w_quick #{x}
added	picoJava

code	CD x:i16
asm	ldc2_w_quick #{x}
added	picoJava

code	CE x:i8 _:i8
asm	getfield_quick #{x}
added	picoJava

code	CF x:i8 _:i8
asm	putfield_quick #{x}
added	picoJava

code	D0 x:i8 _:i8
asm	getfield2_quick #{x}
added	picoJava

code	D1 x:i8 _:i8
asm	putfield2_quick #{x}
added	picoJava

code	D2 x:i16
asm	getstatic_quick #{x}
added	picoJava

code	D3 x:i16
asm	putstatic_quick #{x}
added	picoJava

code	D4 x:i16
asm	getstatic2_quick #{x}
added	picoJava

code	D5 x:i16
asm	putstatic2_quick #{x}
added	picoJava

code	D6 x:i8 c:i8
asm	invokevirtual_quick #{x} #{c}
added	picoJava

code	D7 x:i16
asm	invokenonvirtual_quick #{x}
added	picoJava

code	D8 x:i16
asm	invokesuper_quick #{x}
added	picoJava

code	D9 x:i16
asm	invokestatic_quick #{x}
added	picoJava

code	DA x:i16 c:i8 g:i8
asm	invokeinterface_quick #{x} #{c} #{g}
added	picoJava

code	DC
asm	aastore_quick
added	picoJava

code	DD x:i16
asm	new_quick #{x}
added	picoJava

code	DE x:i16
asm	anewarray_quick #{x}
added	picoJava

code	DF x:i16 d:i8
asm	multianewarray_quick #{x} #{d}
added	picoJava

code	E0 x:i16
asm	checkcast_quick #{x}
added	picoJava

code	E1 x:i16
asm	instanceof_quick #{x}
added	picoJava

code	E2 x:i16
asm	invokevirtual_quick_w #{x}
added	picoJava

code	E3 x:i16
asm	getfield_quick_w #{x}
added	picoJava

code	E4 x:i16
asm	putfield_quick_w #{x}
added	picoJava

code	E5
asm	nonnull_quick
added	picoJava

code	E6 x:i16
asm	agetfield_quick #{x}
added	picoJava

code	E7 x:i16
asm	aputfield_quick #{x}
added	picoJava

code	E8 x:i16
asm	agetstatic_quick #{x}
added	picoJava

code	E9 x:i16
asm	aputstatic_quick #{x}
added	picoJava

code	EA x:i8
asm	aldc_quick #{x}
added	picoJava

code	EB x:i16
asm	aldc_w_quick #{x}
added	picoJava

code	EC
asm	exit_sync_method
added	picoJava

code	ED v:i16
asm	sethi #{v}
added	picoJava
usedby	extension
begin
	// sethi
	uint32_t value = j32_pop_word(cpu);
	j32_push_word(cpu, ((uint32_t)${v} << 16) | (value & 0x0000FFFF));
end

code	EE x:i8 o:i8
asm	load_word_index #{x} #{o}
added	picoJava

code	EF x:i8 o:i8
asm	load_short_index #{x} #{o}
added	picoJava

code	F0 x:i8 o:i8
asm	load_char_index #{x} #{o}
added	picoJava

code	F1 x:i8 o:i8
asm	load_byte_index #{x} #{o}
added	picoJava

code	F2 x:i8 o:i8
asm	load_ubyte_index #{x} #{o}
added	picoJava

code	F3 x:i8 o:i8
asm	store_word_index #{x} #{o}
added	picoJava

code	F4 x:i8 o:i8
asm	nastore_word_index #{x} #{o}
added	picoJava

code	F5 x:i8 o:i8
asm	store_short_index #{x} #{o}
added	picoJava

code	F6 x:i8 o:i8
asm	store_byte_index #{x} #{o}
added	picoJava

code	FE 00
asm	ret_from_jazelle
added	extension
usedby	extension
begin
	// ret_from_jazelle
	j32_spill_fast_stack(cpu);
	uint32_t address = j32_pop_word(cpu);
	$lr = $pc_next;
	//$cpsr.j = 0;
	$cpsr.thumb = address & 1; // must be set first for proper alignment
	$pc = address;
end

code	FE 01
asm	swi
added	extension
usedby	extension
begin
	// swi
	j32_spill_fast_stack(cpu);
	arm_svc(cpu);
end

code	FE 02
asm	jsr_indirect
added	extension
usedby	extension
begin
	// jsr_indirect
	j32_spill_fast_stack(cpu);
	uint32_t address = j32_pop_word(cpu);
	j32_push_word(cpu, $pc_next);
	$pc = address;
end

code	FF
asm	bkpt #0
added	5TEJ
usedby	5TEJ
begin
	// brkpt #0
	$pc = $pc_next;
	arm_breakpoint(cpu);
end

#code	FF
#asm	extend
#added	picoJava

code	FF 00
asm	load_ubyte
added	picoJava
usedby	extension
begin
	// load_ubyte
	uint32_t value = j32_pop_word(cpu);
	j32_push_word(cpu, a32_read8(cpu, value));
end

code	FF 01
asm	load_byte
added	picoJava
usedby	extension
begin
	// load_byte
	uint32_t value = j32_pop_word(cpu);
	j32_push_word(cpu, sign_extend(8, a32_read8(cpu, value)));
end

code	FF 02
asm	load_char
added	picoJava
usedby	extension
begin
	// load_char
	uint32_t value = j32_pop_word(cpu);
	j32_push_word(cpu, a32_read16(cpu, value));
end

code	FF 03
asm	load_short
added	picoJava
usedby	extension
begin
	// load_short
	uint32_t value = j32_pop_word(cpu);
	j32_push_word(cpu, sign_extend(16, a32_read16(cpu, value)));
end

code	FF 04
asm	load_word
added	picoJava
usedby	extension
begin
	// load_word
	uint32_t value = j32_pop_word(cpu);
	j32_push_word(cpu, a32_read32(cpu, value));
end

code	FF 05
asm	priv_ret_from_trap
added	picoJava

code	FF 06
asm	priv_read_dcache_tag
added	picoJava

code	FF 07
asm	priv_read_dcache_data
added	picoJava

code	FF 0A
asm	load_char_oe
added	picoJava

code	FF 0B
asm	load_short_oe
added	picoJava

code	FF 0C
asm	load_word_oe
added	picoJava

code	FF 0D
asm	return0
added	picoJava
usedby	extension
begin
	// return0
	j32_spill_fast_stack(cpu);
	$pc = j32_pop_word(cpu);
	uint32_t loc = j32_pop_word(cpu);
	$r[J32_TOS] = $r[J32_LOC];
	$r[J32_LOC] = loc;
end

code	FF 0E
asm	priv_read_icache_tag
added	picoJava

code	FF 0F
asm	priv_read_icache_data
added	picoJava

code	FF 10
asm	ncload_ubyte
added	picoJava

code	FF 11
asm	ncload_byte
added	picoJava

code	FF 12
asm	ncload_char
added	picoJava

code	FF 13
asm	ncload_short
added	picoJava

code	FF 14
asm	ncload_word
added	picoJava

code	FF 15
asm	iucmp
added	picoJava
usedby	extension
begin
	// iucmp
	uint16_t value2 = j32_pop_word(cpu);
	uint16_t value1 = j32_pop_word(cpu);
	if(value1 > value2)
		j32_push_word(cpu, 1);
	else if(value1 < value2)
		j32_push_word(cpu, -1);
	else
		j32_push_word(cpu, 0);
end

code	FF 16
asm	priv_powerdown
added	picoJava

code	FF 17
asm	cache_invalidate
added	picoJava

code	FF 1A
asm	ncload_char_oe
added	picoJava

code	FF 1B
asm	ncload_short_oe
added	picoJava

code	FF 1C
asm	ncload_word_oe
added	picoJava

code	FF 1D
asm	return1
added	picoJava
usedby	extension
begin
	// return1
	j32_spill_fast_stack(cpu);
	uint32_t value = j32_pop_word(cpu);
	$pc = j32_pop_word(cpu);
	uint32_t loc = j32_pop_word(cpu);
	$r[J32_TOS] = $r[J32_LOC];
	$r[J32_LOC] = loc;
	j32_push_word(cpu, value);
end

code	FF 1E
asm	cache_flush
added	picoJava

code	FF 1F
asm	cache_index_flush
added	picoJava

code	FF 20
asm	store_byte
added	picoJava
usedby	extension
begin
	// store_byte
	uint32_t address = j32_pop_word(cpu);
	uint32_t value = j32_pop_word(cpu);
	a32_write8(cpu, address, value);
end

code	FF 22
asm	store_short
added	picoJava
usedby	extension
begin
	// store_short
	uint32_t address = j32_pop_word(cpu);
	uint32_t value = j32_pop_word(cpu);
	a32_write16(cpu, address, value);
end

code	FF 24
asm	store_word
added	picoJava
usedby	extension
begin
	// store_word
	uint32_t address = j32_pop_word(cpu);
	uint32_t value = j32_pop_word(cpu);
	a32_write32(cpu, address, value);
end

code	FF 25
asm	soft_trap
added	picoJava

code	FF 26
asm	priv_write_dcache_tag
added	picoJava

code	FF 27
asm	priv_write_dcache_data
added	picoJava

code	FF 2A
asm	store_short_ce
added	picoJava

code	FF 2C
asm	store_word_oe
added	picoJava

code	FF 2D
asm	return2
added	picoJava
usedby	extension
begin
	// return2
	j32_spill_fast_stack(cpu);
	uint32_t value1 = j32_pop_word(cpu);
	uint32_t value2 = j32_pop_word(cpu);
	$pc = j32_pop_word(cpu);
	uint32_t loc = j32_pop_word(cpu);
	$r[J32_TOS] = $r[J32_LOC];
	$r[J32_LOC] = loc;
	j32_push_word(cpu, value2);
	j32_push_word(cpu, value1);
end

code	FF 2E
asm	priv_write_icache_tag
added	picoJava

code	FF 2F
asm	priv_write_icache_data
added	picoJava

code	FF 30
asm	ncstore_byte
added	picoJava

code	FF 32
asm	ncstore_short
added	picoJava

code	FF 33
asm	ncstore_word
added	picoJava

code	FF 36
asm	priv_reset
added	picoJava

code	FF 37
asm	get_current_class
added	picoJava

code	FF 3A
asm	ncstore_short_oe
added	picoJava

code	FF 3C
asm	ncstore_word_oe
added	picoJava

code	FF 3D
asm	call
added	picoJava
usedby	extension
begin
	// call
	j32_spill_fast_stack(cpu);
	uint32_t nargs = j32_pop_word(cpu);
	uint32_t target = j32_pop_word(cpu);
	j32_push_word(cpu, $r[J32_LOC]);
	j32_push_word(cpu, $pc);
	$r[J32_LOC] = $r[J32_TOS] - 4 * nargs;
	$pc = target;
end

code	FF 3E
asm	zero_line
added	picoJava

code	FF 3F
asm	priv_update_optop
added	picoJava

code	FF 40
asm	read_pc
added	picoJava
usedby	extension
begin
	// read_pc
	j32_push_word(cpu, $pc);
end

code	FF 41
asm	read_vars
added	picoJava
usedby	extension
begin
	// read_vars
	j32_push_word(cpu, $r[J32_LOC]);
end

code	FF 42
asm	read_frame
added	picoJava

code	FF 43
asm	read_optop
added	picoJava
usedby	extension
begin
	// read_optop
	j32_spill_fast_stack(cpu);
	j32_push_word(cpu, $r[J32_TOS]);
end

code	FF 44
asm	priv_read_oplim
added	picoJava

code	FF 45
asm	read_const_pool
added	picoJava
usedby	extension
begin
	// read_const_pool
	j32_push_word(cpu, $r[J32_CP]);
end

code	FF 46
asm	priv_read_psr
added	picoJava

code	FF 47
asm	priv_read_trapbase
added	picoJava

code	FF 48
asm	priv_read_lockcount0
added	picoJava

code	FF 49
asm	priv_read_lockcount1
added	picoJava

code	FF 4C
asm	priv_read_lockaddr0
added	picoJava

code	FF 4D
asm	priv_read_lockaddr1
added	picoJava

code	FF 50
asm	priv_read_userrange1
added	picoJava

code	FF 51
asm	priv_read_gc_config
added	picoJava

code	FF 52
asm	priv_read_brk1a
added	picoJava

code	FF 53
asm	priv_read_brk2a
added	picoJava

code	FF 54
asm	priv_read_brk12c
added	picoJava

code	FF 55
asm	priv_read_userrange2
added	picoJava

code	FF 57
asm	priv_read_versionid
added	picoJava

code	FF 58
asm	priv_read_hcr
added	picoJava

code	FF 59
asm	priv_read_sc_bottom
added	picoJava

code	FF 5A
asm	read_global0
added	picoJava

code	FF 5B
asm	read_global1
added	picoJava

code	FF 5C
asm	read_global2
added	picoJava

code	FF 5D
asm	read_global3
added	picoJava

code	FF 60
#asm	ret_from_sub
asm	write_pc
added	picoJava
usedby	extension
begin
	// write_pc/ret_from_sub
	$pc = j32_pop_word(cpu);
end

code	FF 61
asm	write_vars
added	picoJava
usedby	extension
begin
	// write_vars
	$r[J32_LOC] = j32_pop_word(cpu);
end

code	FF 62
asm	write_frame
added	picoJava

code	FF 63
asm	write_optop
added	picoJava
usedby	extension
begin
	// write_optop
	j32_spill_fast_stack(cpu);
	$r[J32_TOS] = j32_pop_word(cpu);
end

code	FF 64
asm	priv_write_oplim
added	picoJava

code	FF 65
asm	write_const_pool
added	picoJava
usedby	extension
begin
	// write_const_pool
	$r[J32_CP] = j32_pop_word(cpu);
end

code	FF 66
asm	priv_write_psr
added	picoJava

code	FF 67
asm	priv_write_trapbase
added	picoJava

code	FF 68
asm	priv_write_lockcount0
added	picoJava

code	FF 69
asm	priv_write_lockcount1
added	picoJava

code	FF 6C
asm	priv_write_lockaddr0
added	picoJava

code	FF 6D
asm	priv_write_lockaddr1
added	picoJava

code	FF 70
asm	priv_write_userrange1
added	picoJava

code	FF 71
asm	priv_write_gc_config
added	picoJava

code	FF 72
asm	priv_write_brk1a
added	picoJava

code	FF 73
asm	priv_write_brk2a
added	picoJava

code	FF 74
asm	priv_write_brk12c
added	picoJava

code	FF 75
asm	priv_write_userrange2
added	picoJava

code	FF 79
asm	priv_write_sc_bottom
added	picoJava

code	FF 7A
asm	write_global0
added	picoJava

code	FF 7B
asm	write_global1
added	picoJava

code	FF 7C
asm	write_global2
added	picoJava

code	FF 7D
asm	write_global3
added	picoJava

######## AArch64
# the 64-bit instruction set comes with its own set of complexities, so a few new macros are needed
# $x[n] and $w[n] access the general purpose registers R0-R30, or the zero register
# $x|sp[n,suppress_sp] can also access the SP register, provided that suppress_sp evaluates to false
# for instructions, {d.W!r} denotes a register or the zero register, {d.W!sp} a register or SP, and {d.W!sp?suppress_sp} can only denote SP if suppress_sp evaluates to false

isa	A64

code	W0S11010000mmmmm000000nnnnnddddd
asm	adc{S?s:} {d.W!r}, {n.W!r}, {m.W!r}
added	8
begin
	// adc/adcs
	if(${W!test})
		$x[${d}] = a64_adc64(cpu, $x[${n}], $x[${m}], ${S!test});
	else
		$w[${d}] = a64_adc32(cpu, $w[${n}], $w[${m}], ${S!test});
end

code	W0S01011001mmmmmOooiiinnnnnddddd
exclude	..1........................11111
asm	add{S?s:} {d.W!sp?S}, {n.W!sp}, {m.W'o!r}{extend(O'o,i,W)}
added	8
begin
	// add/adds
	if(${W!test})
		$x|sp[${d},${S!test}] = a64_add64(cpu, $x|sp[${n},0], a64_extend($x[${m}], ${O'o}, ${i}), ${S!test});
	else
		$w|sp[${d},${S!test}] = a64_add32(cpu, $w|sp[${n},0], a64_extend($w[${m}], ${O'o}, ${i}), ${S!test});
end

code	W0S1000100iiiiiiiiiiiinnnnnddddd
asm	add{S?s:} {d.W!sp?S}, {n.W!sp}, #{i:X}
added	8
begin
	// add/adds
	if(${W!test})
		$x|sp[${d},${S!test}] = a64_add64(cpu, $x|sp[${n},0], ${i}, ${S!test});
	else
		$w|sp[${d},${S!test}] = a64_add32(cpu, $w|sp[${n},0], ${i}, ${S!test});
end

code	W0S1000101iiiiiiiiiiiinnnnnddddd
asm	add{S?s:} {d.W!sp?S}, {n.W!sp}, #{i'000000000000:X}
added	8
begin
	// add/adds
	if(${W!test})
		$x|sp[${d},${S!test}] = a64_add64(cpu, $x|sp[${n},0], ${i'000000000000}, ${S!test});
	else
		$w|sp[${d},${S!test}] = a64_add32(cpu, $w|sp[${n},0], ${i'000000000000}, ${S!test});
end

code	W0S01011ss0mmmmmiiiiiinnnnnddddd
exclude	........11......................
exclude	0...............1...............
asm	add{S?s:} {d.W!sp?S}, {n.W!r}, {m.W!r}, {s?lsl;lsr;asr;} #{i}
added	8
begin
	// add/adds
	if(${W!test})
		$x|sp[${d},${S!test}] = a64_add64(cpu, $x|sp[${n},0], a64_get_shifted_operand64($x[${m}], ${s}, ${i}), ${S!test});
	else
		$w|sp[${d},${S!test}] = a64_add32(cpu, $w|sp[${n},0], a64_get_shifted_operand32($w[${m}], ${s}, ${i}), ${S!test});
end

code	0II10000iiiiiiiiiiiiiiiiiiiddddd
asm	adr {d.1!r}, {signextend i'I!offset}
added	8
begin
	// adr
	$x[${d}] = ${signextend i'I!offset};
end

code	1II10000iiiiiiiiiiiiiiiiiiiddddd
asm	adrp {d.1!r}, {signextend i'I'000000000000!shifted_offset}
added	8
begin
	// adrp
	$x[${d}] = ${signextend i'I'000000000000!shifted_offset};
end

code	W00100100.............nnnnnddddd
exclude	0........1......................
asm	and {d.W!sp}, {n.W!r}, #{bitmask(W)}
added	8
begin
	// and
	if(${W!test})
		$x|sp[${d},0] = a64_and64(cpu, $x[${n}], ${bitmask(1)}, false);
	else
		$w|sp[${d},0] = a64_and32(cpu, $w[${n}], ${bitmask(0)}, false);
end

code	W11100100.............nnnnnddddd
exclude	0........1......................
asm	ands {d.W!r}, {n.W!r}, #{bitmask(W)}
added	8
begin
	// and
	if(${W!test})
		$x[${d}] = a64_and64(cpu, $x[${n}], ${bitmask(1)}, true);
	else
		$w[${d}] = a64_and32(cpu, $w[${n}], ${bitmask(0)}, true);
end

code	W.S01010ss0mmmmmiiiiiinnnnnddddd
exclude	.01.............................
exclude	.10.............................
exclude	0...............1...............
asm	and{S?s:} {d.W!r}, {n.W!r}, {m.W!r}, {s?lsl;lsr;asr;ror} #{i}
added	8
begin
	// and/ands
	if(${W!test})
		$x[${d}] = a64_and64(cpu, $x[${n}], a64_get_shifted_operand64($x[${m}], ${s}, ${i}), ${S!test});
	else
		$w[${d}] = a64_and32(cpu, $w[${n}], a64_get_shifted_operand32($w[${m}], ${s}, ${i}), ${S!test});
end

code	W0011010110mmmmm0010ssnnnnnddddd
asm	{s?lsl;lsr;asr;ror}v {d.W!r}, {n.W!r}, {m.W!r}
added	8
begin
	// asrv/lslv/lsrv/rorv
	if(${W!test})
		$x[${d}] = a64_get_shifted_operand64($x[${n}], ${s}, $x[${m}] & 0x1F);
	else
		$w[${d}] = a64_get_shifted_operand32($x[${n}], ${s}, $x[${m}] & 0x3F);
end

# TODO: at

code	01010100iiiiiiiiiiiiiiiiiii0cccc
asm	b.{cond(c)} {signextend i'00!offset}
added	8
begin
	// b
	if($c[${c}])
	{
		$pc = ${signextend i'00!offset};
	}
end

code	L00101iiiiiiiiiiiiiiiiiiiiiiiiii
asm	b{L?l:} {signextend i'00!offset}
added	8
begin
	// b/bl
	if(${L!test})
		$x[A64_LR] = $pc + 4;
	$pc = ${signextend i'00!offset};
end

code	W01100110NRRRRRRSSSSSSnnnnnddddd
exclude	1........0......................
exclude	0........1......................
exclude	0.........1.....................
exclude	0...............1...............
asm	bfm {d.W!r}, {n.W!r}, #{R}, #{S}
added	8
begin
	// bfm
	if(${W!test})
		$x[${d}] = a64_bfm64($x[${d}], $x[${n}], ${R}, ${S});
	else
		$w[${d}] = a64_bfm32($w[${d}], $w[${n}], ${R}, ${S});
end

code	W.S01010ss1mmmmmiiiiiinnnnnddddd
exclude	.01.............................
exclude	.10.............................
exclude	0...............1...............
asm	bic{S?s:} {d.W!r}, {n.W!r}, {m.W!r}, {s?lsl;lsr;asr;ror} #{i}
added	8
begin
	// bic/bics
	if(${W!test})
		$x[${d}] = a64_bic64(cpu, $x[${n}], a64_get_shifted_operand64($x[${m}], ${s}, ${i}), ${S!test});
	else
		$w[${d}] = a64_bic32(cpu, $w[${n}], a64_get_shifted_operand32($w[${m}], ${s}, ${i}), ${S!test});
end

code	110101100RL11111000000nnnnn00000
exclude	.........11.....................
asm	{R?ret:b}{L?l:}{R?:r} {n.1!r}
added	8
begin
	// br/blr/ret
	uint64_t target = $x[${n}];
	if(${L!test})
		$x[A64_LR] = $pc + 4;
	$pc = target;
end

code	11010100001iiiiiiiiiiiiiiii00000
asm	brk #{i:4X}
added	8
begin
	// brk
	arm_breakpoint(cpu);
end

code	W011010Niiiiiiiiiiiiiiiiiiittttt
asm	cb{N?n:}z {t.W!r}, {signextend i'00!offset}
added	8
begin
	// cbz/cbnz
	if(${W!test})
	{
		if(${N!test} ? $x[${t}] != 0 : $x[${t}] == 0)
			$pc = ${signextend i'00!offset};
	}
	else
	{
		if(${N!test} ? $w[${t}] != 0 : $w[${t}] == 0)
			$pc = ${signextend i'00!offset};
	}
end

code	W0111010010iiiiicccc10nnnnn0ffff
asm	ccmn {n.W!r}, #{i}, #{f:2X}, {cond(c)}
added	8
begin
	// ccmn
	if($c[${c}])
	{
		if(${W!test})
			a64_add64(cpu, $x[${n}], ${i}, true);
		else
			a64_add32(cpu, $w[${n}], ${i}, true);
	}
	else
	{
		$nzcv = ${f};
	}
end

code	W0111010010mmmmmcccc00nnnnn0ffff
asm	ccmn {n.W!r}, {m.W!r}, #{f:2X}, {cond(c)}
added	8
begin
	// ccmn
	if($c[${c}])
	{
		if(${W!test})
			a64_add64(cpu, $x[${n}], $x[${m}], true);
		else
			a64_add32(cpu, $w[${n}], $w[${m}], true);
	}
	else
	{
		$nzcv = ${f};
	}
end

code	W1111010010iiiiicccc10nnnnn0ffff
asm	ccmp {n.W!r}, #{i}, #{f:2X}, {cond(c)}
added	8
begin
	// ccmp
	if($c[${c}])
	{
		if(${W!test})
			a64_add64(cpu, $x[${n}], ${i}, true);
		else
			a64_add32(cpu, $w[${n}], ${i}, true);
	}
	else
	{
		$nzcv = ${f};
	}
end

code	W1111010010mmmmmcccc00nnnnn0ffff
asm	ccmp {n.W!r}, {m.W!r}, #{f:2X}, {cond(c)}
added	8
begin
	// ccmp
	if($c[${c}])
	{
		if(${W!test})
			a64_add64(cpu, $x[${n}], $x[${m}], true);
		else
			a64_add32(cpu, $w[${n}], $w[${m}], true);
	}
	else
	{
		$nzcv = ${f};
	}
end

code	11010101000000110011mmmm01011111
asm	clrex #{m}
added	8
begin
	// clrex
	a32_clear_exclusive(cpu);
end

code	W10110101100000000010Znnnnnddddd
asm	cl{Z?s:z} {d.W!r}, {n.W!r}
added	8
begin
	// cls/clz
	if(${Z!test})
	{
		if(${W!test})
			$x[${d}] = cls64($x[${n}]);
		else
			$w[${d}] = cls32($w[${n}]);
	}
	else
	{
		if(${W!test})
			$x[${d}] = clz64($x[${n}]);
		else
			$w[${d}] = clz32($w[${n}]);
	}
end

code	WN011010100mmmmmcccc0Innnnnddddd
asm	c{N'I?sel;sinc;sinv;sneg} {d.W!r}, {n.W!r}, {m.W!r}, {cond(c)}
added	8
begin
	// csel/csinc/csinv/csneg
	if(${W!test})
		$x[${d}] = $c[${c}] ? $x[${n}] : ($x[${m}] ^ (${N!test} ? (uint64_t)-1 : 0)) + ${I};
	else
		$w[${d}] = $c[${c}] ? $w[${n}] : ($w[${m}] ^ (${N!test} ? (uint32_t)-1 : 0)) + ${I};
end

# TODO: dc

code	11010100101iiiiiiiiiiiiiiii000LL
exclude	..............................00
asm	dcps{L} #{i:4X}
added	8
begin
	// dcps
	// TODO
end

code	11010101000000110011mmmm10111111
asm	dmb #{m}
added	8
begin
	// dmb
	// TODO
end

code	11010110101111110000001111100000
asm	drps
added	8
begin
	// drps
	// TODO
end

code	11010101000000110011mmmm10011111
# TODO
exclude	....................1100........	since	8-R
asm	dsb #{m}
added	8
begin
	// dsb
	// TODO
end

code	W1001010ss1mmmmmiiiiiinnnnnddddd
exclude	0...............1...............
asm	eon {d.W!r}, {n.W!r}, {m.W!r}, {s?lsl;lsr;asr;} #{i}
added	8
begin
	// eon
	if(${W!test})
		$x[${d}] = $x[${n}] ^ ~a64_get_shifted_operand64($x[${m}], ${s}, ${i});
	else
		$w[${d}] = $w[${n}] ^ ~a64_get_shifted_operand32($w[${m}], ${s}, ${i});
end

code	W10100100.............nnnnnddddd
exclude	0........1......................
asm	eor {d.W!sp}, {n.W!r}, #{bitmask(W)}
added	8
begin
	// eor
	if(${W!test})
		$x|sp[${d},0] = $x[${n}] ^ ${bitmask(1)};
	else
		$w|sp[${d},0] = $w[${n}] ^ ${bitmask(0)};
end

code	W1001010ss0mmmmmiiiiiinnnnnddddd
exclude	0...............1...............
asm	eor {d.W!r}, {n.W!r}, {m.W!r}, {s?lsl;lsr;asr;ror} #{i}
added	8
begin
	// eor
	if(${W!test})
		$x[${d}] = $x[${n}] ^ a64_get_shifted_operand64($x[${m}], ${s}, ${i});
	else
		$w[${d}] = $w[${n}] ^ a64_get_shifted_operand32($w[${m}], ${s}, ${i});
end

code	11010110100111110000001111100000
asm	eret
added	8
begin
	// eret
	a64_eret(cpu);
end

code	W00100111.0mmmmmiiiiiinnnnnddddd
exclude	0........1......................
exclude	0...............1...............
exclude	1........0......................
asm	extr {d.W!r}, {n.W!r}, {m.W!r}, #{i}
added	8
begin
	// extr
	if(${W!test})
		$x[${d}] = ${i} == 0 ? $x[${m}] : ($x[${n}] << (64 - ${i})) | ($x[${m}] >> ${i});
	else
		$w[${d}] = ${i} == 0 ? $w[${m}] : ($w[${n}] << (64 - ${i})) | ($w[${m}] >> ${i});
end

code	11010101000000110010iiiiiii11111
exclude	....................0000000.....
exclude	....................000001......
exclude	....................000010......
exclude	....................001000......	since	8.2
asm	hint #{i}
added	8
begin
	// hint
end

code	11010100010iiiiiiiiiiiiiiii00000
asm	hlt #{i:4X}
added	8
begin
	// hlt
	// TODO
end

code	11010100000iiiiiiiiiiiiiiii00010
asm	hvc #{i:4X}
added	8
begin
	// hvc
	arm_hvc(cpu);
end

# TODO: ic

code	11010101000000110011mmmm11011111
asm	isb #{m}
added	8
begin
	// isb
	// TODO
end

code	WW001000XL0!!!!!1!!!!!nnnnnttttt
asm	{L?stl:lda}{X?:x}r{W?b;h;;} {t.W!r}, [{n.1!sp}]
added	8
begin
	// stlr/stlxr/ldar/ldaxr
	// stlrb/stlxrb/ldarb/ldaxrb
	// stlrh/stlxrh/ldarh/ldaxrh
	// TODO
end

code	1W0010000L1!!!!!1TTTTTnnnnnttttt
asm	{L?lda:stl}xp {t.W!r}, {T.W!r}, [{n.1!sp}]
added	8
begin
	// ldaxp/stlxp
	// TODO
end

code	W01010000LiiiiiiiTTTTTnnnnnttttt
asm	{L?ld:st}np {t.W!r}, {T.W!r}, [{n.1!sp}, #{signextend i'00<<W:2X}]
added	8
begin
	// ldnp/stnp
	// TODO
end

code	W01010001LiiiiiiiTTTTTnnnnnttttt
asm	{L?ldp:stp} {t.W!r}, {T.W!r}, [{n.1!sp}], #{signextend i'00<<W:2X}
added	8
begin
	// ldp/stl
	if(${L!test})
		a64_ldp(cpu, ${W!test}, ${W} ? MEM64 : MEM32, UNSIGNED, ${t}, ${T}, ${n}, ${signextend i'00<<W}, POSTINDEXED, WRITEBACK);
	else
		a64_stp(cpu, ${W!test}, ${W} ? MEM64 : MEM32,           ${t}, ${T}, ${n}, ${signextend i'00<<W}, POSTINDEXED, WRITEBACK);
end

code	W0101001wLiiiiiiiTTTTTnnnnnttttt
asm	{L?ldp:stp} {t.W!r}, {T.W!r}, [{n.1!sp}, #{signextend i'00<<W:2X}]{w?!:}
added	8
begin
	// ldp/stp
	if(${L!test})
		a64_ldp(cpu, ${W!test}, ${W} ? MEM64 : MEM32, UNSIGNED, ${t}, ${T}, ${n}, ${signextend i'00<<W}, PREINDEXED, ${w});
	else
		a64_stp(cpu, ${W!test}, ${W} ? MEM64 : MEM32,           ${t}, ${T}, ${n}, ${signextend i'00<<W}, PREINDEXED, ${w});
end

code	0110100011iiiiiiiTTTTTnnnnnttttt
asm	ldpsw {t.1!r}, {T.1!r}, [{n.1!sp}], #{signextend i'000:2X}
added	8
begin
	// ldpsw
	a64_ldp(cpu, OP64, MEM32, SIGNED, ${t}, ${T}, ${n}, ${signextend i'000}, POSTINDEXED, WRITEBACK);
end

code	01101001w1iiiiiiiTTTTTnnnnnttttt
asm	ldpsw {t.1!r}, {T.1!r}, [{n.1!sp}, #{signextend i'000:2X}]{w?!:}
added	8
begin
	// ldpsw
	a64_ldp(cpu, OP64, MEM32, SIGNED, ${t}, ${T}, ${n}, ${signextend i'000}, PREINDEXED, ${w});
end

code	WW1110000L0iiiiiiiii01nnnnnttttt
asm	{L?ldr:str}{W?b;h;;} {t.W!r}, [{n.1!sp}], #{signextend i:X}
added	8
begin
	// ldrb/ldrh/ldr
	// strb/strh/str

	if(${L!test})
		a64_ldr(cpu, ${W} == 3, 1 << ${W}, UNSIGNED, ${t}, ${n}, ${signextend i}, POSTINDEXED, WRITEBACK);
	else
		a64_str(cpu, ${W} == 3, 1 << ${W},           ${t}, ${n}, ${signextend i}, POSTINDEXED, WRITEBACK);
end

code	HH1110001W0iiiiiiiii01nnnnnttttt
exclude	11..............................
exclude	10.......1......................
asm	ldrs{H?b;h;w;} {t.~W!r}, [{n.1!sp}], #{signextend i:X}
added	8
begin
	// ldrsb/ldrsh/ldrsw

	a64_ldr(cpu, !${W!test}, ${H}, SIGNED, ${t}, ${n}, ${signextend i}, POSTINDEXED, WRITEBACK);
end

code	WW1110000L0iiiiiiiii11nnnnnttttt
asm	{L?ldr:str}{W?b;h;;} {t.W!r}, [{n.1!sp}, #{signextend i:X}]!
added	8
begin
	// ldrb/ldrh/ldr
	// strb/strh/str

	if(${L!test})
		a64_ldr(cpu, ${W} == 3, 1 << ${W}, UNSIGNED, ${t}, ${n}, ${signextend i}, PREINDEXED, WRITEBACK);
	else
		a64_str(cpu, ${W} == 3, 1 << ${W},           ${t}, ${n}, ${signextend i}, PREINDEXED, WRITEBACK);
end

code	HH1110001W0iiiiiiiii11nnnnnttttt
exclude	11..............................
exclude	10.......1......................
asm	ldrs{H?b;h;w;} {t.~W!r}, [{n.1!sp}, #{signextend i:X}]!
added	8
begin
	// ldrsb/ldrsh/ldrsw

	a64_ldr(cpu, !${W!test}, ${H}, SIGNED, ${t}, ${n}, ${signextend i}, PREINDEXED, WRITEBACK);
end

code	WW1110010Liiiiiiiiiiiinnnnnttttt
asm	{L?ldr:str}{W?b;h;;} {t.W!r}, [{n.1!sp}, #{i<<W:X}]
added	8
begin
	// ldrb/ldrh/ldr
	// strb/strh/str

	if(${L!test})
		a64_ldr(cpu, ${W} == 3, 1 << ${W}, UNSIGNED, ${t}, ${n}, ${i} << ${W}, PREINDEXED, NOWRITEBACK);
	else
		a64_str(cpu, ${W} == 3, 1 << ${W},           ${t}, ${n}, ${i} << ${W}, PREINDEXED, NOWRITEBACK);
end

code	HH1110011Wiiiiiiiiiiiinnnnnttttt
exclude	11..............................
exclude	10.......1......................
asm	ldrs{H?b;h;w;} {t.~W!r}, [{n.1!sp}, #{i<<H:X}]
added	8
begin
	// ldrsb/ldrsh/ldrsw

	a64_ldr(cpu, !${W!test}, ${H}, SIGNED, ${t}, ${n}, ${i} << ${H}, PREINDEXED, NOWRITEBACK);
end

code	0W011000iiiiiiiiiiiiiiiiiiittttt
asm	ldr {t.W!r}, {signextend i'00!offset}
added	8
begin
	// ldr

	a64_ldr(cpu, ${W!test}, ${W!test} ? MEM64 : MEM32, UNSIGNED, ${t}, PC, ${signextend i'00!offset}, PREINDEXED, NOWRITEBACK);
end

code	10011000iiiiiiiiiiiiiiiiiiittttt
asm	ldrsw {t.1!r}, {signextend i'00!offset}
added	8
begin
	// ldrsw
	a64_ldr(cpu, OP64, MEM32, SIGNED, ${t}, PC, ${signextend i'00!offset}, PREINDEXED, NOWRITEBACK);
end

code	WW1110000L1mmmmmOOoS10nnnnnttttt
asm	{L?ldr:str}{W?b;h;;} {t.W!r}, [{n.1!sp}, {m.o!r}{extend(O'o,W*S,1)}]
added	8
begin
	// ldrb/ldrh/ldr
	// strb/strh/str

	if(${L!test})
		a64_ldr(cpu, ${W} == 3, 1 << ${W}, UNSIGNED, ${t}, ${n}, a64_extend($x[${m}], ${O'o}, ${S!test} ? ${W} : 0), PREINDEXED, NOWRITEBACK);
	else
		a64_str(cpu, ${W} == 3, 1 << ${W},           ${t}, ${n}, a64_extend($x[${m}], ${O'o}, ${S!test} ? ${W} : 0), PREINDEXED, NOWRITEBACK);
end

code	HH1110001W1mmmmmOOoS10nnnnnttttt
exclude	11..............................
exclude	10.......1......................
asm	ldrs{H?b;h;w} {t.~W!r}, [{n.1!sp}, {m.o!r}{extend(O'o,H*S,1)}]
added	8
begin
	// ldrsb/ldrsh/ldrsw

	a64_ldr(cpu, !${W!test}, ${H}, SIGNED, ${t}, ${n}, a64_extend($x[${m}], ${O'o}, ${S!test} ? ${H} : 0), PREINDEXED, NOWRITEBACK);
end

code	WW1110000L0iiiiiiiii10nnnnnttttt
asm	{L?ldtr:sttr}{W?b;h;;} {t.W!r}, [{n.1!sp}, #{signextend i:2X}]
added	8
begin
	// ldtr/sttr
	// TODO
end

code	HH1110001W0iiiiiiiii10nnnnnttttt
exclude	11..............................
exclude	10.......1......................
asm	ldtrs{H?b;h;w;} {t.~W!r}, [{n.1!sp}, #{signextend i:2X}]
added	8
begin
	// TODO
end

code	WW1110000L0iiiiiiiii00nnnnnttttt
asm	{L?ldur:stur}{W?b;h;;} {t.W!r}, [{n.1!sp}, #{signextend i:2X}]
added	8
begin
	// ldur/stur
	if(${L!test})
		a64_ldr(cpu, ${W} == 3, 1 << ${W}, UNSIGNED, ${t}, ${n}, ${signextend i}, PREINDEXED, NOWRITEBACK);
	else
		a64_str(cpu, ${W} == 3, 1 << ${W},           ${t}, ${n}, ${signextend i}, PREINDEXED, NOWRITEBACK);
end

code	HH1110001W0iiiiiiiii00nnnnnttttt
exclude	11..............................
exclude	10.......1......................
asm	ldurs{H?b;h;w;} {t.~W!r}, [{n.1!sp}, #{signextend i:2X}]
added	8
begin
	// ldur
	a64_ldr(cpu, !${W!test}, 1 << ${W}, SIGNED, ${t}, ${n}, ${signextend i}, PREINDEXED, NOWRITEBACK);
end

code	1W0010000L1!!!!!0TTTTTnnnnnttttt
asm	{L?ldxp:stxp} {t.W!r}, {T.W!r}, [{n.1!sp}]
added	8
begin
	// ldxp/stxp
	// TODO
end

code	WW0010000L0!!!!!0!!!!!nnnnnttttt
asm	{L?ldxr:stxr}{W?b;h;;} {t.W!r}, [{n.1!sp}]
added	8
begin
	// ldxr/stxr
	// TODO
end

code	W0011011000mmmmmsaaaaannnnnddddd
asm	{s?msub:madd} {d.W!r}, {n.W!r}, {m.W!r}, {a.W!r}
added	8
begin
	// madd/msub
	if(${s!test})
	{
		if(${W!test})
		{
			$x[${d}] = $x[${a}] - $x[${n}] * $x[${m}];
		}
		else
		{
			$w[${d}] = $w[${a}] - $w[${n}] * $w[${m}];
		}
	}
	else
	{
		if(${W!test})
		{
			$x[${d}] = $x[${a}] + $x[${n}] * $x[${m}];
		}
		else
		{
			$w[${d}] = $w[${a}] + $w[${n}] * $w[${m}];
		}
	}
end

code	W11100101hhiiiiiiiiiiiiiiiiddddd
exclude	0........1......................
asm	movk {d.W!r}, #{i:2X}, lsl #{h'0000}
added	8
begin
	// movk
	if(${W!test})
	{
		uint64_t shift = ${h} << 4;
		uint64_t mask = (uint64_t)0xFFFF << shift;
		$x[${d}] = ($x[${d}] & ~mask) | (${i} << shift);
	}
	else
	{
		uint32_t shift = ${h} << 4;
		uint32_t mask = (uint32_t)0xFFFF << shift;
		$w[${d}] = ($w[${d}] & ~mask) | (${i} << shift);
	}
end

code	W00100101hhiiiiiiiiiiiiiiiiddddd
exclude	0........1......................
asm	movn {d.W!r}, #{i:2X}, lsl #{h'0000}
added	8
begin
	// movn
	if(${W!test})
	{
		$x[${d}] = ~((uint64_t)${i} << (${h} << 4));
	}
	else
	{
		$x[${d}] = ~((uint32_t)${i} << (${h} << 4));
	}
end

code	W10100101hhiiiiiiiiiiiiiiiiddddd
exclude	0........1......................
asm	movz {d.W!r}, #{i:2X}, lsl #{h'0000}
added	8
begin
	// movz
	if(${W!test})
	{
		$x[${d}] = ((uint64_t)${i} << (${h} << 4));
	}
	else
	{
		$x[${d}] = ((uint32_t)${i} << (${h} << 4));
	}
end

code	110101010011abbbnnnnmmmmcccttttt
asm	mrs {t.1!r}, s{a?3:2}_{b}_c{n}_c{m}_{c}
added	8
begin
	// mrs
	$x[${t}] = a64_perform_mrs(cpu, opcode);
end

code	1101010100000aaa0100mmmmbbb11111
asm	msr {pstate(a'b)}, #{m:1X}
added	8
begin
	// msr
	switch(${a'b})
	{
	case 0b000011:
		// UAO // TODO: 8.2-UAO only
		// TODO
		break;
	case 0b000100:
		// PAN // TODO: 8.1-PAN only
		// TODO
		break;
	case 0b000101:
		// SPSel
		// TODO
		break;
	case 0b011110:
		// DAIFSet
		// TODO
		break;
	case 0b011111:
		// DAIFClr
		// TODO
		break;
	}
end

code	110101010001abbbnnnnmmmmcccttttt
asm	msr s{a?3:2}_{b}_c{n}_c{m}_{c}, {t.1!r}
added	8
begin
	// msr
	a64_perform_msr(cpu, opcode, $x[${t}]);
end

code	11010101000000110010000000011111
asm	nop
added	8
begin
	// nop
end

code	W0101010ssNmmmmmiiiiiinnnnnddddd
asm	{N?orn:orr} {d.W!r}, {n.W!r}, {m.W!r}, {s?lsl;lsr;asr;ror} #{i}
added	8
begin
	// orn
	if(${W!test})
		$x[${d}] = $x[${n}] | (a64_get_shifted_operand64($x[${m}], ${s}, ${i}) ^ (${N!test} ? 0xFFFFFFFFFFFFFFFF : 0));
	else
		$w[${d}] = $w[${n}] | (a64_get_shifted_operand32($w[${m}], ${s}, ${i}) ^ (${N!test} ? 0xFFFFFFFF : 0));
end

code	W01100100.............nnnnnddddd
exclude	0........1......................
asm	orr {d.W!sp}, {n.W!r}, #{bitmask(W)}
added	8
begin
	// orr
	if(${W!test})
		$x|sp[${d},0] = $x[${n}] | ${bitmask(1)};
	else
		$w|sp[${d},0] = $w[${n}] | ${bitmask(0)};
end

code	1111100110iiiiiiiiiiiinnnnnttttt
asm	prfm #{t}, [{n.1!sp}, {i'000:X}]
added	8
begin
	// prfm
end

code	11011000iiiiiiiiiiiiiiiiiiittttt
asm	prfm #{t}, [{signextend i'00!offset}]
added	8
begin
	// prfm
end

code	11111000101mmmmmOOoS10nnnnnttttt
asm	prfm #{t}, [{n.1!sp}, {m.o!r}{extend(O'o,S'000,1)}]
added	8
begin
	// prfm
end

code	11111000100iiiiiiiii00nnnnnttttt
asm	prfum #{t}, [{n.1!sp}, #{signextend i:2X}]
added	8
begin
	// prfum
end

code	W101101011000000000000nnnnnddddd
asm	rbit {d.W!r}, {n.W!r}
added	8
begin
	// rbit
	if(${W!test})
		$x[${d}] = rbit64($x[${n}]);
	else
		$w[${d}] = rbit32($w[${n}]);
end

code	W1011010110000000000Ssnnnnnddddd
exclude	....................00..........
exclude	0...................11..........
exclude	1...................10..........
asm	rev{S?:16} {d.W!r}, {n.W!r}
added	8
begin
	// rev/rev16
	if(${W!test})
	{
		if(${S!test}) // Ss == 11
			$x[${d}] = bswap_64($x[${n}]);
		else // Ss == 01
			$x[${d}] = bswap_64_16($x[${n}]);
	}
	else
	{
		if(${S!test}) // Ss == 10
			$w[${d}] = bswap_32($w[${n}]);
		else // Ss == 01
			$w[${d}] = bswap_32_16($w[${n}]);
	}
end

code	1101101011000000000010nnnnnddddd
asm	rev32 {d.1!r}, {n.1!r}
added	8
begin
	// rev32
	$x[${d}] = bswap_64_32($x[${n}]);
end

code	W1S11010000mmmmm000000nnnnnddddd
asm	sbc{S?s:} {d.W!r}, {n.W!r}, {m.W!r}
added	8
begin
	// sbc/sbcs
	if(${W!test})
		$x[${d}] = a64_sbc64(cpu, $x[${n}], $x[${m}], ${S!test});
	else
		$w[${d}] = a64_sbc32(cpu, $w[${n}], $w[${m}], ${S!test});
end

code	WU0100110NRRRRRRSSSSSSnnnnnddddd
exclude	1........0......................
exclude	0........1......................
exclude	0.........1.....................
exclude	0...............1...............
asm	{U?u:s}bfm {d.W!r}, {n.W!r}, #{R}, #{S}
added	8
begin
	// ubfm/sbfm
	if(${U!test})
	{
		if(${W!test})
			$x[${d}] = a64_ubfm64($x[${n}], ${R}, ${S});
		else
			$w[${d}] = a64_ubfm32($w[${n}], ${R}, ${S});
	}
	else
	{
		if(${W!test})
			$x[${d}] = a64_sbfm64($x[${n}], ${R}, ${S});
		else
			$w[${d}] = a64_sbfm32($w[${n}], ${R}, ${S});
	}
end

code	W0011010110mmmmm00001Snnnnnddddd
asm	{S?s:u}div {d.W!r}, {n.W!r}, {m.W!r}
added	8
begin
	// sdiv/udiv
	if(${W!test})
	{
		if($x[${m}] == 0)
			$x[${d}] = 0;
		else if(${S!test})
			$x[${d}] = (int64_t)$x[${n}] / (int64_t)$x[${m}];
		else
			$x[${d}] = (uint64_t)$x[${n}] / (uint64_t)$x[${m}];
	}
	else
	{
		if($w[${m}] == 0)
			$w[${d}] = 0;
		else if(${S!test})
			$w[${d}] = (int64_t)$w[${n}] / (int64_t)$w[${m}];
		else
			$w[${d}] = (uint64_t)$w[${n}] / (uint64_t)$w[${m}];
	}
end

code	11010101000000110010000010L11111
asm	sev{L?l:}
added	8
begin
	// sev/sevl
	// TODO
end

code	10011011U01mmmmmSaaaaannnnnddddd
asm	{U?u:s}m{S?sub:add}l {d.1!r}, {n.0!r}, {m.0!r}, {a.1!r}
added	8
begin
	// smaddl/umaddl/smsubl/umsubl
	if(${S!test})
	{
		if(${U!test})
			$x[${d}] = $x[${a}] - (uint32_t)$w[${n}] * (uint32_t)$w[${m}];
		else
			$x[${d}] = $x[${a}] - (int32_t)$w[${n}] * (int32_t)$w[${m}];
	}
	else
	{
		if(${U!test})
			$x[${d}] = $x[${a}] + (uint32_t)$w[${n}] * (uint32_t)$w[${m}];
		else
			$x[${d}] = $x[${a}] + (int32_t)$w[${n}] * (int32_t)$w[${m}];
	}
end

code	11010100000iiiiiiiiiiiiiiii00011
asm	smc #{i:4X}
added	8
begin
	// smc
	arm_smc(cpu);
end

code	10011011U10mmmmm0!!!!!nnnnnddddd
asm	{U?u:s}mulh {d.1!r}, {n.1!r}, {m.1!r}
added	8
begin
	// smulh/umulh
	if(${U!test})
		$x[${d}] = umulh64($x[${n}], $x[${m}]);
	else
		$x[${d}] = smulh64($x[${n}], $x[${m}]);
end

code	W1S01011001mmmmmOooiiinnnnnddddd
exclude	..1........................11111
asm	sub{S?s:} {d.W!sp?S}, {n.W!sp}, {m.W'o!r}{extend(O'o,i,W)}
added	8
begin
	// sub/subs
	if(${W!test})
		$x|sp[${d},${S!test}] = a64_sub64(cpu, $x|sp[${n},0], a64_extend($x[${m}], ${O'o}, ${i}), ${S!test});
	else
		$w|sp[${d},${S!test}] = a64_sub32(cpu, $w|sp[${n},0], a64_extend($w[${m}], ${O'o}, ${i}), ${S!test});
end

code	W1S1000100iiiiiiiiiiiinnnnnddddd
asm	sub{S?s:} {d.W!sp?S}, {n.W!sp}, #{i:X}
added	8
begin
	// sub/subs
	if(${W!test})
		$x|sp[${d},${S!test}] = a64_sub64(cpu, $x|sp[${n},0], ${i}, ${S!test});
	else
		$w|sp[${d},${S!test}] = a64_sub32(cpu, $w|sp[${n},0], ${i}, ${S!test});
end

code	W1S1000101iiiiiiiiiiiinnnnnddddd
asm	sub{S?s:} {d.W!sp?S}, {n.W!sp}, #{i'000000000000:X}
added	8
begin
	// sub/subs
	if(${W!test})
		$x|sp[${d},${S!test}] = a64_sub64(cpu, $x|sp[${n},0], ${i'000000000000}, ${S!test});
	else
		$w|sp[${d},${S!test}] = a64_sub32(cpu, $w|sp[${n},0], ${i'000000000000}, ${S!test});
end

code	W1S01011ss0mmmmmiiiiiinnnnnddddd
exclude	........11......................
exclude	0...............1...............
asm	sub{S?s:} {d.W!sp?S}, {n.W!r}, {m.W!r}, {s?lsl;lsr;asr;} #{i}
added	8
begin
	// sub/subs
	if(${W!test})
		$x|sp[${d},${S!test}] = a64_sub64(cpu, $x|sp[${n},0], a64_get_shifted_operand64($x[${m}], ${s}, ${i}), ${S!test});
	else
		$w|sp[${d},${S!test}] = a64_sub32(cpu, $w|sp[${n},0], a64_get_shifted_operand32($w[${m}], ${s}, ${i}), ${S!test});
end

code	11010100000iiiiiiiiiiiiiiii00001
asm	svc #{i:4X}
added	8
begin
	// svc
	arm_svc(cpu);
end

code	1101010100001aaannnnmmmmbbbttttt
asm	sys #{a}, c{n}, c{m}, #{b}, {t.1!r}
added	8
begin
	// sys
	a64_perform_sys(cpu, opcode, $x[${t}]);
end

code	1101010100101aaannnnmmmmbbbttttt
asm	sysl {t.1!r}, #{a}, c{n}, c{m}, #{b}
added	8
begin
	// sysl
	$x[${t}] = a64_perform_sysl(cpu, opcode);
end

code	W011011Nbbbbbiiiiiiiiiiiiiittttt
asm	tb{N?n:}z {t.W!r}, #{W'b}, {signextend i'00!offset}
added	8
begin
	// tbz/tbnz
	uint64_t bit = ($x[${t}] & ((uint64_t)1 << ${W'b}));
	if(${N!test} ? bit != 0 : bit == 0)
	{
		$pc = ${signextend i'0!offset};
	}

end

# TODO: tlbi

code	11010101000000110010000001011111
asm	wfe
added	8
begin
	// wfe
	// TODO
end

code	11010101000000110010000001111111
asm	wfi
added	8
begin
	// wfi
	// TODO
end

#### ARMv8-R

code	11010101000000110011110010011111
asm	dfb
added	8-R
begin
	// dfb
end

####	ARMv8.1

# TODO: only some of the instructions are included

code	WW0010001L1ssssso11111nnnnnttttt
asm	cas{L?a:}{o?l:}{W?b;h;;} {s.W!r}, {t.W!r}, [{n.1!sp}]
added	8.1
begin
	// casb/casab/caslb/casalb
	// cash/casah/caslh/casalh
	// cas/casa/casl/casal
	// TODO
end

code	0W0010000L1ssssso11111nnnnnttttt
asm	casp{L?a:}{o?l:} {s.W!r}, {s+1.W!r}, {t.W!r}, {t+1.W!r}, [{n.1!sp}]
added	8.1
begin
	// casp/caspa/caspl/caspal
	// TODO
end

code	W0011010110mmmmm010Cssnnnnnddddd
asm	crc32{C?c:}{s?b;h;w;x} {d.0!r}, {n.0!r}, {m.s!r}
added	8.1
begin
	// crc32/crc32c
	// TODO
end

code	WW111000AR1sssss000000nnnnnttttt
asm	ldadd{A?a:}{R?l:}{W?b;h;;} {s.W!r}, {t.W!r}, [{n.1!sp}]
added	8.1
begin
	// ldaddb/ldaddab/ldaddlb/ldaddalb
	// ldaddh/ldaddah/ldaddlh/ldaddalh
	// ldadd/ldadda/ldaddl/ldaddal
	// TODO
end

code	WW111000AR1sssss000100nnnnnttttt
asm	ldclr{A?a:}{R?l:}{W?b;h;;} {s.W!r}, {t.W!r}, [{n.1!sp}]
added	8.1
begin
	// ldclrb/ldclrab/ldclrlb/ldclralb
	// ldclrh/ldclrah/ldclrlh/ldclralh
	// ldclr/ldclra/ldclrl/ldclral
	// TODO
end

code	WW111000AR1sssss001000nnnnnttttt
asm	ldeor{A?a:}{R?l:}{W?b;h;;} {s.W!r}, {t.W!r}, [{n.1!sp}]
added	8.1
begin
	// ldeorb/ldeorab/ldeorlb/ldeoralb
	// ldeorh/ldeorah/ldeorlh/ldeoralh
	// ldeor/ldeora/ldeorl/ldeoral
	// TODO
end

code	WW001000110!!!!!0!!!!!nnnnnttttt
asm	ldlar{W?b;h;;} {t.W!r}, [{n.1!sp}]
added	8.1
begin
	// ldlarb/ldlarh/ldlar
	// TODO
end

code	WW111000AR1sssss001100nnnnnttttt
asm	ldset{A?a:}{R?l:}{W?b;h;;} {s.W!r}, {t.W!r}, [{n.1!sp}]
added	8.1
begin
	// ldsetb/ldsetab/ldsetlb/ldsetalb
	// ldseth/ldsetah/ldsetlh/ldsetalh
	// ldset/ldseta/ldsetl/ldsetal
	// TODO
end

code	WW111000AR1sssss01U000nnnnnttttt
asm	ld{U?u:s}max{A?a:}{R?l:}{W?b;h;;} {s.W!r}, {t.W!r}, [{n.1!sp}]
added	8.1
begin
	// ldsmaxb/ldsmaxab/ldsmaxlb/ldsmaxalb
	// ldsmaxh/ldsmaxah/ldsmaxlh/ldsmaxalh
	// ldsmax/ldsmaxa/ldsmaxl/ldsmaxal
	// ldumaxb/ldumaxab/ldumaxlb/ldumaxalb
	// ldumaxh/ldumaxah/ldumaxlh/ldumaxalh
	// ldumax/ldumaxa/ldumaxl/ldumaxal
	// TODO
end

code	WW111000AR1sssss01U100nnnnnttttt
asm	ld{U?u:s}min{A?a:}{R?l:}{W?b;h;;} {s.W!r}, {t.W!r}, [{n.1!sp}]
added	8.1
begin
	// ldsminb/ldsminab/ldsminlb/ldsminalb
	// ldsminh/ldsminah/ldsminlh/ldsminalh
	// ldsmin/ldsmina/ldsminl/ldsminal
	// lduminb/lduminab/lduminlb/lduminalb
	// lduminh/lduminah/lduminlh/lduminalh
	// ldumin/ldumina/lduminl/lduminal
	// TODO
end

code	WW001000100!!!!!0!!!!!nnnnnttttt
asm	stllr{W?b;h;;} {t.W!r}, [{n.1!sp}]
added	8.1
begin
	// stllrb/stllrh/stllr
	// TODO
end

code	WW111000AR1sssss100000nnnnnttttt
asm	swp{A?a:}{R?l:}{W?b;h;;} {s.W!r}, {t.W!r}, [{n.1!sp}]
added	8.1
begin
	// swpb/swpab/swplb/swpalb
	// swph/swpah/swplh/swpalh
	// swp/swpa/swpl/swpal
	// TODO
end

####	ARMv8.2

# TODO: only some of the instructions are included

code	11010101000000110010001000011111
asm	esb
added	8.2
begin
	// esb
	// TODO
end

code	11010101000000110010001000111111
asm	psb csync
added	8.2
begin
	// psb csync
	// TODO
end

####	ARMv8.3

code	11011010110000010001DMnnnnnddddd
asm	aut{D?d:i}{M?b:a} {d.1!r}, {n.1!sp}
added	8.3
begin
	// autia/autib/autda/autdb
	// TODO
end

code	11011010110000010011DM11111ddddd
asm	aut{D?d:i}z{M?b:a} {d.1!r}
added	8.3
begin
	// autiza/autizb/autdza/autdzb
	// TODO
end

code	1101010100000011001000o11Mo11111
exclude	......................0...1.....
asm	auti{M?b:a}{o?1716;;z;sp}
added	8.3
begin
	// autia1716/autiasp/autiaz/autib1716/autibsp/autibz
	// TODO
end

code	1101011100L1111100001Mnnnnnmmmmm
asm	b{L?l:}ra{M?b:a} {n.1!r}, {m.1!sp}
added	8.3
begin
	// braa/brab/blraa/blrab
	// TODO
end

code	1101011000L1111100001Mnnnnn11111
asm	b{L?l:}ra{M?b:a}z {n.1!r}
added	8.3
begin
	// braaz/brabz/blraaz/blrabz
	// TODO
end

code	110101101001111100001M1111111111
asm	ereta{M?b:a}
added	8.3
begin
	// eretaa/eretab
	// TODO
end

code	WW111000101!!!!!110000nnnnnttttt
asm	ldapr{W?b;h;;} {t.W!r}, [{n.1!sp}]
added	8.3
begin
	// ldaprb/ldaprh/ldapr
	// TODO
end

code	11111000Mi1iiiiiiiiiW1nnnnnttttt
asm	ldra{M?b:a} {t.1!r}, [{n.1!sp}, #{signextend i'000:X}]{W?!:}
added	8.3
begin
	// ldraa/ldrab
	// TODO
end

code	11011010110000010000DMnnnnnddddd
asm	pac{D?d:i}{M?b:a} {d.1!r}, {n.1!sp}
added	8.3
begin
	// pacia/pacib/pacda/pacdb
	// TODO
end

code	11011010110000010010DM11111ddddd
asm	pac{D?d:i}z{M?b:a} {d.1!r}
added	8.3
begin
	// paciza/pacizb/pacdza/pacdzb
	// TODO
end

code	10011010110mmmmm001100nnnnnddddd
asm	pacga {d.1!r}, {n.1!r}, {m.1!sp}
added	8.3
begin
	// pacga
	// TODO
end

code	1101010100000011001000o10Mo11111
exclude	......................0...1.....
asm	paci{M?b:a}{o?1716;;z;sp}
added	8.3
begin
	// pacia1716/paciaz/paciasp
	// pacib1716/pacibz/pacibsp
	// TODO
end

code	110101100101111100001M1111111111
asm	reta{M?b:a}
added	8.3
begin
	// retaa/retab
	// TODO
end

code	110110101100000101000D11111ddddd
asm	xpac{D?d:i} {d.1!r}
added	8.3
begin
	// xpaci/xpacd
	// TODO
end

######## A64 SIMD and floating point

code	0101111011100000101110nnnnnddddd
asm	abs d{d}, d{n}
added	8
begin
	// abs
	// TODO
end

code	0W001110WW100000101110nnnnnddddd
exclude	.0......11......................
asm	abs {d.W!v}, {n.W!v}
added	8
begin
	// abs
	// TODO
end

code	01011110111mmmmm100001nnnnnddddd
asm	add d{d}, d{n}, d{m}
added	8
begin
	// add
	// TODO
end

code	0W001110WW1mmmmm100001nnnnnddddd
exclude	.0......11......................
asm	add {d.W!v}, {n.W!v}, {m.W!v}
added	8
begin
	// add
	// TODO
end

code	0Q001110WW1mmmmm010000nnnnnddddd
exclude	........11......................
asm	addhn{Q?2:} {d.Q'W!v}, {n.Q'W!v}, {m.Q'W!v}
added	8
begin
	// addhn
	// TODO
end

code	0101111011110001101110nnnnnddddd
asm	addp d{d}, d{n}.2d
added	8
begin
	// addp
	// TODO
end

code	0W001110WW1mmmmm101111nnnnnddddd
exclude	.0......11......................
asm	addp {d.W!v}, {n.W!v}, {m.W!v}
added	8
begin
	// addp
	// TODO
end

code	0Q001110WW110001101110nnnnnddddd
exclude	.0......10......................
exclude	........11......................
asm	addv {W?b;h;s}{d}, {n.Q'W!v}
added	8
begin
	// addv
	// TODO
end

code	0100111000101000010D10nnnnnddddd
asm	aes{D?d:e} v{d}.16b, v{n}.16b
added	8
begin
	// aesd/aese
	// TODO
end

code	0100111000101000011D10nnnnnddddd
asm	aes{D?i:}mc v{d}.16b, v{n}.16b
added	8
begin
	// aesmc/aesimc
	// TODO
end

code	0Q001110001mmmmm000111nnnnnddddd
asm	and v{d}.{8<<Q}b, v{n}.{8<<Q}b, v{m}.{8<<Q}t
added	8
begin
	// and
	// TODO
end

code	0Q10111100000iiisaa101iiiiiddddd
exclude	................11..............
asm	bic v{d}.{4<<Q}{s?h:s}, #{simd_operand()}, lsl #{a<<3}
added	8
begin
	// bic
	// TODO
end

code	0Q001110011mmmmm000111nnnnnddddd
asm	bic v{d}.{8<<Q}b, v{n}.{8<<Q}b, v{m}.{8<<Q}b
added	8
begin
	// bic
	// TODO
end

code	0Q101110111mmmmm000111nnnnnddddd
asm	bif v{d}.{8<<Q}b, v{n}.{8<<Q}b, v{m}.{8<<Q}b
added	8
begin
	// bic
	// TODO
end

code	0Q101110101mmmmm000111nnnnnddddd
asm	bit v{d}.{8<<Q}b, v{n}.{8<<Q}b, v{m}.{8<<Q}b
added	8
begin
	// bit
	// TODO
end

code	0Q101110011mmmmm000111nnnnnddddd
asm	bsl v{d}.{8<<Q}b, v{n}.{8<<Q}b, v{m}.{8<<Q}b
added	8
begin
	// bsl
	// TODO
end

code	0W001110WW100000010010nnnnnddddd
exclude	........11......................
asm	cls {d.W!v}, {n.W!v}
added	8
begin
	// cls
	// TODO
end

code	0W101110WW100000010010nnnnnddddd
exclude	........11......................
asm	clz {d.W!v}, {n.W!v}
added	8
begin
	// clz
	// TODO
end

code	01111110111mmmmm100011nnnnnddddd
asm	cmeq d{d}, d{n}, d{m}
added	8
begin
	// cmeq
	// TODO
end

code	0W101110WW1mmmmm100011nnnnnddddd
exclude	.0......11......................
asm	cmeq {d.W!v}, {n.W!v}, {m.W!v}
added	8
begin
	// cmeq
	// TODO
end

code	01U11110111mmmmm0011E1nnnnnddddd
asm	cm{U'E?gt;ge;hi;hs} d{d}, d{n}, d{m}
added	8
begin
	// cmgt/cmge/cmhi/cmhs
	// TODO
end

code	0WU01110WW1mmmmm0011E1nnnnnddddd
exclude	.0......11......................
asm	cm{U'E?gt;ge;hi;hs} {d.W!v}, {n.W!v}, {m.W!v}
added	8
begin
	// cmgt/cmge/cmhi/cmhs
	// TODO
end

code	01o1111011100000100o10nnnnnddddd
asm	cm{o?gt;eq;ge;le} d{d}, d{n}, #0
added	8
begin
	// cmgt/cmeq/cmge/cmle
	// TODO
end

code	0Wo01110WW100000100o10nnnnnddddd
exclude	.0......11......................
asm	cm{o?gt;eq;ge;le} {d.W!v}, {n.W!v}, #0
added	8
begin
	// cmgt/cmeq/cmge/cmle
	// TODO
end

code	01011110111mmmmm100011nnnnnddddd
asm	cmtst d{d}, d{n}, d{m}
added	8
begin
	// cmtst
	// TODO
end

code	0W001110WW1mmmmm100011nnnnnddddd
exclude	.0......11......................
asm	cmtst {d.W!v}, {n.W!v}, {m.W!v}
added	8
begin
	// cmtst
	// TODO
end

code	0Q00111000100000010110nnnnnddddd
asm	cnt v{d}.{8<<Q}b, v{n}.{8<<Q}b
added	8
begin
	// cnt
	// TODO
end

######## 8.2

code	11001110001mmmmm0aaaaannnnnddddd
asm	bcax v{d}.16b, v{n}.16b, v{m}.16b, v{a}.16b
added	8.2
begin
	// bcax
	// TODO
end









